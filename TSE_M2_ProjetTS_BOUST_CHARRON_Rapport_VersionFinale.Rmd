---
title: "Projet de séries temporelles - Rapport final"
author: 
- "Paul Boust"
- "Faustine Charron"
date: "16 décembre 2020"
output:
  html_notebook:
    number_sections: yes
    toc: yes
    toc_depth: '2'
  pdf_document:
    toc: yes
    toc_depth: '2'
subtitle: "Prévision de la consommation d'électricité en France"
df_print: paged
bibliography: TSE_M2_SeriesTemporelles_Projet_Bibliographie.bib
csl: StyleBibliographie_Chicago-author-date-fr.csl
nocite: | 
  @hyndman_forecasting_2014
---



```{r Lisez_moi, include=FALSE, eval=FALSE}

############### -
# LISEZ-MOI ! # -
############### -

# Nom : TSE_M2_SeriesTemporelles_Projet_CodeR
# Date de validation : 12/12/2020
# Version : 1.0
# Créateurs : Paul BOUST, Faustine CHARRON
#
#
# Fichier R associé au projet semestriel de séries temporelles
# Quelques consignes pour une bonne utilisation : 
#
#   - Une connexion internet est requise pour télécharger les bases de données depuis GitHub
#   - Pour un fonctionnement correct de la bibliographie, penser à ajouter au dossier de travail :
#     (sans cela, message d'erreur de Pandoc lors de la Preview du NB.HTML)
#
#       - TSE_M2_SeriesTemporelles_Projet_Bibliographie.bib
#       - StyleBibliographie_Chicago-author-date-fr.csl
#
#   Les deux fichiers sont disponible sur GitHub
#   https://github.com/PaulB1204/TSE.M2.S1_ProjetTS_Paul.Faustine
#
#   - Le code fonctionne théoriquement de A à Z, sans bugs
#   - L'exécution du code dans son ensemble est assez longue : 
#   
#   ######################################################################
#   # -> Compter 5 bonnes minutes avant que tout le code ne soit exécuté #
#   ######################################################################
#
```



```{r Import_GitHub, include=FALSE}
########################### -
# IMPORT DES BASES GITHUB # -
########################### -

# Connexion internet requise !

# Base 2016-2019
df <- read.csv("https://raw.githubusercontent.com/PaulB1204/TSE.M2.S1_ProjetTS_Paul.Faustine/main/TSE_M2_ProjetTS_BasePrincipale_2016_2019.csv", sep = ";", dec = ",")

# Base 2020
df2020 <- read.csv("https://raw.githubusercontent.com/PaulB1204/TSE.M2.S1_ProjetTS_Paul.Faustine/main/TSE_M2_ProjetTS_BasePrevisions_2020.csv", sep = ";", dec = ",")
```

```{r Import_Packages, include=FALSE}
####################### -
# IMPORT DES PACKAGES # -
####################### -

library(tidyverse)
library(readxl)
library(forecast)
library(ggplot2)
library(astsa)
library(urca)
library(multipol)
library(zoo)
```

```{r Chargement_fonctions_maison, include=FALSE}
#################### -
# FONCTIONS MAISON # -
#################### -

# Fonction  pour les tests ADF
fonction.ADF = function(serie, lags, type = "trend"){
  
  # Test ADF
  test.adf <- ur.df(serie, type = type,lags = lags)
  
  # Mise en forme des résultats
  res.df <- data.frame(as.vector(test.adf@teststat),test.adf@cval) 
  names(res.df) <- c("Statistique","CV 1%", "CV 5%", "CV 10%")
  res.df <- round(res.df, 2)
  
  # Affichage des résultats
  cat("############ \n# Test ADF # \n############\n\n")
  cat(paste("Nombre de retards :", lags, "\n"))
  cat(paste("Type :", type, "\n\n"))
  print(res.df)}


# Fonction de couleur pour le texte
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, 
      x)
  } else x
}

# Définition de quelques couleurs
rouge1 = "#CB4335"
bleu1 = "#2980B9"
vert1 = "#1E8449"
jaune1 = "#F1C40F"
orange1 = "#E67E22"

# Création de la fonction mode (inexistante dans R)
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

```

\
\
\
\

# Introduction

---


**`r colorize("Thème et problématique du projet", bleu1)`**

Dans le cadre de notre projet semestriel de séries temporelles, nous avons arrêté notre choix sur le thème suivant : la prévision de la consommation nationale d'électricité en France. 

Cette question nous apparaît comme doublement pertinente. De manière générale tout d’abord, être en mesure de prévoir avec précision la consommation d’électricité nous semble être essentiel pour beaucoup d’acteurs économiques. Pour des horizons temporels courts (voire très courts), de telles prévisions permettent d’anticiper et d’ajuster la production électrique nationale. À plus long terme, les prévisions de la consommation électrique française trouvent également leur utilité : elles peuvent par exemple guider des décisions d’investissement (construction de nouvelles infrastructures de production et/ou de transport d’électricité), ou encore servir de support à la mise en place de différentes politiques énergétiques (inciter les secteurs les plus gourmands en énergie à réduire leur consommation etc.).

Nous les présenterons plus en détails dans la partie suivante, mais nos données nous permettent de connaître la consommation électrique française toutes les 3 heures, chaque jour, entre le 1er janvier 2016 et le 31 décembre 2019. La question que nous nous posons et qui va guider l'ensemble de notre analyse est la suivante : 

---

**Dans quelle mesure est-il possible de capturer la dynamique de la série de la consommation d'électricité afin de calculer des prévisions pour des horizons temporels "lointains" tout en conservant une fréquence de données très élevée (données journalières voire horaires) ?**

---

En effet, la problématique principale liée à cette question est la présence d'une saisonnalité multiple dans les données. Avec des données horaires, trois saisonnalités existent : la première est mensuelle (la consommation d'électricité varie d'un mois à l'autre), la seconde est hebdomadaire (elle varie également au cours de la semaine --- jours ouvrés *v.* week-end) et la troisième est journalière (la consommation n'est pas la même à midi et à minuit). La littérature s'est beaucoup penchée sur cette question, et apporte des éléments de réflexion fort intéressants. 

\

**`r colorize("Revue de littérature sur le sujet", bleu1)`**

La littérature sur ce sujet est en effet abondante, et nous ne pouvons en présenter ici qu’un aperçu ayant pour objet d’appuyer notre analyse à venir. La littérature économétrique peut être séparée en différentes catégories, selon l’horizon temporel des prévisions souhaitées. Pour des prévisions de moyen-long terme, quelques recherches proposent l’utilisation de modèles univariés [@abadie_etude_1979]. On peut noter l’utilisation de méthodes de *bootstrap aggregating (bagging)* avec des modèles ETS ou ARIMA [@meira_de_oliveira_forecasting_2018]. Cependant, la majorité des travaux à moyen-long terme utilise des variables exogènes. Si les variables météorologiques semblent incontournables [@mirasgedis_models_2006; @de_felice_seasonal_2015; @cancelo_forecasting_2008], d’autres travaux prennent également en compte certaines variables économiques et démographiques [@chui_long-term_2009] (le PIB par exemple).

Pour des prévisions à court-terme (consommation à la journée), voire à très court-terme (consommation à l’heure, à la demi-heure, voire à la minute), la littérature est encore plus importante. Avec de tels horizons temporels, il semble exister un réel débat sur les méthodes à employer. Beaucoup de travaux proposent des modèles SARIMA [@soares_modeling_2008], la saisonnalité étant de toute évidence l’un des enjeux majeurs de la prévision de la consommation d’électricité à court-terme [@taylor_triple_2010]. Inclure plusieurs saisonnalités dans le modèle est essentiel. L’utilisation de variables exogènes semble moins indispensable que pour des horizons temporels plus lointain. James W. Taylor le justifie en expliquant que les variables exogènes habituellement utilisées (e.g. la météo) ne changent que lentement et de manière lisse à très court terme, et que ces faibles changement sont capturés par la série elle-même.

Les travaux les plus importants sur la gestion des saisonnalités multiples pour la prévision de l'électricité sont vraisemblablement ceux de James Taylor. Dans son article "Triple Seasonal Methods for Short-Term Electricity Demand Forecasting" qui nous a largement inspiré, il propose de réconcilier les deux approches précédentes en conservant un horizon temporel conséquent, avec des données pourtant horaires. Pour cela, il met en place un ambitieux modèle SARIMA avec triple saisonnalité, que nous détaillerons plus loin dans notre rapport. 

\

**`r colorize("Construction de ce rapport", bleu1)`**

Notre ambition est de s'inspirer des travaux de Taylor, et de tenter de modéliser plusieurs saisonnalités dans notre série. Pour cela, notre rapport va s'organiser de la façon suivante. Dans un premier temps, nous présenterons nos données et nous mettrons en évidence les différentes saisonnalités qui les caractérisent. Puis dans une longue partie d'analyse, nous commencerons par présenter la fonction SARMA multiple développée spécialement pour ce projet. Une fois la fonction présentée, nous progresserons de manière pyramidale dans la modélisation de notre série, en ajoutant progressivement de la complexité à nos modèles. Enfin, nous résumerons nos résultats dans une conclusion détaillée, dans laquelle nous présenterons également plusieurs idées intéressantes quant à la poursuite de ces travaux. 

\

**`r colorize("Note importante concernant la fonction S3ARMA", bleu1)`**

*Le développement de la fonction `S3ARMA`, permettant de modéliser une série par un modèle SARMA multiple, constitue l'un des éléments principaux de ce projet. Inspiré nous l'avons dit par les travaux de James Taylor, la possibilité d'ajouter des polynômes saisonniers à un modèle SARMA classique nous a immédiatement intrigué. Nous avons alors voulu mettre cette méthode en place, en développant une fonction permettant de le faire de la manière la plus complète possible. Ce travail de développement fut passionnant, au sens propre du terme. Des dizaines d'heures de travail furent nécessaire pour aboutir à la fonction `S3ARMA` telle que présentée dans ce projet, des heures que nous nous sommes refusées à compter tant étudier, comprendre mathématiquement, développer et tester notre fonction fut riche en apprentissage<u>s</u>. Pourquoi écrire tout cela en cette fin d'introduction ? Parce que malheureusement, nous n'avons pas eu le temps d'exploiter pleinement cette fonction et de l'appliquer à nos données. Nous avons pu le faire sur des données simulées, dont la présentation est disponible en annexe de ce devoir, mais pas sur les séries de consommation d'électricité. La raison d'être de ce paragraphe est ainsi de souligner que, malgré sa faible part dans notre analyse finale, cette fonction `S3ARMA` et la modélisation théorique associée sont des élements centraux de ce projet, car ils sont à l'origine de notre épanouissement à le réaliser.*


\
\
\
\

# Données

Pour cette analyse, nous allons utiliser deux bases de données principales. La première concerne bien sûr la consommation d’électricité en France, tandis que la seconde regroupe des données météorologiques. Nous les présentons plus en détail ci-dessous. Le lecteur trouvera également dans cette partie une analyse descriptive de nos différentes variables. 

---

```{r Import_des_donnees_Base2016_2019, include=FALSE}

############################################################ -
### Étape 1 : Import et synthèse des données par échelle ### - 
############################################################ -

# Confirmation du nom des colonnes
colnames(df) = c("ID", "Consommation", "Annee", "Mois", "Jour", "Creneau", "JourSem", "NumSem", "temp", "cover", "hum", "dummyJF", "vacances_zone_a", "vacances_zone_b", "vacances_zone_c", "nb_zones")

# Passage en gigawatts : division de la consommation par 1 000 000 000 (un milliard)
df$Consommation = (df$Consommation)/1000000000

################# -
# Synthèse mois # -
################# -

# On synthétise les données par mois (moyenne)
df.gr.mois <- df %>% group_by(Annee, Mois) %>% summarise(
  Consommation = round(mean(Consommation),0),
  Mois = mean(Mois),
  Annee = mean(Annee),
  Temp = mean(temp, na.rm = TRUE),
  Cover = mean(cover, na.rm = TRUE),
  Hum = mean(hum, na.rm = TRUE),
  dummyJF = sum(dummyJF),
  vacances_zone_a = sum(vacances_zone_a),
  vacances_zone_b = sum(vacances_zone_b),
  vacances_zone_c = sum(vacances_zone_c),
  nb_zones = sum(nb_zones))

# Création de la série temporelle associée
ts_mois <- ts(df.gr.mois$Consommation, frequency=12, start=c(2016,01))

#################### -
# Synthèse semaine # -
#################### -

# On synthétise les données par semaine (moyenne)
df.gr.semaine <- df %>% group_by(Annee, NumSem) %>% summarise(
  Consommation = round(mean(Consommation),0),
  NumSem = mean(NumSem),
  Mois = mean(Mois),
  Annee = mean(Annee),
  Temp= mean(temp, na.rm=TRUE),
  Cover = mean(cover, na.rm=TRUE),
  Hum = mean(hum, na.rm=TRUE),
  dummyJF = sum(dummyJF),
  vacances_zone_a = sum(vacances_zone_a),
  vacances_zone_b = sum(vacances_zone_b),
  vacances_zone_c = sum(vacances_zone_c),
  nb_zones = sum(nb_zones))

# On enlève les semaines 0 et 53
df.gr.semaine = df.gr.semaine[df.gr.semaine$NumSem != 0,]
df.gr.semaine = df.gr.semaine[df.gr.semaine$NumSem != 53,]

# Création de la série temporelle associée
ts_semaine <- ts(df.gr.semaine$Consommation, frequency=52, start=c(2016,01))

################# -
# Synthèse jour # -
################# -

# On synthétise les données par jour (moyenne)
df.gr.jour <- df %>% group_by(Annee, Mois, Jour) %>% summarise(
  Consommation = round(mean(Consommation),0),
  Jour = mean(Jour),
  JourSem = getmode(JourSem),
  NumSem = mean(NumSem),
  Mois = mean(Mois),
  Annee = mean(Annee),
  Temp= mean(temp, na.rm=TRUE),
  Cover = mean(cover, na.rm=TRUE),
  Hum = mean(hum, na.rm=TRUE),
  dummyJF = mean(dummyJF),
  vacances_zone_a = mean(vacances_zone_a),
  vacances_zone_b = mean(vacances_zone_b),
  vacances_zone_c = mean(vacances_zone_c),
  nb_zones = mean(nb_zones))

# On enlève les semaines 0 et 53
df.gr.jour = df.gr.jour[df.gr.jour$NumSem != 0,]
df.gr.jour = df.gr.jour[df.gr.jour$NumSem != 53,]

# Création de la série temporelle associée
ts_jour <- ts(df.gr.jour$Consommation)

```

```{r Import_des_donnees_Base2020, include=FALSE}

########################## -
# Construction base 2020 # -
########################## -

# Suppression des 3 premières colonnes
df2020 = df2020[,c(-1,-2,-3)]

##################### -
# Synthèse par mois # -
##################### -

# Variable au futur certain : calendrier (vacances, jours fériés)
df.gr.mois.2020 <- df2020 %>% group_by(Annee, Mois) %>% summarise(
                    Annee = mean(Annee),
                    Mois = mean(Mois),
                    dummyJF = sum(dummyJF),
                    vacances_zone_a = sum(vacances_zone_a),
                    vacances_zone_b = sum(vacances_zone_b),
                    vacances_zone_c = sum(vacances_zone_c),
                    nb_zones = sum(nb_zones))

# Variable au futur incertain : moyenne des variables météo sur les 4 années précédentes
mean_temp <- df %>% group_by(Mois) %>% summarise(Temp= mean(temp, na.rm=TRUE))
mean_hum <- df %>% group_by(Mois) %>% summarise(Hum= mean(hum, na.rm=TRUE))
mean_cover <- df %>% group_by(Mois) %>% summarise(Cover= mean(cover, na.rm=TRUE))

# On ajoute les variables météo à la base
df.gr.mois.2020 = left_join(df.gr.mois.2020, mean_temp, by=c("Mois" = "Mois"))
df.gr.mois.2020 = left_join(df.gr.mois.2020, mean_hum, by=c("Mois" = "Mois"))
df.gr.mois.2020 = left_join(df.gr.mois.2020, mean_cover, by=c("Mois" = "Mois"))


######################## -
# Synthèse par semaine # -
######################## -

# Variable au futur certain : calendrier (vacances, jours fériés)
df.gr.semaine.2020 <- df2020 %>% group_by(Annee, NumSem) %>% summarise(
                    NumSem = mean(NumSem),
                    Annee = mean(Annee),
                    dummyJF = sum(dummyJF),
                    vacances_zone_a = sum(vacances_zone_a),
                    vacances_zone_b = sum(vacances_zone_b),
                    vacances_zone_c = sum(vacances_zone_c),
                    nb_zones = sum(nb_zones))

# On enlève les semaines 0 et 53
df.gr.semaine.2020 = df.gr.semaine.2020[df.gr.semaine.2020$NumSem != 0,]
df.gr.semaine.2020 = df.gr.semaine.2020[df.gr.semaine.2020$NumSem != 53,]

# On synthétise les données par semaine (moyenne)
mean_temp <- df %>% group_by(NumSem) %>% summarise(Temp= mean(temp, na.rm=TRUE))
mean_hum <- df %>% group_by(NumSem) %>% summarise(Hum= mean(hum, na.rm=TRUE))
mean_cover <- df %>% group_by(NumSem) %>% summarise(Cover= mean(cover, na.rm=TRUE))

# On ajoute les variables météo à la base
df.gr.semaine.2020 = left_join(df.gr.semaine.2020, mean_temp, by=c("NumSem" = "NumSem"))
df.gr.semaine.2020 = left_join(df.gr.semaine.2020, mean_hum, by=c("NumSem" = "NumSem"))
df.gr.semaine.2020 = left_join(df.gr.semaine.2020, mean_cover, by=c("NumSem" = "NumSem"))


##################### -
# Synthèse par jour # -
##################### -

# On synthétise les données par jour
df.gr.jour.2020 <- df2020 %>% group_by(Annee, Mois, Jour) %>% summarise(
                    NumSem = mean(NumSem),
                    Annee = mean(Annee),
                    Mois = mean(Mois),
                    Jour = mean(Jour),
                    dummyJF = mean(dummyJF),
                    vacances_zone_a = mean(vacances_zone_a),
                    vacances_zone_b = mean(vacances_zone_b),
                    vacances_zone_c = mean(vacances_zone_c),
                    nb_zones = mean(nb_zones))

# On enlève les semaines 0 et 53
df.gr.jour.2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem != 0,]
df.gr.jour.2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem != 53,]

# On synthétise les données par jour (moyenne)
mean_temp <- df %>% group_by(Mois, Jour) %>% summarise(Temp= mean(temp, na.rm=TRUE))
mean_hum <- df %>% group_by(Mois, Jour) %>% summarise(Hum= mean(hum, na.rm=TRUE))
mean_cover <- df %>% group_by(Mois, Jour) %>% summarise(Cover= mean(cover, na.rm=TRUE))

# On ajoute les variables météo à la base
df.gr.jour.2020 = left_join(df.gr.jour.2020, mean_temp, by=c("Mois" = "Mois", "Jour" = "Jour"))
df.gr.jour.2020 = left_join(df.gr.jour.2020, mean_hum, by=c("Mois" = "Mois", "Jour" = "Jour"))
df.gr.jour.2020 = left_join(df.gr.jour.2020, mean_cover, by=c("Mois" = "Mois", "Jour" = "Jour"))
```

## Présentation des données et définition des variables
### Consommation électrique

Notre base de données principale concerne **la consommation d’électricité en France** (métropolitaine). Nous utilisons les données mises à disposition par ENEDIS, filiale d’EDF, qui est en charge de la gestion et de l’aménagement de 95% du réseau de distribution d’électricité en France. Nous utilisons des jeux de données annuels, correspondant au bilan électrique au pas demi-heure de l’année (i.e. une observations toutes les demi-heures). On trouve dans cette base la consommation électrique, des variables relatives aux différents modes de production etc.

Dans cette base initiale, une seule variable nous intéresse : la consommation électrique totale (en watts) mesurée toutes les demi-heures, toute l’année. Tous les types de consommateurs et de consommations sont regroupés dans ce chiffre : entreprises, ménages, activités de production ou non etc. Nous utilisons 4 années de données, de 2016 à 2019. Nous transformons la série, pour passer d’une observation toutes les demi-heures à une observation toutes les trois heures. Une telle transformation de la temporalité de la série se justifie par la nature des données météo que nous présenterons plus loin, qui elles-mêmes sont observées toutes les trois heures.

Ainsi, notre série temporelle principale est la série de la consommation électrique totale française (en watts). Nous disposons de 11 688 observations, réparties toutes les trois heures (minuit, 3h, 6h, 9h, 12h, 15h, 18h et 21h) entre le 1<sup>er</sup> janvier 2016 minuit jusqu’au 31 décembre 2019 à 21h. Ce niveau que nous pouvons qualifier de “niveau-3h” est le plus fin à notre disposition. Bien entendu, à partir d’un tel niveau de détail, il est possible de synthétiser la consommation en des niveaux d’agrégation plus larges.

Le lecteur trouvera ci-dessous la représentation temporelle de notre série. De prime abord, nous concédons que c’est assez difficile à lire, tant les observations sont nombreuses et les saisonnalités multiples. Pour faciliter l'analyse, nous travaillerons tout au long de ce projet en gigawatts (GW), un gigawatt correspondant à un milliard de watts. 

*Note : Dans la suite de ce projet, la variable consommation électrique sera souvent écrite `Consommation` ou `Conso`.*

\

<center>

```{r, include=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
autoplot(ts(df$Consommation)) + 
  labs(title =  "Consommation électrique nationale française mesurée toutes les 3 heures",
       subtitle = "Observations entre le 01/01/2016 00:00 et le 31/12/2019 21:00",
       x = "Temps", y = "Consommation électrique (GW)")
```
</center>

\

### Données météorologiques

Dans notre analyse de la série de la consommation électrique, nous intégrerons certaines variables exogènes. Les principales sont des **variables météorologiques**, au premier rang desquelles la température. Il s’agit donc de récupérer l’historique météorologique français, en gardant en tête la contrainte suivante : pour l'analyse, la fréquence des données météo doit être la même que celle des données électriques.

Pour cela, nous utilisons les données mises à disposition par Météo France. Plus précisément, nous utilisons l’historique des codes SYNOP émis par l’ensemble des stations météorologiques françaises. Le code SYNOP est un codage de données utilisé par l’Organisation météorologique mondiale. Il est employé pour diffuser les observations d’une station météorologique terrestre à intervalle régulier de 3 heures. Un code SYNOP regroupe de nombreux paramètres atmosphériques mesurés ou observés (température, humidité, direction et force du vent, description des nuages etc.). Météo France fournit l’historique de ces codes SYNOP émis par les 62 stations météo françaises, en métropole aussi bien qu’en outre-mer.

Nous récupérons l’ensemble de ces codes SYNOP, entre janvier 2016 et décembre 2019. Il s’agit ensuite de synthétiser l’information. En effet, toutes les trois heures, nous disposons de 62 codes SYNOP. Or les données électriques sont à l’échelle nationale, il faut donc synthétiser les données des différentes stations météo. Nous laissons de côté les stations météorologiques d’outre-mer, dont les chiffres viendraient fausser les moyennes métropolitaines. L’idée est donc de ne conserver que les 42 stations de métropole. Pour chaque période temporelle, on synthétise les informations émanant de ces 42 stations en utilisant une moyenne. On ne conserve que trois variables :

- **La température** (exprimée en degrés Celsius) : Il s’agit de l’une des variables clé pour modéliser la consommation d’électricité. Nous détaillerons l'effet de la température sur la consommation d'électricité dans le point suivant, qui nous le verrons n'est pas constant au fil des saisons. Dans la suite de ce projet, cette variable sera souvent synthétisée sous le nom `Temp` ou `temp`.

- **Le taux d’humidité** (compris entre 0 et 100) : La littérature nous indique que c’est une variable importante lorsqu’il s’agit de comprendre la consommation d’électricité [@ihara_city-block-scale_2008; @hor_analyzing_2005]. Un taux d'humidité important impliquerait une consommation électrique plus importante. Dans la suite de ce projet, cette variable sera souvent synthétisée sous le nom `Hum` ou `hum`.

- **La couverture nuageuse** (comprise entre 0 et 100) : L’idée derrière la sélection de cette variable est que plus la couverture nuageuse est importante, plus la luminosité est faible, générant une plus grande consommation électrique. Dans la suite de ce projet, cette variable sera souvent synthétisée sous le nom `Cover` ou `cover`.

\

### Variables calendaires

Enfin, nous incluons à nos données quelques variables calendaires, dont nous savons qu'elles impactent la consommation d'électricité. L'avantage massif de ces données, nous aurons l'occasion de le voir plus loin, est **qu'elles sont parfaitement prévisibles : nous connaissons d'ores et déjà la composition du calendrier pour les prochaines années**. Nous considérons ainsi les variables suivantes : 

- **Les jours de la semaine** : Pour chaque observation, nous prenons le soin d'indiquer à quel jour de la semaine elle correspond. Nous le verrons dans le point suivant, ce paramètre a de l'importance. Parfois dans cette étude cette variable sera nommée `JourSem`.

- **Les jours fériés** : Nous utilisons une variable binaire égale à 1 lorsque le jour d'observation est un jour férié et égale à 0 le reste du temps. Souvent par la suite cette variable prendra le nom `dummyJF` ou `DummyJF`.

- **Les jours de vacances** : Cette fois, la prise en compte de ce paramètre est un peu plus complexe. Nous savons que la France est divisée en trois zones (A, B, C) en ce qui concerne les vacances. De fait, nous avons initialement trois variables binaires associées à chaque observation, respectivement notées `vacances_zone_a`, `vacances_zone_b` et `vacances_zone_c`, égalent à 1 lorsque l'observation correspond à un jour de vacances dans l'une des zones. Pour synthétiser cette information, nous créons une variable, appelée `nb_zones` et parfois notée `NbZones`. Elle correspond à la somme des trois variables binaires précédente, et correspond donc pour chaque observation au nombre de zones en vacances à l'instant t. Là-encore, nous allons voir que les vacances ont une importance lorsqu'il s'agit de modéliser la consommation d'électricité.  

\

### Synthèse des données

Nous l'avons dit, nous allons au cours de cette étude travailler sur des données synthétisées obtenues à partir de notre base initiale. Nous travaillons avec trois niveaux de synthèse principaux : 

- **Une synthèse au mois** et une **synthèse à la semaine**. Pour ces deux bases, nous synthétisons nos variables de la façon suivante. Nous prenons la moyenne des variables consommation électrique, température, humidité et couverture nuageuse, et nous prenons la somme de nos variables jours fériés et vacances. 
  
- **Une synthèse à la journée** : Cette fois, nous travaillons avec les moyennes de toutes nos variables. En effet, les variables calendaires sont toutes des variables "journalières". Ainsi, pour le 1<sup>er</sup> janvier 2017 par exemple, les huit observations de cette journées vont toutes avoir la variable binaire jour fériée égale à 1. En prenant la moyenne pour la journée, nous obtenons bien 1. 

\

### Création d'une base pour l'année 2020

Nos données s'étalent de janvier 2016 à décembre 2019. Notre objectif pour ce projet et de calculer des prévisions pour l'année 2020. Pour cela, nous allons mettre en place des modèles de type SARIMAX, avec pour régresseurs un certain nombre de variables présentées plus haut. Afin de pouvoir calculer des prévisions pour ces modèles, il nous faut "connaître" les valeurs futures des régresseurs. Nous créons donc une base de données pour l'année 2020, qui comporte les valeurs futures de nos variables (sauf la consommation électrique bien-sûr). 

Pour les variables calendaires, rien de plus simple ! Nous connaissons dès aujourd'hui les jours fériés pour de nombreuses années d'avance, et donc *a fortiori* pour l'année 2020. Il en va de même pour les vacances scolaires, dont le calendrier est fixé plusieurs années à l'avance. Pour nos variables météorologiques, c'est évidemment une autre histoire. Nous ne connaissons bien entendu pas un an à l'avance le temps qu'il fera dans le futur. Nous prenons donc comme valeurs futures pour nos trois variables météo la moyenne des 4 années précédentes. Bien entendu, ce n'est qu'une estimation de la valeur future de nos variables, et cette valeur future comporte donc une part d'incertitude. 

\
\

## Analyse descriptive
### Statistiques descriptives des variables continues

Avant d'entamer la modélisation de notre série, prenons le temps d'observer nos données. Pour cela, commençons par quelques statistiques descriptives pour nos variables continues, à savoir `Consommation`, `Temp`, `Cover` et `Hum`. Elles sont disponibles ci-dessous. Pour l'instant, nous travaillons toujours avec les données horaires. 

```{r, include=TRUE, echo=FALSE}
summary(df[,c("Consommation", "temp", "cover", "hum")])
```

Si l'on regarde la consommation électrique, il est intéressant de noter que le minimum observé est de 21 GW, tandis que le maximum atteint est de 74.03 GW. Les variations sont donc très importantes. Les statistiques descriptives relatives à la température surprendront peut-être le lecteur. En effet, le minimum n'est "que" de -6.5°C, et le maximum atteint entre 2016 et 2019 de 34°C. Or, nous savons que des températures bien supérieures sont souvent atteintes l'été, et que le thermomètre descend bien en dessous de -6.5°C par endroits l'hiver. L'explication réside dans le fait qu'il s'agit, pour chaque période *i.e.* un créneau de 3h, d'une moyenne des 42 stations météo métropolitaines utilisées. Des minimums/maximums locaux n'apparaissent donc pas dans ces chiffres. 

\

### Analyse des saisonnalités existantes dans les données

Nous l'avons dit en introduction, les séries de consommation d'électricité, en France ou ailleurs, sont bien connues pour la présence de saisonnalités multiples, si la fréquence d'observation est suffisamment élevée. C'est également le cas dans nos données, et nous pouvons l'illustrer.

Commençons par **la saisonnalité annuelle**. Chaque année, un motif se répète dans la consommation d'électricité, et il est assez facile à comprendre : l'été, la consommation d'électricité est plus faible que l'hiver, l'automne et le printemps servant de périodes de transition. Cette disparité intra-annuelle est principalement due aux variation des dépenses électriques de chauffage. Pour observer cette saisonnalité, on représente ci-dessous un graphique saisonnier, à partir de nos donnée synthétisées au mois. Chaque courbe correspond à une année, et l'on observe bien qu'elles ont toutes une forme similaire. La saisonnalité annuelle est ainsi bien visible. 

\

<center>

```{r Graphique_saisonnalite_annuelle, include=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
ggseasonplot(ts_mois, year.labels=TRUE, year.labels.left=TRUE) +
  ylab("$ million") +
  labs(title = "Consommation mensuelle moyenne d'électricité", 
       subtitle = "Moyenne mensuelle entre janvier 2016 et décembre 2019",
       x = "Mois", y = "Consommation électrique (GW)")
```

</center>

\

Il existe également une **saisonnalité hebdomadaire** dans la série de la consommation d'électricité. En effet, chaque jour de la semaine n'est pas équivalent en termes de consommation électrique. Les jours travaillés sont des jours où la demande d'électricité est plus importante que pendant le week-end. Nous pouvons le constater graphiquement ci-dessous. Nous profitons de cette représentation graphique pour faire également apparaître la différence de consommation entre jours classiques, jours de vacances et jours fériés. On observe clairement qu'une journée de vacances, qu'importe sa position dans la semaine, est une journée où la demande d'électricité est moindre. L'effet d'un jour férié est identique.

\

<center>

```{r Graphique_saisonnalite_hebdomadaire, include=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# Base des jours de non-vacances
saison_hebdo_nonVac = df.gr.jour[df.gr.jour$nb_zones == 0,] %>% 
  group_by("Jour" = JourSem) %>% 
  summarise(Consommation = round(mean(Consommation, na.rm=TRUE), 2))
saison_hebdo_nonVac$Periode = "Classique"

# Base des jours de vacances
saison_hebdo_Vac =  df.gr.jour[df.gr.jour$nb_zones > 0,] %>% 
                                group_by("Jour" = JourSem) %>% 
                                summarise(Consommation = round(mean(Consommation, na.rm=TRUE), 2))
saison_hebdo_Vac$Periode = "Vacances"

# Base des jours fériés
saison_hebdo_JF = data.frame("Jour" = "jours fériés", 
                             "Consommation" = round(mean(df.gr.jour[df.gr.jour$dummyJF == 1,]$Consommation), 2))
saison_hebdo_JF$Periode = "Autre"

# Regroupement des bases
saison_hebdo_completeVac = rbind(saison_hebdo_nonVac,saison_hebdo_Vac, saison_hebdo_JF)

# Construction graphique
graph_saison_hebdoVac <- ggplot(data=saison_hebdo_completeVac, aes(x=Jour, y=Consommation, fill = Periode)) + 
                              geom_bar(stat="identity",  position=position_dodge()) + 
  
                              geom_text(aes(label=Consommation), # Ajout étiquettes
                                        vjust=-1., color="black", 
                                        position = position_dodge(1), size=3.5) +
  
                              coord_cartesian(ylim=c(32,44)) + # Zoom
                              theme(legend.position="bottom") + # Position de la légende
                              
                              # Labels des titres et axes
                              labs(title = "Consommation journalière moyenne d'électricité",
                                   subtitle = "Moyenne journalière entre le 01/01/2016 et le 31/12/2019", 
                                   x = "", 
                                   y="Consommation électrique (GW)") +
  
                              # Choix manuel des couleurs
                              scale_fill_manual(values=c(jaune1, bleu1, rouge1)) +
  
                              # Changer l'ordre des éléments sur l'axe x
                              scale_x_discrete(limits=c("lundi", "mardi", 
                                                        "mercredi", "jeudi", 
                                                        "vendredi", "samedi", 
                                                        "dimanche", "jours fériés"))

# Affichage du graphique
graph_saison_hebdoVac
```

</center>

\

Enfin, la troisième saisonnalité qui existe dans les données est une **saisonnalité horaire**. C'est à nouveau facile à comprendre, la consommation électrique varie au cours de la journée : on ne consomme pas, en moyenne, la même chose à midi et à minuit. Pour le voir, on représente de nouveau graphiquement la moyenne de la consommation par créneau horaire. Ce motif se répète, en moyenne, chaque jour, créant ainsi une troisième saisonnalité dans les données. Évidemment, cette saisonnalité n'est visible que si l'on travaille avec des données non-synthétisées, c'est à dire observées au pas-3h. 

\

<center>

```{r Graphique_saisonnalite_horaire, include=TRUE, echo = FALSE, warning=FALSE, message=FALSE}
# Construction d'un graphique permettant de visualiser la saisonnalité hebdomadaire
# Création d'une base
saison_journalier = df %>% group_by(Creneau) %>% summarise(Conso = round(mean(Consommation, na.rm=TRUE), 2))
saison_journalier$Creneau<-as.factor(saison_journalier$Creneau)

# Construction graphique
graph_saison_journalier <- ggplot(data=saison_journalier, aes(x=Creneau, y=Conso)) + 
                            # Ajout du format barplot
                            geom_bar(stat="identity", fill=bleu1) + 
  
                            coord_cartesian(ylim=c(32,45)) + # Zoom
                            geom_text(aes(label=Conso), vjust=-1., color="black", size=3.5) +
                            labs(title = "Consommation horaire moyenne d'électricité",
                                 subtitle = "Moyenne horaire entre le 01/01/2016 00:00 et le 31/12/2019 21:00", 
                                 x = "Heure de la journée", 
                                 y="Consommation électrique (GW)")  
# Affichage du graphique
graph_saison_journalier
```

</center>

\

### Analyse du lien entre variables météo et demande d'électricité
#### Effet(<u>s</u>) de la température 

Dans le point précédent, nous avons profité de l'analyse des saisonnalités pour souligner l'effet non-nul de nos variables calendaires sur la consommation électrique, en moyenne. Il ne reste plus pour cette partie d'analyse descriptive qu'à faire la même chose avec nos données météorologiques. 

Commençons par la variable la plus importante : **la température moyenne**. Traçons tout d'abord un graphique double, sur lequel on représente à la fois la courbe de la consommation d'électricité, et la courbe de la température. Pour plus de lisibilité, on utilise les données synthétisées à la semaine, mais les résultats seraient équivalents avec une fréquence de données plus élevée. Sur ce graphique, on remarque tout de suite une symétrie en miroir entre les deux courbes : lorsque la température est faible, la demande d'électricité est importante, et vice versa. 

\

<center>

```{r Electricite_Temp_Graph, include=TRUE, echo = FALSE, warning=FALSE, message=FALSE}
autoplot(ts.intersect("Conso. électrique (GW)" = ts_semaine,
                      "Température (°C)" = ts(df.gr.semaine$Temp, frequency = 52, start = c(2016,01))),
         facets = TRUE) +
  labs(title="Consommation électrique et température moyenne", 
       subtitle = "Données hebdomadaires",
       x = "Temps", y = "")
```

</center>

\

```{r Electricite_Temp_Graph_Hiver1, include=FALSE}
# Création d'une sous-base pour l'hiver
df.gr.jour.hiver = df.gr.jour[df.gr.jour$Mois %in% c(1,2),]
df.gr.jour.hiver = df.gr.jour.hiver %>% group_by(Mois, Jour) %>% summarise(
  Temp = mean(Temp),
  Conso = mean(Consommation))
```

**La relation entre nos deux variables est-elle pour autant aussi simple ?** Séparons notre analyse en deux, en reproduisant ce graphique, cette fois seulement pour les mois hivernaux (fixons janvier et février), puis pour les mois d'été (juillet et août). On utilise cette fois les données journalières, car il y a moins d'observations à afficher. Pour l'hiver, on obtient la représentation suivante. La dynamique est bien celle que l'on avait observé sur le graphique précédent. Lorsque la température est faible, la demande d'électricité est élevée. On calcule le coefficient de corrélation entre nos deux séries, qui est en effet égal à `r round(cor(df.gr.jour.hiver$Conso, df.gr.jour.hiver$Temp),2)`. 

\

<center>

```{r Electricite_Temp_Graph_Hiver2, include=TRUE, echo = FALSE, warning=FALSE, message=FALSE}
autoplot(ts.intersect("Conso. électrique (GW)" = ts(df.gr.jour.hiver$Conso),
                      "Température (°C)" = ts(df.gr.jour.hiver$Temp)),
                      facets = TRUE) +
    labs(title="Consommation électrique et température moyenne en hiver", 
       subtitle = "Données journalières moyennes pour les mois de janvier et février",
       x = "Temps", y = "")
```

</center>

\

```{r Electricite_Temp_Graph_Ete1, include=FALSE}
# Création d'une sous-base pour l'été
df.gr.jour.ete = df.gr.jour[df.gr.jour$Mois %in% c(7,8),]
df.gr.jour.ete = df.gr.jour.ete %>% group_by(Mois, Jour) %>% summarise(
  Temp = mean(Temp),
  Conso = mean(Consommation))
```

\

Reproduisons cela pour l'été. Cette fois la dynamique n'est plus du tout la même : lorsque la température augmente ... la consommation électrique augmente également ! Cette demande d'électricité plus forte est liée très certainement à une utilisation plus importante des climatiseurs par exemple, gourmands en électricité. Cette fois, le coefficient de corrélation entre nos deux séries est positif, et égal à `r round(cor(df.gr.jour.ete$Conso, df.gr.jour.ete$Temp),2)`

\

<center>

```{r Electricite_Temp_Graph_Ete2, include=TRUE, echo = FALSE, warning=FALSE, message=FALSE}
autoplot(ts.intersect("Conso. électrique (GW)" = ts(df.gr.jour.ete$Conso),
                      "Température (°C)" = ts(df.gr.jour.ete$Temp)),
                      facets = TRUE) + 
      labs(title="Consommation électrique et température moyenne en été", 
       subtitle = "Données journalières moyennes pour les mois de juillet et août",
       x = "Temps", y = "")
```

</center>

\

`r colorize("**Ainsi, l'effet de la température sur la demande d'électricité n'est pas linéaire**", rouge1)`. Le graphique ci-dessous permet de confirmer cela, avec une courbe de l'ensemble de nos observations tendant vers une forme en U. Cet effet non linéaire de la température sur notre variable à prévoir sera à garder en tête tout au long de notre modélisation, et à prendre en compte dans cette dernière. 

\

<center>

```{r Electricite_Temp_Graph_global, include=TRUE, echo = FALSE, warning=FALSE, message=FALSE}
qplot(temp, Consommation, data=df) +
      labs(title="Consommation électrique et température", 
       subtitle = "Données complètes",
       x = "Température (°C)", y = "Consommation électrique (GW)")
```

</center>

\

#### Effets des autres variables météorologiques 

Pour nos deux autres variables météorologiques que sont **le taux d'humidité** et **la couverture nuageuse**, l'effet sur la consommation d'électricité apparaît de manière moins claire que pour la température. Bien que les coefficients de corrélation entre demande d'électricité et humidité et entre demande d'électricité et couverture nuageuse soient respectivement de `r round(cor(df.gr.semaine$Consommation, df.gr.semaine$Hum),2)` et `r round(cor(df.gr.semaine$Consommation, df.gr.semaine$Cover),2)`, l'effet graphique est moins flagrant. On représente ci-dessous nos trois courbes. Cependant, nous étudierons tout de même l'effet potentiel de ces variables lors de notre exercice de modélisation. 

\

<center>

```{r Electricite_AutreMeteo_Graph, include=TRUE, echo = FALSE, warning=FALSE, message=FALSE}
autoplot(ts.intersect("Conso. (GW)" = ts_semaine,
                      "Couverture" = ts(df.gr.semaine$Cover, frequency = 52, start = c(2016,01)),
                      "Humidité" = ts(df.gr.semaine$Hum, frequency = 52, start = c(2016,01))),
         facets = TRUE) + 
      labs(title="Consommation électrique, couverture nuageuse et taux d'humidité", 
       subtitle = "Données hebdomadaires",
       x = "Temps", y = "")
```

</center>

\
\
\
\

# Analyses, modélisations et prévisions

---

Notre analyse va s'organiser de manière pyramidale : nous commençons par étudier les séries les plus synthétisées, pour lesquelles beaucoup d'information est perdue, mais qui ont le mérite d'éviter tout problème de saisonnalités multiples. Puis nous nous intéresserons progressivement à des séries de plus en plus fines, permettant de conserver plus d'information sur la consommation d'électricité, mais au prix d'une réflexion plus poussée quant à la modélisation de ces séries. 

Pour modéliser ces dernières, nous avons voulu essayer de mettre en place des modèles SARMA multiples, c'est-à-dire permettant de capturer plusieurs saisonnalités. Nous avons ainsi développé un outil d'analyse adéquat, présenté "sommairement" dans la partie à suivre, et beaucoup plus en détail en annexe de ce rapport. Comme cela a déjà été dit en introduction, cette outil constitue une part importante de notre travail, et nous avons à cœur de le présenter de la manière la plus claire et la plus complète qui soit à nos lecteurs. 

Une fois cet outil présenté, nous nous intéresserons (modélisation et prévisions) successivement : 

- À la synthèse mensuelle de la consommation d'électricité
- À la synthèse hebdomadaire de cette même consommation
- À la synthèse journalière de la consommation d'électricité

\
\

## Principe et algorithme d'un modèle SARMA multiple

### Principe théorique

Comment prendre en compte plusieurs saisonnalités dans un modèle SARMA ? La réponse est en apparence simple : il suffit d'ajouter des polynômes au modèle. Comment cela se traduit-il mathématiquement ? Pour le comprendre, partons d'un modèle SARMA simple.

\

#### Modèle SARMA simple

Lorsque l'on combine coefficients saisonniers et processus ARMA, le modèle type peut s'écrire de la façon suivante : 

\

$$
\Phi(L) \Phi_s(L^s)\left(X_t - \mu\right) = \Theta(L) \Theta_s(L^s) \varepsilon_t \ ,
$$

\

où l'on reconnaît les polynômes $\Phi(L)$ et $\Theta(L)$ comme les composants non-saisonniers du processus ARMA, et où $\Phi_s(L^s)$ et $\Theta_s(L^s)$ sont des polynômes qui ne font intervenir que des retards multiples de la fréquence $s$. Par exemple, pour une série saisonnière de fréquence 7, un modèle $\textrm{SARMA}(2,1)(1,0)[7]$ sans moyenne se développerait mathématiquement de la façon suivante : 

\

$$
\underbrace{(1-\phi_1L - \phi_2L^2)}_{\Phi(L)} \times \underbrace{(1 - \phi_7L^7)}_{\Phi_s(L^s)} \times X_t = \underbrace{(1- \theta_1L)}_{\Theta(L)} \times \varepsilon_t  
$$

\

En développant l'expression ci-dessus, on obtient l'équation suivante : 

\

$$
X_t = \phi_1 X_{t-1} + \phi_2 X_{t-2} + \phi_7 X_{t-7} - \phi_1\phi_7 X_{t-8}  - \phi_2\phi_7X_{t-9} - \theta_1\varepsilon_{t-1} + \varepsilon_t
$$

\

L'idée clé derrière cette dernière équation, idée qui constituera le fondement de la construction algorithmique à venir, est la suivante : `r colorize("**tout modèle SARMA n'est en réalité qu'un modèle ARMA d'ordre élevé, et peut donc être estimé comme tel**", rouge1)`. À partir de cette idée, il est tout à fait possible d'ajouter des polynômes supplémentaires permettant de capturer plusieurs saisonnalités simultanément, et d'être de nouveau seulement face à un modèle ARMA d'ordre élevé. C'est ce que l'on fait dans les deux paragraphes suivants. 

\

#### Modèle SARMA double

Reprenons l'équation théorique précédente, et ajoutons deux nouveaux polynômes permettant de capturer une saisonnalité supplémentaire. On se place ainsi dans le cadre suivant : notre série comporte deux saisonnalités, la première est de fréquence $s_1$ et la seconde de fréquence $s_2$. Notre modèle SARMA double peut donc s'écrire : 

\

$$
\Phi(L) \times \Phi_{s_1}(L^{s_1}) \times \Phi_{s_2}(L^{s_2}) \times \left(X_t - \mu\right) = \Theta(L) \times \Theta_{s_1}(L^{s_1}) \times \Theta_{s_2}(L^{s_2}) \times \varepsilon_t 
$$

\

Pour ce nouveau type de modèles, on introduit une nouvelle notation, permettant d'identifier l'ordre des différentes composantes. Un modèle SARMA double s'écrira synthétiquement de la manière suivante : 

\

$$
\textrm{SARMA}(p,q)(p_{s_1}, q_{s_1})[s_1](p_{s_2}, q_{s_2})[s_2]
$$

\

Par exemple, un modèle SARMA double sur une série de saisonnalités 7 et 10, avec seulement des polynômes AR d'ordre 1, que ce soit pour la partie non-saisonnière ou les parties saisonnières s'écrira de la façon suivante : 

\

$$
\textrm{SARMA}(1,0)(1,0)[7](1,0)[10]
$$

\

Il ne resterait plus qu'à développer les polynômes afin d'identifier le processus ARMA (d'ordre 18, un lecteur attentif l'aura compris) qui se cache derrière ce SARMA double.

\

#### Modèle SARMA triple

Dans le même esprit, il est possible de construire des modèles SARMA permettant de capturer une triple saisonnalité. Pour cela, il suffit de rajouter un nouveau polynôme au modèle SARMA double. C'est ce que l'on fait dans l'équation ci-dessous :

\

$$
\Phi(L) \times \Phi_{s_1}(L^{s_1}) \times \Phi_{s_2}(L^{s_2}) \times \Phi_{s_3}(L^{s_3}) \times \left(X_t - \mu\right) = \Theta(L) \times \Theta_{s_1}(L^{s_1}) \times \Theta_{s_2}(L^{s_2}) \times \Theta_{s_3}(L^{s_3}) \times \varepsilon_t 
$$

\

De manière similaire à l'écriture d'un SARMA double, un SARMA triple peut se synthétiser de la façon suivante : 

\

$$
\textrm{SARMA}(p,q)(p_{s_1}, q_{s_1})[s_1](p_{s_2}, q_{s_2})[s_2](p_{s_3}, q_{s_3})[s_3]
$$

\

Il est intéressant de souligner un dernier point avant de passer à la partie suivante. On peut remarquer que tout modèle SARMA double est en fait un cas particulier du modèle SARMA triple avec $s_3 = p_{s_3} = q_{s_3} = 0$. Par extension, un modèle SARMA simple et même un modèle ARMA sans saisonnalité peuvent à nouveau être vus comme des modèle SARMA triples particuliers. Ainsi, si l'on arrive à construire une méthode algorithmique permettant d'estimer des modèles SARMA triples, cette méthode sera tout à fait utilisable pour estimer des modèles plus simples (ARMA, SARMA et SARMA double). 

\

### Mise en application

Le cadre théorique étant désormais présenté, comment estimer un modèle SARMA triple ? La théorie est "simple", il suffit d'estimer un ARMA défini à partir du développement des différents polynômes du modèle. L'enjeu est à présent de rendre possible cette estimation sur R et de permettre à l'utilisateur d'estimer de nombreux modèles SARMA triples "relativement rapidement", et en épargnant à ce dernier un maximum de calculs fastidieux. 

Pour concourir à cet objectif, nous avons créé une fonction, nommée `S3ARMA`, découpée en 4 sous-fonctions différentes, remplissant chacune un rôle bien précis. Elles sont pleinement expliquées et illustrées par des exemples sur des séries simulées en annexe de ce rapport, mais présentons-les rapidement. 

\

- `r colorize("**La fonction**", bleu1)``S3ARMA_part1` : L'objectif de cette fonction est l'estimation du modèle SARMA triple sur une série stationnaire. 
  - *Inputs* : Les paramètres du modèle (série à modéliser, ordres $p$, $q$, $p_{s_1}$, ..., $q_{s_3}$, moyenne)
  - *Outputs* : Le modèle ARMA correspondant correctement estimé
 
\

- `r colorize("**La fonction**", bleu1)``S3ARMA_part2` : Cette fonction a pour but de faciliter la lecture du résultat de la fonction précédente. Elle permet de n'afficher que les coefficients d'intérêt et d'analyser rapidement leur significativité. 

  - *Inputs* : Un modèle SARMA multiple estimé par la fonction `S3ARMA_part1`
  - *Outputs* : Les coefficients principaux et leur significativité

\

- `r colorize("**La fonction**", bleu1)``S3ARMA_part3` : La fonction `S3ARMA_part1` utilise en input une série stationnaire. Pour l'obtenir, il est fort probable que l'utilisateur ait différencié sa série initiale plusieurs fois. L'objectif de cette fonction `S3ARMA_part3` est ainsi de calculer correctement les prévisions pour la série initiale à partir du modèle estimé sur une série plusieurs fois différenciée. En résumé, la fonction dé-différencie les prévisions. 

  - *Inputs* : Un modèle estimé sur une série différenciée, la série initiale et les ordres de différenciation utilisés
  - *Outputs* : Les prévisions pour la série initiale

\
  
- `r colorize("**La fonction**", bleu1)``S3ARMA_part4` : Dernière partie de la fonction `S3ARMA`, la fonction `S3ARMA_part4` fait office de bonus. Elle n'est pas indispensable pour modéliser une série et la prévoir. Cette fonction est seulement pensée et conçue sur le modèle de la fonction `auto.arima`. Elle permet à l'utilisateur d'estimer automatiquement un ensemble de modélisations possibles sur une série, et de se voir retourner les meilleures d'entre elles. Elle est par exemple très utile lorsque l'on n'a aucune idée de la modélisation à adopter. 

  - *Inputs* : Une série à modéliser et un ensemble de modélisations à estimer (le bon format pour cet ensemble de possibles est fourni par la fonction)
  - *Outputs* : Le classement des meilleurs modèles parmi ceux estimés selon les critères AICc, nombre de paramètres estimés (afin de choisir un modèle le plus parcimonieux possible) et le nombre de coefficients significatifs. 


\
\

## Modélisation mensuelle

Après cette présentation théorique, passons à la modélisation ! Comme nous l'avons expliqué précédemment, on s'intéresse dans un premier temps à la **modélisation de la série de la consommation d'électricité synthétisée au mois**. Pour la suite, cette série sera notée `ts_mois`. Bien entendu, une telle synthèse fait perdre beaucoup d'information, mais constitue un bon point de départ pour notre analyse. La série temporelle synthétisée au mois comprend ainsi 48 observations, entre janvier 2016 et décembre 2019. Elle est représentée ci-dessous : 

\

<center>

```{r Graph_ts_mois, include=TRUE, echo=FALSE}
# Représentation de la série synthétisée au mois
autoplot(ts_mois) +
  labs(title = "Synthèse mensuelle de la consommation d'électricité en France",
       subtitle = "Moyennes mensuelles entre janvier 2016 et décembre 2019",
       x = "Temps", y = "Consommation électrique (GW)")
```

</center>

\

On retrouve bien la saisonnalité annuelle inhérente à notre série initiale. Nous proposons deux types de modélisation pour cette série : une modélisation univariée et une modélisation multivariée. Nous présentons en détails les différentes étapes de modélisation, d'estimation, de vérification et de prévision pour cette première série. Au fur et à mesure du projet, nous allégerons la rédaction afin de rendre la lecture plus agréable. 

\

### Analyse univariée de la série `ts_mois`

Commençons par une modélisation univariée de notre série. Étant donnée sa forte saisonnalité, nous penchons naturellement pour un modèle SARIMA. Afin de bien ordonner notre réflexion, nous suivons la méthode de Box et Jenkins (1970) pour notre analyse. 

\

#### Identification

La première étape de modélisation de la série `ts_mois` consiste à déterminer si la série est intégrée et quel est son ordre d'intégration. À première vue, la série n'est de toute évidence pas stationnaire, tant la saisonnalité annuelle est visible. On commence donc par différencier saisonnièrement notre série temporelle. La voici représentée ci-dessous, et notée `ts_mois_d`.

\

<center>

```{r Differenciation_ts_mois, include=FALSE}
# Différenciation saisonnière de la série ts_mois
ts_mois_d = diff(ts_mois, lag = 12)
```

```{r Graph_ts_mois_d, include=TRUE, echo = FALSE}
autoplot(ts_mois_d) +
  labs(title = "Série de la consommation mensuelle différenciée saisonnièrement",
       subtitle = "Saisonnalité de fréquence 12",
       x = "Temps", y = "Consommation électrique (GW)")
```

</center>

\

La question est désormais de savoir si cette série est stationnaire. Pour cela, nous procédons à un test de Dickey-Fuller formel. Bien que non indispensable dans ce cas, détailler ce premier test ADF correctement nous permettra d'alléger la rédaction pour les suivants. Afin de paramétrer le test ADF, nous observons l'ACF/PACF de la série `ts_mois_d` différenciée simplement. 

\
<center>

```{r, include=TRUE, echo=FALSE}
# ACF/PACF de la série diff(ts_mois_d)
aux <- acf2(diff(ts_mois_d), max.lag = 15)
```

</center>
\

Sur le PACF ci-dessus, le douzième retard est le dernier significativement différent de 0. On fixe ainsi `lags = 12` pour notre test de Dickey-Fuller. On le calcule ci-dessous, en utilisant notre fonction `fonction.ADF` (cette fonction n'est qu'une simple remise en forme des résultats du test obtenus par la commande `ur.df` du *package* `urca`). 

\

```{r Test_ADF_ts_mois, include=TRUE, echo=FALSE}
fonction.ADF(ts_mois_d, lags = 12)
```

\

La statistique de test `tau3` est égale à -6.31 et est largement inférieure à la valeur critique à 1%, -4.15. On peut donc rejeter l'hypothèse nulle du test au seuil de 1%, à savoir la présence d'une racine unité. Notre série différenciée saisonnièrement est donc stationnaire. 

Il s'agit à présent de déterminer le meilleur modèle SARIMA pour la capture de la dynamique de notre série. Pour cela, observons l'ACF/PACF de notre série.

\

<center>

```{r, include=TRUE, echo=FALSE}
# ACF/PACF de la série ts_mois_d
aux<-acf2(ts_mois_d, max.lag = 26)
```

</center>

\

Sur l'ACF comme sur le PACF, on observe un pic significatif au 12ème retard, mais pas au 24ème. Ainsi, l'ordre de la partie saisonnière, qu'il s'agisse de la partie AR ou MA ne devrait pas dépasser 1. Aucun coefficient d'autocorrélation ou d'autocorrélation partielle n'est significativement différent de 0 en début d'ACF/PACF. Il semble donc que la partie non-saisonnière de notre SARMA soit nulle. On choisit donc la modélisation suivante pour notre série `ts_mois`:

$$
\textrm{SARIMA}(0,0,0)(1,1,0)[12]
$$

\

#### Estimation

Nous estimons ce modèle et nous obtenons le résultat ci-dessous. Notre coefficient AR saisonnier est significatif, nous sommes donc à ce stade satisfaits de notre modélisation.

\

```{r, include=TRUE, echo=FALSE}
# Modélisation SARIMA de la série `ts_mois`
order_sarima = c(0,0,0)
seasonal_sarima = c(1,1,0)
mean_sarima = FALSE

sarma_ts_mois <- Arima(ts_mois,
                       order=order_sarima, 
                       seasonal = seasonal_sarima,
                       include.constant = mean_sarima, 
                       method="CSS-ML")
sarma_ts_mois
```

\

#### Vérification

Notre modèle étant désormais estimé, il s'agit de procéder à plusieurs étapes de vérification. La première consiste à vérifier que nos ordres non-saisonniers et saisonniers sont bien choisis. Pour cela, nous les augmentons successivement d'une unité chacun, et observons qu'aucun de ces modèles alternatifs n'est significatif. Nous confirmons donc notre modélisation $\textrm{SARIMA}(0,0,0)(1,1,0)[12]$. 

Il ne reste plus qu'à vérifier les résidus du modèle, ce que nous faisons grâce à la commande `checkresiduals`. Le résultat est présenté ci-dessous. Le test de Ljung-Box sur les résidus nous confirme qu'ils sont assimilables à un bruit blanc. Leur faible nombre ne permet cependant pas de savoir clairement s'ils sont normalement distribués.

\

```{r Verification_residus_SARMA_ts_mois, include=TRUE, echo = FALSE}
# Vérification des résidus du modèle `sarma_ts_mois`
checkresiduals(sarma_ts_mois, plot = FALSE)
```

<center>

```{r Verification_residus_SARMA_ts_mois_bis, include=TRUE, echo = FALSE}
# Vérification des résidus du modèle `sarma_ts_mois`
checkresiduals(sarma_ts_mois, test = FALSE)
```

</center>

\

#### Conclusion de l'analyse univariée

Nous sommes ainsi à ce stade satisfaits de notre modélisation de la série `ts_mois` par un modèle $\textrm{SARIMA}(0,0,0)(1,1,0)[12]$. Les coefficients du modèle sont significatifs, il n'y a pas d'autocorrélation dans les résidus du modèle, et ces derniers semblent normalement distribués. 

\
\

### Analyse multivariée de la série `ts_mois`

On poursuit notre analyse par une modélisation multivariée de notre série `ts_mois`. Bien entendu, ce n'est pas pour cette série que la modélisation multivariée est la plus intéressante, mais cela permet de poser les bases de la méthode et de comparer les approches. 

\

#### Régression linéaire

On commence par régresser notre série temporelle de la consommation mensuelle d'électricité sur différentes séries. Nous proposons les régresseurs suivants : la température, l'humidité, et la couverture nuageuse mensuelles moyennes, le nombre de jours fériés dans le mois, et la somme du nombre de jours de vacances des zones (A, B, C) par mois. Seules cette dernière variable et la température moyenne mensuelle sont significatives (resp. à 5% et 1%)

\

```{r ts_mois_Regression1, include=TRUE, echo=FALSE}
# Régression linéaire
reg1 <- lm(Consommation ~ Temp + nb_zones, data = df.gr.mois)
summary(reg1)
```

\

#### Modélisation des résidus

Il s'agit à présent de modéliser les résidus de notre régression. On commence par étudier la stationnarité de ces derniers. On ne détaille pas toute l'analyse ici, cela a déjà été fait pour la modélisation univariée de la série. 

*Note : Nous utilisons pour gagner du temps les fonctions `ndiffs` et `nsdiffs` proposées par Rob J. Hyndman and George Athanasopoulos dans l'ouvrage* Forecasting: Principles and Practice*. Elles reposent respectivement sur les statistiques de test KPSS et sur une mesure de la force de la saisonnalité. En cas de doute, nous sommes bien entendus revenus au test ADF manuel.*

```{r, include = FALSE, echo=FALSE}
# On récupère les résidus
res = ts(residuals(reg1), frequency = 12)

# Analyse de la stationnarité des résidus
print(paste("Nombre de différenciations simples requises :", ndiffs(res)))
print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(res)))

res_d = diff(res, lag = 12)

# Analyse de la stationnarité des résidus différenciés
print(paste("Nombre de différenciations simples requises :", ndiffs(res_d)))
print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(res_d)))
```

Les résidus doivent être différenciés saisonnièrement. Nous le faisons, et traçons ci-dessous l'ACF/PACF de la série des résidus différenciée.

\
<center>

```{r ACF_residus_regression, include=TRUE, echo=FALSE}
# ACF/PACF des résidus différenfiés
aux <- acf2(res_d, max.lag = 25)
```

</center>
\

Sur l'ACF/PACF ci-dessus, on observe que seul le coefficient d'autocorrélation d'ordre 12 est significativement différent de 0, traduisant une saisonnalité à prendre en compte dans la modélisation. Sur le PACF, aucun coefficient ne semble significativement différent de 0. Nous optons donc pour une modélisation $\textrm{SARIMA}(0,0,0)(1,1,0)[12]$ pour notre série des résidus de la régression. Nous estimons ce modèle, et nous obtenons un coefficient AR saisonnier significatif. Nous entamons ensuite une phase de vérification similaire à ce que nous avions fait pour la modélisation univariée. En augmentant successivement d'une unité les autres paramètres du modèle, nous n'obtenons aucune alternative à notre modélisation initiale qui ne soit significative. De plus, les résidus de cette modélisation sont assimilable à un bruit blanc, d'après le résultat du test de Ljung-Box et au regard de leur distribution qui apparaît comme normale. Nous sommes donc satisfaits de notre modélisation.

```{r SARMA_residus_reg1, include=FALSE}
# Modélisation SARIMA des résidus de la régression
order_arimax_res = c(0,0,0)
seasonal_arimax_res = c(1,1,0)
mean_arimax_res = FALSE

sarma_residus_reg1 = Arima(res,
                            order = order_arimax_res,
                            seasonal = seasonal_arimax_res,
                            include.mean = mean_arimax_res)
sarma_residus_reg1
checkresiduals(sarma_residus_reg1)
```

\

#### Modèle ARIMAX

Les résidus de la régression étant désormais modélisés correctement, nous disposons de toutes les informations nécessaires pour construire notre modèle ARIMAX. Pour cela, nous utilisons le code suivant (nous présentons ici le code car il s'agit de notre première modélisation ARIMAX, nous ne le ferons pas pour les nombreuses modélisations suivantes) : 

```{r ARIMAX_ts_mois, include=TRUE}
# Modélisation type ARIMAX
# Ordre du modèle
order_arimax_res = c(0,0,0)
seasonal_arimax_res = c(1,1,0)
mean_arimax_res = FALSE

# Régresseurs du modèle
regresseurs_arimax = data.frame("Temperature" = df.gr.mois$Temp, 
                                "Nb_Zones" = df.gr.mois$nb_zones)

# Estimation du modèle ARIMAX
arimax_ts_mois = Arima(ts_mois,
                        xreg = as.matrix(regresseurs_arimax),
                        order = order_arimax_res,
                        seasonal = seasonal_arimax_res,
                        include.mean = mean_arimax_res,
                        method = "CSS-ML")
# Résultats
arimax_ts_mois
```

```{r Verification_residus_ARIMAX, include=FALSE}
checkresiduals(arimax_ts_mois)
```

\

Notre modélisation est de nouveau satisfaisante. Les résidus issus de cette dernière ne présentent pas d'autocorrélation (le test de Ljung-Box nous retourne une *p*-valeur de 7%), et les résidus semblent plutôt normalement distribués, bien que leur faible nombre ne permet pas de conclure clairement sur ce point. 

\
\

### Comparaison des modèles

Nous avons donc désormais estimé l'ensemble de nos modèles. On souhaite à présent sélectionner le meilleur d'entre eux. Pour cela, on divise la série en un échantillon d'entraînement (75%) et un échantillon de test (25%). On ré-estime chacun de nos modèle sur l'échantillon d'entraînement, et l'on calcule à partir de cela des prévisions pour un horizon temporel égal à la longueur de l'échantillon de test. À partir de ces prévisions, on calcule différentes mesures de précision sur l'échantillon d'entraînement et de test. On ne retient que le RMSE et le MAPE, que l'on compare principalement sur l'échantillon de test (c'est en effet sur cet échantillon que le modèle "prédit vraiment"). 

\

```{r Qualite_previsions_ts_mois, include=TRUE, echo=FALSE, collapse=TRUE}
# Définition des échantillons de test et d'entrainement
serie = ts_mois
train_set = head(serie, length(serie) * 0.75)
test_set = tail(serie, length(serie) * 0.25)

regresseurs_arimax_train = head(regresseurs_arimax, nrow(regresseurs_arimax) * 0.75)
regresseurs_arimax_test = tail(regresseurs_arimax, nrow(regresseurs_arimax) * 0.25)

# Ré-estimation du modèle SARIMA
sarma_ts_mois_train =Arima(train_set, 
                           order = order_sarima,
                           seasonal = seasonal_sarima,
                           include.mean = mean_sarima,
                           method = "ML")

# Ré-estimation du modèle ARIMAX
arimax_ts_mois_train = Arima(train_set,
                        xreg = as.matrix(regresseurs_arimax_train),
                        order = order_arimax_res,
                        seasonal = seasonal_arimax_res,
                        include.mean = mean_arimax_res,
                        method = "CSS-ML")

# Calcul des prévisions
fc_sarma_ts_mois_test = forecast(sarma_ts_mois_train, h=length(test_set))
fc_arimax_ts_mois_test = forecast(arimax_ts_mois_train, h=length(test_set), 
                                  xreg = as.matrix(regresseurs_arimax_test))

# Précision des modèles
cat("####################################################",
    "\n# Comparaison de la qualité prédictive des modèles #",
    "\n####################################################")

cat("\n\nModèle univarié (SARIMA) :", "\n-------------------------- \n")
round(accuracy(fc_sarma_ts_mois_test, serie)[,c("RMSE","MAPE")],2)

cat("\nModèle multivarié (ARIMAX) :", "\n---------------------------- \n")
round(accuracy(fc_arimax_ts_mois_test, serie)[,c("RMSE","MAPE")],2)
```

\

Nos deux modèles présentent de bons scores de précision. Pour le modèle univarié, le RMSE sur l'échantillon de test est de 1.40, pour un MAPE de 2.64%. Pour le modèle multivarié, le RMSE est de 1.05, et le MAPE de 2.31%. Ainsi, le modèle multivarié semble présenter de meilleures capacités prédictives que le modèle univarié, bien que l'écart ne soit pas massif entre les deux. Nous représentons ci-dessous les prévisions obtenues à partir de chacune des modélisations, pour l'année 2020 (horizon temporel de 12 mois donc). 

\
<center>

```{r Prevision_ts_mois, include = TRUE, echo = FALSE}
# Prévisions à 1 an de la consommation synthétisée au mois
regresseurs_arimax_2020 = data.frame("Temperature" = df.gr.mois.2020$Temp, 
                                     "Nb_Zones" = df.gr.mois.2020$nb_zones)

previsions_sarma_ts_mois = forecast(sarma_ts_mois, h=12)
previsions_arimax_ts_mois = forecast(arimax_ts_mois, h=12, 
                                     xreg = as.matrix(regresseurs_arimax_2020))

# Construction graphique
autoplot(ts_mois) +
  labs(title = "Prévisions à 12 mois de la consommation mensuelle d'électricité",
       subtitle = "Deux modèles sont possibles pour les prévisions",
       x = "Temps", y = "Consommation électrique (GW)") +

  autolayer(previsions_sarma_ts_mois, PI=FALSE, serie = "SARIMA", size = 1) +
  autolayer(previsions_arimax_ts_mois, PI=FALSE, serie = "ARIMAX", size = 1) +
  
  theme(legend.position="bottom", 
        legend.title = ) +
  scale_color_manual(values=c("#2471A3", "#CB4335")) 
```

</center>
\

### Conclusion pour la synthèse mensuelle de la consommation d'électricité

Nous l'avons vu, nos deux modélisations (SARIMA et ARIMAX) sont satisfaisantes pour la prévision de la consommation mensuelle d'électricité en France. Si nous ne devions en retenir qu'une, nous choisirions la modélisation SARIMA. Bien que présentant des capacités prédictives légèrement plus faibles, elle présente l'avantage d'être plus significative, et surtout elle ne repose pas sur un scénario. Il ne faut en effet pas oublier que le modèle ARIMAX nécessite des valeurs pour les régresseurs en 2020. Pour les variables de calendrier, aucune incertitude sur les valeurs futures. Par contre, nous utilisons une moyenne pour la prévision de la température. Or, rien ne dit avec certitude que les températures de 2020 correspondront exactement à la moyenne des températures des 4 années précédentes. Ainsi, à l'incertitude propre au modèle, il faut garder en tête l'incertitude pré-existante dans les valeurs futures de certains régresseurs, qui ne sont alors qu'un scénario possible. 

\
<center>

```{r, include=TRUE, echo=FALSE}
autoplot(previsions_sarma_ts_mois) +
  labs(title = "Prévisions à 12 mois de la consommation mensuelle d'électricité",
       subtitle = "Modèle SARIMA(0,0,0)(1,1,0)[12]",
       x = "Temps", y = "Consommation électrique (GW)")
```
</center>


\
\
\
\

## Modélisation hebdomadaire

On s'intéresse désormais à la série de la consommation d'électricité synthétisée à la semaine. Cette échelle plus fine devrait nous permettre de gagner en précision dans nos prévisions, tout en évitant encore tout problème de saisonnalité multiple. En effet, à l'échelle hebdomadaire, la saisonnalité reste annuelle. On représente ci-dessous la série synthétisée à la semaine, que l'on notera désormais `ts_semaine`. Il va donc s'agir une fois de plus de modéliser au mieux cette série, à la fois de manière univariée et multivariée. 

*Note : Comme expliqué plus haut, les grandes étapes de l'analyse et de la modélisation sont identiques à celle de la série synthétisée au mois. Ainsi, nous épargnons au lecteur un certain nombre d'étapes, que nous réalisons bien entendu dans le code R.*

\

<center>

```{r Graph_ts_semaine, include=TRUE, echo=FALSE}
# Représentation de la série synthétisée au mois
autoplot(ts_semaine) +
  labs(title = "Synthèse hebdomadaire de la consommation d'électricité en France",
       subtitle = "Observations entre janvier 2016 (semaine 1) et décembre 2019 (semaine 52)",
       x = "Temps", y = "Consommation électrique (GW)")
```

</center>

\

### Analyse univariée de la série `ts_semaine` 

Commençons par une modélisation univariée de la série temporelle `ts_semaine`, toujours en suivant les grandes étapes de la procédure de Box et Jenkins. 

\

#### Identification

On remarque rapidement que la série n'est pas stationnaire : la forte saisonnalité qui la caractérise nous pousse à la différencier saisonnièrement. Nous effectuons des tests pour savoir si la série différenciée saisonnièrement (lag = 52) est désormais stationnaire. Les tests nous confirment cette hypothèse. Nous travaillons donc désormais à la modélisation de la série différenciée saisonnièrement. 

```{r Differenciation_ts_semaine, include=FALSE}
# Différenciation de la série `ts_semaine`
print(paste("Nombre de différenciations simples requises :", ndiffs(ts_semaine)))
print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(ts_semaine)))

# Différenciation
ts_semaine_d = diff(ts_semaine, lag=52)

# Analyse de la stationnarité de la série différenciée
print(paste("Nombre de différenciations simples requises :", ndiffs(ts_semaine_d)))
print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(ts_semaine_d)))
```

Pour cela, on trace l'ACF/PACF de cette dernière. Il est représenté ci-dessous. On observe assez nettement la saisonnalité apparaître sur l'ACF, avec un coefficient d'autocorrélation significativement différent de 0 pour le retard 56. De plus, on note sur le PACF la présence de trois coefficients significativement différents de 0 pour les retards 1, 3 et 4. On choisit donc la modélisation de départ suivante pour notre série : 

<center> 

$\textrm{SARIMA}(4,0,0)(1,1,0)[52]$

\

```{r ACF_sarma_ts_semaine, include=TRUE, echo=FALSE}
# ACF/PACF de la série ts_semaine_d
aux<-acf2(ts_semaine_d, max.lag = 60)
```

</center>

\

#### Estimation et vérification

On estime ce modèle sur notre série. Tous les coefficients du modèle sont significatifs, et il n'y a aucun problème de racine unité. Cependant, le test de Ljung-Box permet de rejeter l'hypothèse nulle au seuil 5%, il semble donc qu'il reste de l'autocorrélation dans nos résidus. Ces derniers sont néanmoins distribués normalement. Nous passons à la phase de vérification. 

```{r SARMA_ts_semaine, include=FALSE}
# Modélisation SARIMA de la série `ts_semaine`
order_sarima = c(4,0,0)
seasonal_sarima = c(1,1,0)
mean_sarima = FALSE

# Estimation du modèle
sarma_ts_semaine <- Arima(ts_semaine,
                           order=order_sarima, 
                           seasonal = seasonal_sarima,
                           include.constant = mean_sarima, 
                           method="CSS-ML")

# Résultats et vérification
sarma_ts_semaine
checkresiduals(sarma_ts_semaine)
```

En faisant varier successivement d'une unité les coefficients du modèle, il apparaît qu'ajouter un terme MA(1) non-saisonnier est requis. En effet, avec un modèle $\textrm{SARIMA}(4,0,1)(1,1,0)[52]$, tous les coefficients sont significatifs, le modèle gagne en précision (AICc plus faible), et les propriétés sont plus intéressantes. En effet, on ne peut cette fois rejeter l'hypothèse nulle du test de Ljung-Box qu'au seuil 10% (*p*-valeur à 6%). Les résidus du modèles sont bien assimilables à un bruit blanc, et semblent normalement distribués.

```{r SARMA_ts_semaine_bis, include=FALSE}
# Modélisation bis SARIMA de la série `ts_semaine`
order_sarima = c(4,0,1)
seasonal_sarima = c(1,1,0)
mean_sarima = FALSE

# Estimation du modèle
sarma_ts_semaine <- Arima(ts_semaine,
                           order=order_sarima, 
                           seasonal = seasonal_sarima,
                           include.constant = mean_sarima, 
                           method="CSS-ML")

# Résultats et vérification
sarma_ts_semaine
checkresiduals(sarma_ts_semaine)
```

\

#### Conclusion de l'analyse univariée

Ainsi, nous adoptons le modèle $\textrm{SARIMA}(4,0,1)(1,1,0)[52]$ comme modélisation univariée finale de notre série. Nous sommes globalement satisfaits de ce premier résultat.  

\
\

### Analyse multivariée de la série `ts_semaine`

Comme précédemment, on poursuit notre analyse par une modélisation multivariée de notre série `ts_semaine`.

\

#### Régression linéaire

On régresse notre série temporelle de la consommation hebdomadaire d'électricité sur différentes séries. Nous proposons de nouveau les régresseurs suivants : la température, l'humidité, et la couverture nuageuse hebdomadaires moyennes, le nombre de jours fériés par semaine, et la somme du nombre de jours de vacances des zones (A, B, C) par semaine.  

Cette fois, la température et le nombre de jours fériés sont tous les deux significatifs à 1%. Nous conservons donc cette régression, dont nous allons essayer de modéliser les résidus. 

```{r ts_Semaine_Regression1, include=TRUE, echo=FALSE}
# Régression pour la consommation à la semaine
reg1 <- lm(Consommation ~ Temp + dummyJF, data = df.gr.semaine)
summary(reg1)
```

\

#### Modélisation des résidus

Il s'agit à présent de modéliser les résidus de notre régression. On commence par étudier la stationnarité de ces derniers. Il en retourne que les résidus ne sont pas stationnaires, et doivent être différenciés une fois pour le devenir. Une fois cela fait, nous traçons leur ACF/PACF, visible ci-dessous. 

\

<center>

```{r Stationnarite_residus_reg_ts_semaine, include = FALSE, echo=FALSE}
# On récupère les résidus
res = ts(residuals(reg1), frequency = 52)

# Analyse de la stationnarité des résidus
print(paste("Nombre de différenciations simples requises :", ndiffs(res)))
print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(res)))

res_d = diff(res, lag = 52)

print(paste("Nombre de différenciations simples requises :", ndiffs(res_d)))
print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(res_d)))
```

```{r ACF_residus_regression_ts_semaine, include=TRUE, echo=FALSE}
# ACF/PACF des résidus de la régression
aux <- acf2(res_d, max.lag = 60)
```

</center>

\

L'observation de la figure ci-dessous nous laisse penser à un modèle SARMA, car on observe un pic très significatif à l'ordre 52 sur l'ACF et le PACF. De plus, sur les deux graphiques nous observons des pics significativement différents de 0 pour les retards 1 et 3. Nous partons donc sur une modélisation : 

<center>
$\textrm{SARIMA}(3,0,0)(1,1,0)[52]$
</center>

\

Nous estimons ce premier modèle, et nous constatons que les coefficients sont bien significatifs. Les résidus du modèle sont normalement distribués, et ne présentent pas d'autocorrélation (*p*-valeur de 76% pour le test de Ljung-Box). Pour vérifier notre modélisation, nous augmentons successivement les ordres du modèle d'une unité, mais aucune de ces modélisations alternatives n'est significative. Nous conservons donc notre modèle $\textrm{SARIMA}(3,0,0)(1,1,0)[52]$. 

```{r SARMA_residus_reg1_ts_semaine, include=FALSE}
# Modélisation SARIMA des résidus de la régression
order_arimax_res = c(3,0,0)
seasonal_arimax_res = c(1,1,0)
mean_arimax_res = FALSE

# Estimation du modèle
sarma_residus_reg1 = Arima(res,
                           order = order_arimax_res,
                           seasonal = seasonal_arimax_res,
                           include.mean = mean_arimax_res,
                           method = "CSS-ML")

# Résultats
sarma_residus_reg1
checkresiduals(sarma_residus_reg1)
```

\

#### Modèle ARIMAX

Nous modélisons donc notre série `ts_semaine` en utilisant le résultat précédent sur la modélisation des résidus. Nous obtenons le résultat suivant : 

\

```{r ARIMAX_ts_semaine, include=TRUE, echo=FALSE}
# Régresseurs du modèle
regresseurs_arimax = data.frame("Temperature" = df.gr.semaine$Temp, 
                                "JoursFeries" = df.gr.semaine$dummyJF)

# Estimation du modèle ARIMAX
arimax_ts_semaine = Arima(ts_semaine,
                        xreg = as.matrix(regresseurs_arimax),
                        order = order_arimax_res,
                        seasonal = seasonal_arimax_res,
                        include.mean = mean_arimax_res,
                        method = "CSS-ML")
# Résultats
arimax_ts_semaine
```

\

Tous les coefficients du modèle sont significatifs, et l'on peut noter que le signe de nos régresseurs est conforme à notre intuition. La température et le nombre de jours fériés dans la semaine jouent négativement sur la consommation moyenne d'électricité. En analysant les résidus de cette modélisation ARIMAX, il ne reste plus d'autocorrélation (*p*-valeur du test de Ljung-Box de 70%), et les résidus sont normalement distribués. 

```{r Verification_residus_ARIMAX_ts_semaine, include=FALSE}
checkresiduals(arimax_ts_semaine)
```

\
\

### Comparaison des modèles

Nous avons donc désormais estimé l'ensemble de nos modèles. On souhaite à présent sélectionner le meilleur d'entre eux. Pour cela, on procède comme pour la série précédente : on divise la série en un échantillon d'entraînement (75%) et un échantillon de test (25%). On ré-estime chacun de nos modèles sur l'échantillon d'entraînement, et l'on calcule à partir de cela des prévisions pour un horizon temporel égal à la longueur de l'échantillon de test. À partir de ces prévisions, on calcule différentes mesures de précision sur l'échantillon d'entraînement et de test. On ne retient que le RMSE et le MAPE, que l'on compare principalement sur l'échantillon de test. 

\

```{r Qualite_previsions_ts_semaine, include=TRUE, echo=FALSE, collapse=TRUE}
# Définition des échantillons de test et d'entraînement
serie = ts_semaine
train_set = head(serie, length(serie) * 0.75)
test_set = tail(serie, length(serie) * 0.25)

regresseurs_arimax_train = head(regresseurs_arimax, nrow(regresseurs_arimax) * 0.75)
regresseurs_arimax_test = tail(regresseurs_arimax, nrow(regresseurs_arimax) * 0.25)

# Ré-estimation du modèle SARIMA
sarma_ts_semaine_train =Arima(train_set, 
                           order = order_sarima,
                           seasonal = seasonal_sarima,
                           include.mean = mean_sarima,
                           method = "CSS-ML")

# Ré-estimation du modèle ARIMAX
arimax_ts_semaine_train = Arima(train_set,
                        xreg = as.matrix(regresseurs_arimax_train),
                        order = order_arimax_res,
                        seasonal = seasonal_arimax_res,
                        include.mean = mean_arimax_res,
                        method = "CSS-ML")

# Calcul des prévisions
fc_sarma_ts_semaine_test = forecast(sarma_ts_semaine_train, h=length(test_set))
fc_arimax_ts_semaine_test = forecast(arimax_ts_semaine_train, h=length(test_set), 
                                  xreg = as.matrix(regresseurs_arimax_test))

# Précision des modèles
cat("####################################################",
    "\n# Comparaison de la qualité prédictive des modèles #",
    "\n####################################################")

cat("\n\nModèle univarié (SARIMA) :", "\n-------------------------- \n")
round(accuracy(fc_sarma_ts_semaine_test, serie)[,c("RMSE","MAPE")],2)

cat("\nModèle multivarié (ARIMAX) :", "\n---------------------------- \n")
round(accuracy(fc_arimax_ts_semaine_test, serie)[,c("RMSE","MAPE")],2)
```

\

Nos deux modèles présentent de bons scores de précision. Pour le modèle univarié, le RMSE sur l'échantillon de test est de 3.10, pour un MAPE de 5.12%. Pour le modèle multivarié, le RMSE est de 2.00, et le MAPE de 4.25%. Ainsi, le modèle multivarié semble présenter de meilleures capacités prédictives que le modèle univarié. Nous représentons ci-dessous les prévisions obtenues à partir de chacune des modélisations, pour l'année 2020 (horizon temporel de 52 semaines). On représente également les prévisions obtenues par modèle ARIMAX seulement, en prenant le soin de faire apparaître les intervalles de prévision. 

\

<center>

```{r Prevision_ts_semaine, include = TRUE, echo = FALSE}
# Prévisions à 1 an de la consommation synthétisée au mois
regresseurs_arimax_2020 = data.frame("Temperature" = df.gr.semaine.2020$Temp, 
                                     "JoursFeries" = df.gr.semaine.2020$dummyJF)

previsions_sarma_ts_semaine = forecast(sarma_ts_semaine, h=52)
previsions_arimax_ts_semaine = forecast(arimax_ts_semaine, h=52, 
                                     xreg = as.matrix(regresseurs_arimax_2020))

# Construction graphique 1
autoplot(ts_semaine) +
  labs(title = "Prévisions à 52 semaines de la consommation hebdomadaire d'électricité",
       subtitle = "Deux modélisations différentes affichées (SARIMA et ARIMA)",
       x = "Temps", y = "Consommation électrique (GW)") + 
  
  autolayer(previsions_sarma_ts_semaine, PI=FALSE, serie = "SARIMA", size = 1) +
  autolayer(previsions_arimax_ts_semaine, PI=FALSE, serie = "ARIMAX", size = 1) +
  
  theme(legend.position="bottom", 
        legend.title = ) +
  scale_color_manual(values=c("#2471A3", "#CB4335"))

# Construction graphique 2 
autoplot(previsions_arimax_ts_semaine) +
  labs(title = "Prévisions à 52 semaines de la consommation hebdomadaire d'électricité",
       subtitle = "Modèle ARIMAX(3,0,0)(1,1,0)[52] avec la température comme régresseur ",
       x = "Temps", y = "Consommation électrique (GW)")

```

</center>

\
\


### Conclusion pour la synthèse hebdomadaire de la consommation d'électricité

À nouveau, nos deux modélisations (SARIMA et ARIMAX) sont satisfaisantes pour la prévision de la consommation hebdomadaire d'électricité en France. Nous retenons le modèle ARIMAX avec pour régresseurs la température et le nombre de jours fériés par semaine en tant que modèle le plus précis pour la prévision. Bien que vérifiant toutes les conditions d'un bon modèle (coefficients significatifs, résidus assimilable à un bruit blanc), `r colorize("**il ne faudra pas oublier lors de la lecture des prévisions que les intervalles sont calculés selon l'idée que la valeur future de tous les régresseurs ne comporte pas d'incertitude. Nous l'avons dit, c'est vrai pour certaines variables, mais pas pour toutes.**", rouge1)` La température future n'est qu'une moyenne des températures passées, et l'incertitude associée est à garder en tête. 

\
\
\
\

## Modélisation journalière

On souhaite à présent franchir une nouvelle étape pour nos prévisions, et pas des moindres ! En effet, nous nous intéressons à présent à la consommation d'électricité synthétisée à la journée. Ce niveau de synthèse plus faible permet de prendre en compte beaucoup plus d'information, mais il a un prix : l'apparition d'une double saisonnalité dans les données avec laquelle il va falloir composer. 

\

### Enjeu de la saisonnalité multiple et méthodes de résolution

En effet, avec la série de la consommation d'électricité synthétisée à la journée, une double saisonnalité apparaît : elle est à la fois hebdomadaire et annuelle. Chaque semaine, un motif similaire se répète, les jours ouvrés étant plus gourmands en électricité que les jours de week-end. De plus, les variations annuelles de consommation demeurent toujours présentes. La combinaison de ces deux phénomène aboutit à la courbe suivante : 

\

<center>

```{r Graph_ts_jour, include=TRUE, echo=FALSE}
# Représentation de la série synthétisée à la journée
autoplot(ts_jour) + 
  labs(title = "Synthèse journalière de la consommation d'électricité en France",
       subtitle = "Observations entre le 01/01/2016 et le 31/12/2019",
       x = "Temps", y = "Consommation électrique (GW)")
```

</center>

\

On peut zoomer sur les 400 premières observations (un peu plus d'un an de données) pour voir encore plus clairement le motif saisonnier hebdomadaire.

\

<center>

```{r Graph_ts_jour_zoom, include=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# Représentation de la série synthétisée à la journée
autoplot(ts_jour) +
    labs(title = "Synthèse journalière de la consommation d'électricité en France",
       subtitle = "Affichage des 400 premières observations seulement",
       x = "Temps", y = "Consommation électrique (GW)") + 
  xlim(0,400)
```

</center>

\

Comment traiter alors cette double saisonnalité ?

\

#### Utilisation de la fonction S3ARMA

Une première option consisterait à utiliser notre fonction `S3ARMA`, spécialement conçue pour traiter ce type d'enjeu. Nous avons en effet une première saisonnalité de fréquence 7, et une seconde saisonnalité de fréquence 365 (en réalité 365.25 étant donné que l'année 2016 est une année bissextile, mais ignorons cela pour l'instant). 

Avec ces deux paramètres, il serait en effet théoriquement possible d'utiliser notre fonction `S3ARMA`. Malheureusement, un simple modèle SARMA saisonnier d'ordre 365 ne serait déjà pas estimable sur R, en tout cas pas avec les fonctions fournies par le logiciel. En effet, le lecteur se rappellera qu'un modèle $\textrm{SARMA}(0,0,0)(1,0,0)[365]$ saisonnier n'est en réalité qu'un modèle $\textrm{ARMA}(365,0,0)$. Or la fonction `Arima` n'autorise pas d'ordre AR ou MA supérieur à 250, et un ordre supérieur à 150 représente déjà un défi pour la fonction en termes de temps de calcul. `r colorize("**Ainsi, impossible pour nous d'imaginer un modèle**", rouge1)` `S3ARMA` `r colorize("**avec une saisonnalité de fréquence 365**", rouge1)`. 

De plus, nous pourrions imaginer un modèle type SARIMAX avec pour régresseur la température, avec l'idée que cette dernière capture la saisonnalité annuelle. Cependant cette méthode ne fonctionne plus à l'échelle de la journée : l'effet de la température sur l'électricité varie trop d'une saison à l'autre, comme nous l'avons dit dans la partie de présentation des données. Au cours d'une année, le signe du coefficient passe de positif à négatif ! 

Il s'agit donc d'être malin et de trouver une alternative. 

\

#### Découpage en plusieurs modèles

**La solution que nous avons adopté pour ce projet consiste, pour la synthèse journalière, à ne pas estimer 1 mais 13 modèles**. En effet, la littérature sur le sujet nous apprend que beaucoup de travaux adoptent une solution simple pour "casser" les saisonnalités : découper la série initiale en sous-séries (*e.g.* mois, saison été/automne/hiver/printemps). Un découpage en 4 saisons s'effectuerait par exemple en récupérant chaque année les observations de chaque saison, et en créant ensuite 4 nouvelles séries correspondant pour chacune à la mise bout à bout des observations de chaque année pour la saison en question. 

Avec cette méthode, la saisonnalité annuelle disparaît naturellement, mais le nombre de modèles est bien entendu démultiplié. Nous adoptons cette méthode pour nos données, en découpant notre série en 13 sous-séries, de 4 semaines chacune. Nous récupérons pour chaque série l'ensemble des données disponibles chaque année, et nous les collons ensemble. Par exemple, le groupe 1 correspond aux observations des semaines 1 à 4. Nous extrayons de la série initiale les données des semaines 1 à 4 pour les années 2016, 2017, 2018, 2019, et nous regroupons ces observations en une série unique. 

Il s'agit ensuite de modéliser chacune de ces séries. Elles présentent bien entendu des caractéristiques variables selon leur position dans l'année. Les groupes "hivernaux" (ex. le groupe 1 pour les semaines 1 à 4 ou le groupe 13 pour les semaines 49 à 52) sont plus volatiles car bien davantage liées aux variations de température que les séries "estivales", beaucoup plus stables. Cette différence est frappante graphiquement. On représente ci-dessous les séries 1 (semaines 1-4) et 7 (semaines 25-28). Pour ces deux exemples (seulement), on colorie les données issues de chaque année d'une couleur différente. On se rend bien compte que la modélisation ne sera pas la même pour ces deux groupes.

```{r Creation_groupes, include=FALSE}
# Création des groupes
groupe1 = df.gr.jour[df.gr.jour$NumSem %in% c(1:4),]
groupe2 = df.gr.jour[df.gr.jour$NumSem %in% c(5:8),]
groupe3 = df.gr.jour[df.gr.jour$NumSem %in% c(9:12),]
groupe4 = df.gr.jour[df.gr.jour$NumSem %in% c(13:16),]
groupe5 = df.gr.jour[df.gr.jour$NumSem %in% c(17:20),]
groupe6 = df.gr.jour[df.gr.jour$NumSem %in% c(21:24),]
groupe7 = df.gr.jour[df.gr.jour$NumSem %in% c(25:28),]
groupe8 = df.gr.jour[df.gr.jour$NumSem %in% c(29:32),]
groupe9 = df.gr.jour[df.gr.jour$NumSem %in% c(33:36),]
groupe10 = df.gr.jour[df.gr.jour$NumSem %in% c(37:40),]
groupe11 = df.gr.jour[df.gr.jour$NumSem %in% c(41:44),]
groupe12 = df.gr.jour[df.gr.jour$NumSem %in% c(45:48),]
groupe13 = df.gr.jour[df.gr.jour$NumSem %in% c(49:52),]

# Création des séries
ts_groupe1 = ts(groupe1$Consommation, frequency = 7)
ts_groupe2 = ts(groupe2$Consommation, frequency = 7)
ts_groupe3 = ts(groupe3$Consommation, frequency = 7)
ts_groupe4 = ts(groupe4$Consommation, frequency = 7)
ts_groupe5 = ts(groupe5$Consommation, frequency = 7)
ts_groupe6 = ts(groupe6$Consommation, frequency = 7)
ts_groupe7 = ts(groupe7$Consommation, frequency = 7)
ts_groupe8 = ts(groupe8$Consommation, frequency = 7)
ts_groupe9 = ts(groupe9$Consommation, frequency = 7)
ts_groupe10 = ts(groupe10$Consommation, frequency = 7)
ts_groupe11 = ts(groupe11$Consommation, frequency = 7)
ts_groupe12 = ts(groupe12$Consommation, frequency = 7)
ts_groupe13 = ts(groupe13$Consommation, frequency = 7)
```

\

<center>

```{r Graph_ts_groupe1, include = TRUE, echo = FALSE}
# Représentation du groupe 1
groupe1_2016 = df.gr.jour[(df.gr.jour$NumSem %in% c(1:4) & df.gr.jour$Annee == 2016),]
groupe1_2017 = df.gr.jour[(df.gr.jour$NumSem %in% c(1:4) & df.gr.jour$Annee == 2017),]
groupe1_2018 = df.gr.jour[(df.gr.jour$NumSem %in% c(1:4) & df.gr.jour$Annee == 2018),]
groupe1_2019 = df.gr.jour[(df.gr.jour$NumSem %in% c(1:4) & df.gr.jour$Annee == 2019),]

ts_groupe1_2016 = ts(groupe1_2016$Consommation, start = 1)
ts_groupe1_2017 = ts(groupe1_2017$Consommation, start = 29)
ts_groupe1_2018 = ts(groupe1_2018$Consommation, start = 57)
ts_groupe1_2019 = ts(groupe1_2019$Consommation, start = 85)

autoplot(ts_groupe1_2016, serie = "2016",
         main = "Consommation électrique du groupe 1 (semaines (1-4))",
         xlab = "Temps", ylab = "Consommation électrique (GW)") + 
  
  autolayer(ts_groupe1_2017, serie = "2017") + 
  autolayer(ts_groupe1_2018, serie = "2018") + 
  autolayer(ts_groupe1_2019, serie = "2019") +
  theme(legend.position="bottom")
```

```{r Graph_ts_groupe7, include = TRUE, echo = FALSE}
# Représentation du groupe 7
groupe7_2016 = df.gr.jour[(df.gr.jour$NumSem %in% c(25:28) & df.gr.jour$Annee == 2016),]
groupe7_2017 = df.gr.jour[(df.gr.jour$NumSem %in% c(25:28) & df.gr.jour$Annee == 2017),]
groupe7_2018 = df.gr.jour[(df.gr.jour$NumSem %in% c(25:28) & df.gr.jour$Annee == 2018),]
groupe7_2019 = df.gr.jour[(df.gr.jour$NumSem %in% c(25:28) & df.gr.jour$Annee == 2019),]

ts_groupe7_2016 = ts(groupe7_2016$Consommation, start = 1)
ts_groupe7_2017 = ts(groupe7_2017$Consommation, start = 29)
ts_groupe7_2018 = ts(groupe7_2018$Consommation, start = 57)
ts_groupe7_2019 = ts(groupe7_2019$Consommation, start = 85)

autoplot(ts_groupe7_2016, serie = "2016",
         main = "Consommation électrique du groupe 7 (semaines (25-28))",
         xlab = "Temps", ylab = "Consommation électrique (GW)") + 
  autolayer(ts_groupe7_2017, serie = "2017") + 
  autolayer(ts_groupe7_2018, serie = "2018") + 
  autolayer(ts_groupe7_2019, serie = "2019") +
  theme(legend.position="bottom") 
```

</center>

\

Pour toute cette partie, nous n'allons évidemment pas présenter l'ensemble des travaux de modélisation. Nous avons modélisé chaque série avec beaucoup de rigueur, et avec le même degré d'attention porté à chacune. Dans ce qui suit, nous ne présentons que les résultats, excepté pour la première série, en guise d'exemple. Pour chacune, le processus a été le suivant : 

- Modélisation univarié : Modélisation SARIMA de la série
- Modélisations multivariées (deux à chaque fois) :
  - Une modélisation avec pour seul régresseur la température
  - Une modélisation autorisant d'autres régresseurs complémentaires à la température (s'ils sont significatifs dans la régression)
- Comparaison des performances des différentes modélisations sur échantillon d'entraînement/de test
- Sélection du meilleur modèle

Une fois toutes les séries modélisées, il sera possible de calculer des prévisions pour chacune d'entre elles et ensuite de les regrouper pour prédire l'année 2020. Nous reviendrons sur ce point plus loin. 

\
\

### Analyse détaillée le groupe 1 (semaines 1-4)

Pour le premier groupe, nous détaillons (un peu) la démarche. Le lecteur comprendra rapidement que cette dernière est fort similaire à ce que nous avons fait pour les séries mensuelle et hebdomadaire. Ainsi, nous ne présentons qu'un minimum de résultats afin de ne pas encombrer la lecture. Tout est bien sûr disponible dans le code R associé à ce projet. 

La série a été affichée plus haut. La première modélisation que nous souhaitons mettre en place est une modélisation univariée. Pour cela, on commence par étudier la stationnarité de la série. Saisonnière, la série doit être différenciée (lag = 7). Une fois différenciée saisonnièrement, la série est stationnaire. On étudie l'ACF/PACF de la série différenciée pour trouver une modélisation optimale. Une fois cette modélisation trouvée, nous procédons aux étapes habituelles de vérification : variation à la hausse d'une unité des différents coefficients, absence de racine unité et test de Ljung-Box sur les résidus. Le modèle SARIMA retenu est le suivant : 

\

<center>
$\textrm{SARIMA}(2,0,0)(2,1,0)[7]$
</center>

\

Tous les coefficients du modèle sont significatifs, les résidus sont assimilables à un bruit blanc (le test de Ljung-Box nous renvoie une *p*-valeur de 6%) et sont normalement distribués. On peut donc être satisfaits de cette modélisation univariée. 

\

```{r Modelisation_Groupe1_partie1, include=FALSE}
################################ -
### GROUPE 1 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe1
groupe = groupe1
print = FALSE

##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(2,0,0)
seasonal_sarma_gr <- c(2,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}
```

```{r Modelisation_Groupe1_partie1_Resultats, include=TRUE, echo=FALSE}
# Affichage des résultats
summary(sarma_gr)
```

\

Une fois notre modélisation univariée terminée, nous nous tournons vers la modélisation multivariée, importante pour des séries "hivernales" comme celle du groupe 1. On commence par un modèle ARIMAX avec pour seul régresseur la température, afin de voir "si elle se suffit à elle-même". On régresse donc la consommation d'électricité sur la température moyenne journalière. Cette dernière est très significative, comme on pouvait s'y attendre. On récupère les résidus de cette régression, que l'on modélise par un processus : 

\

<center>
$\textrm{SARIMA}(1,0,0)(4,1,0)[7]$
</center>

\

Cette modélisation des résidus est tout à fait satisfaisante car tous les coefficients sont significatifs, les résidus sont normalement distribués et assimilables à un bruit blanc (*p*-valeur du test de Ljung-Box égale à 24%). On met donc en place notre modèle ARIMAX à partir de cette modélisation, et l'on obtient là-encore de très bons résultats : tout est significatif, la température a un coefficient de -1.03, cohérent avec notre intuition, et les résidus du modèle sont normalement distribués, et ne contiennent pas d'autocorrélation (*p*-valeur du test de Ljung-Box de 21%). On affiche les résultats ci-dessous. 

\

```{r Modelisation_Groupe1_partie2, include=FALSE}
####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(4,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}
```

```{r Modelisation_Groupe1_partie2_Resultats, include=TRUE, echo=FALSE}
# Résultats
summary(armax_gr_TempOnly)
checkresiduals(armax_gr_TempOnly, plot=FALSE)
```

<center>

```{r Modelisation_Groupe1_partie2_Resultats_bis, include=TRUE, echo=FALSE}
# Résultats
checkresiduals(armax_gr_TempOnly, test = FALSE)
```
</center>

\

On procède de la même façon pour notre second modèle ARIMAX. Cette fois, deux régresseurs sont utilisés : la température bien-sûr, et la variable binaire correspondant aux jours fériés. Le même travail que pour le modèle précédent nous fait aboutir à la même modélisation : 

\

<center>
$\textrm{SARIMA}(1,0,0)(4,1,0)[7]$
</center>

\

On estime un modèle ARIMAX à partir de cette dernière. Là-encore, les résidus sont bien assimilables à un bruit blanc et sont normalement distribués. Nous sommes donc satisfaits de ce modèle également. 

\

```{r Modelisation_Groupe1_partie3, include=FALSE}
############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$dummyJF)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(1,0,0)
seasonal_sarma_residuals_2 <- c(4,1,0)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "JoursFeries" = groupe$dummyJF)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}
```

```{r Modelisation_Groupe1_partie3_Resultats, include=TRUE, echo=FALSE}
# Résultats
summary(armax_gr_Complet)
```

\

Il ne reste plus qu'à comparer nos modèles. Pour cela, on sépare notre série en un échantillon d'entraînement (75%) et un échantillon de test (25%). On ré-estime nos trois modèles sur l'échantillon d'entraînement, et on compare leurs performances sur l'échantillon de test, grâce aux métriques RMSE et MAPE. Le modèle le plus précis est le modèle ARIMAX avec pour seul régresseur la température. On sauvegarde donc ce modèle comme la modélisation optimale pour le groupe 1.

\

```{r Modelisation_Groupe1_partie4, include=FALSE}
################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

```

```{r Modelisation_Groupe1_partie4_Resultats, include=TRUE, echo=FALSE, collapse=TRUE}
# Calcul des mesures de précision

cat("####################################################",
    "\n# Comparaison de la qualité prédictive des modèles #",
    "\n####################################################")

cat("\n\nModèle univarié (SARIMA) :", "\n-------------------------- \n")
print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))

cat("\nModèle multivarié (ARIMAX, Température seulement) :", 
    "\n--------------------------------------------------- \n")
print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))

cat("\nModèle multivarié (ARIMAX, Complet) :", 
    "\n------------------------------------- \n")
print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))
```

```{r Modelisation_Groupe1_partie5, include=FALSE}
################## -
# BILAN GROUPE 1 # -
################## -

# Modèle final
modele_final_gr1 = armax_gr_TempOnly
graph_gr1 = autoplot(armax_gr_TempOnly_test) + autolayer(serie)
fc_groupe1_test = armax_gr_TempOnly_test
# Régresseurs retenus
regresseurs_groupe1 = c("Temperature")
```


\
\

### Résultats globaux

On effectue exactement la même chose pour les 12 autres modèles, et l'on regroupe les résultats dans les tableaux ci-dessous. Le lecteur trouvera dans le code R associé les 12 blocs de code permettant d'aboutir à chacun de ces résultats, et est bien sûr libre de les exécuter de nouveau. Bien entendu, la qualité des modèles (absence d'autocorrélation dans les résidus, normalité de ces derniers, ou encore mesures de la qualité prédictive) peut varier d'un modèle à un autre. L'idée est simplement de sélectionner pour chaque groupe la meilleure modélisation possible. Le modèle retenu pour chaque groupe est celui en gras dans les tableaux ci-dessous.

\

<u>`r colorize("Résultats du **Groupe 1** :", bleu1)`</u>

|     Type    |        Identification        |        Régresseurs        | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:-------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |   SARIMA(2,0,0)(2,1,0)[7]    |           Aucun           |          6%          |   5.22   |   8.06   |
| **SARIMAX** | **SARIMAX(1,0,0)(4,1,0)[7]** |      **Température**      |        **21%**       | **3.82** | **6.46** |
|   SARIMAX   |   SARIMAX(1,0,0)(4,1,0)[7]   | Température, Jours Fériés |          6%          |   4.82   |   8.17   |

\

<u>`r colorize("Résultats du **Groupe 2** :", bleu1)`</u>

Comparé aux autres groupes, les trois modélisations sont assez peu précises sur échantillon de test. On fixe comme modèle préféré pour ce groupe le modèle SARIMAX "complet". 

|     Type    |        Identification        |        Régresseurs        | Ljung-Box *p*-valeur |   RMSE   |    MAPE   |
|:-----------:|:----------------------------:|:-------------------------:|:--------------------:|:--------:|:---------:|
|    SARIMA   |   SARIMA(3,0,0)(2,1,0)[7]    |           Aucun           |          57%         |   10.11  |   19.78   |
|   SARIMAX   |   SARIMAX(1,0,1)(2,1,0)[7]   |        Température        |          7%          |   5.56   |   10.63   |
| **SARIMAX** | **SARIMAX(3,0,2)(0,1,1)[7]** | **Température, Vacances** |        **6%**        | **5.06** | **10.27** |

\

<u>`r colorize("Résultats du **Groupe 3** :", bleu1)`</u>

Les modèles SARIMAX gagnent en précision par rapport au SARIMA simple. On choisit pour ce groupe la modélisation SARIMAX "complet", avec pour régresseur la température et la couverture nuageuse, très satisfaisante. 

|     Type    |        Identification        |         Régresseurs         | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:---------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |   SARIMA(1,0,0)(0,1,1)[7]    |            Aucun            |          64%         |   4.81   |   10.76  |
|   SARIMAX   |   SARIMAX(1,0,0)(3,1,0)[7]   |         Température         |          35%         |   2.71   |   5.29   |
| **SARIMAX** | **SARIMAX(2,0,0)(0,1,1)[7]** | **Température, Couverture** |        **23%**       | **2.17** | **4.25** |

\

<u>`r colorize("Résultats du **Groupe 4** :", bleu1)`</u>

Pour ce groupe, aucun régresseur n'est significatif excepté la température. Le modèle SARIMAX présente de bons scores de précision sur l'échantillon de test, même si le modèle SARIMA simple devient également plus précis, comparé à ses résultats pour les groupes précédents. C'est logique : la série de la consommation se stabilise progressivement à mesure que l'on avance dans les groupes, le printemps et des températures plus stables s'installant. 

|     Type    |        Identification        |   Régresseurs   | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:---------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |   SARIMA(1,0,0)(3,1,0)[7]    |      Aucun      |          85%         |   4.11   |   8.97   |
| **SARIMAX** | **SARIMAX(1,0,0)(3,1,0)[7]** | **Température** |        **36%**       | **1.92** | **4.12** |

\

<u>`r colorize("Résultats du **Groupe 5** :", bleu1)`</u>

La dynamique présentée pour le groupe 4 se poursuit. Le modèle le plus précis est le modèle SARIMAX "complet", avec pour régresseurs la température et la variable binaire jours fériés. On le sélectionne donc comme modèle final pour ce groupe. 

|     Type    |        Identification        |          Régresseurs          | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:-----------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(1,0,0)(0,1,1)[7]   |             Aucun             |          24%         |   2.99   |   6.82   |
|   SARIMAX   |   SARIMAX(1,0,0)(2,1,0)[7]   |          Température          |          10%         |   2.13   |   4.70   |
| **SARIMAX** | **SARIMAX(2,0,0)(3,1,0)[7]** | **Température, Jours Fériés** |       **5.4%**       | **2.03** | **4.49** |

\

<u>`r colorize("Résultats du **Groupe 6** :", bleu1)`</u>

Cette fois, la température n'est plus significative pour expliquer la consommation d'électricité pendant cette période. Le seul régresseur pertinent est la variable binaire jours fériés. Rien d'étonnant à cela quand on regarde la courbe du groupe, très stable. Les résultats du modèle sont très bons ! Le MAPE est seulement de 1.68%, bien inférieur à ce que nous avons obtenu pour les groupes précédents. Nous fixons donc cette modélisation comme modélisation finale pour notre groupe 6. 

|     Type    |        Identification        |    Régresseurs   | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:----------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(1,0,0)(3,1,0)[7]   |       Aucun      |         0.3%         |   1.33   |   2.26   |
| **SARIMAX** | **SARIMAX(2,0,0)(0,1,1)[7]** | **Jours Fériés** |        **13%**       | **0.72** | **1.68** |

\

<u>`r colorize("Résultats du **Groupe 7** :", bleu1)`</u>

L'amélioration de la précision de nos modèles se poursuit. Ils présentent tous pour le groupe 7 de très bons niveaux de précision, le modèle SARIMAX avec pour régresseur la température seulement battant le record de précision, avec un MAPE à 1.57%. On sélectionne bien-sûr de nouveau ce modèle comme meilleur modèle pour le groupe 7. 

|     Type    |        Identification        |        Régresseurs        | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:-------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(2,0,1)(3,1,0)[7]   |           Aucun           |          79%         |   1.23   |   2.75   |
| **SARIMAX** | **SARIMAX(1,0,0)(2,1,0)[7]** |      **Température**      |        **15%**       | **0.66** | **1.57** |
|   SARIMAX   |   SARIMAX(0,0,1)(2,1,0)[7]   | Température, Jours Fériés |          20%         |   0.91   |   1.80   |

\

<u>`r colorize("Résultats du **Groupe 8** :", bleu1)`</u>

Les modèles perdent légèrement en précision pour ce groupe. On sélectionne le modèle SARIMAX avec température seulement comme modèle préféré pour ce groupe. 

|     Type    |        Identification        |        Régresseurs        | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:-------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(2,0,1)(2,1,0)[7]   |           Aucun           |          58%         |   1.85   |   4.60   |
| **SARIMAX** | **SARIMAX(1,0,0)(3,1,0)[7]** |      **Température**      |        **81%**       | **1.38** | **3.47** |
|   SARIMAX   |   SARIMAX(1,0,0)(0,1,1)[7]   | Température, Jours Fériés |          2%          |   1.56   |   4.12   |

\

<u>`r colorize("Résultats du **Groupe 9** :", bleu1)`</u>

Pour ce groupe, nos modèles présentent tous de bonnes mesures de précision. On sélectionne de nouveau le premier modèle SARIMAX comme modèle favori pour le groupe 9. 

|     Type    |        Identification        |               Régresseurs               | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:---------------------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(2,0,0)(2,1,0)[7]   |                  Aucun                  |          16%         |   1.23   |   2.55   |
| **SARIMAX** | **SARIMAX(1,0,0)(3,1,0)[7]** |             **Température**             |        **18%**       | **0.92** | **2.23** |
|   SARIMAX   |   SARIMAX(1,0,0)(2,1,0)[7]   | Temp., Humidité, Vacances, Jours Fériés |          0%          |   1.06   |   2.60   |

\

<u>`r colorize("Résultats du **Groupe 10** :", bleu1)`</u>

Pour ce groupe, aucun régresseur n'est significatif à part la température. Nous n'avons donc que deux modèles à présenter. Encore une fois, le modèle SARIMAX avec pour régresseur la température surclasse (de peu) le modèle SARIMA simple. Il gagne donc lui aussi son ticket de modèle favori pour ce groupe !

|     Type    |        Identification        |   Régresseurs   | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:---------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(1,0,0)(3,1,0)[7]   |      Aucun      |          40%         |   1.29   |   3.51   |
| **SARIMAX** | **SARIMAX(1,0,0)(3,1,0)[7]** | **Température** |        **16%**       | **0.91** | **2.23** |

\

<u>`r colorize("Résultats du **Groupe 11** :", bleu1)`</u>

Cette fois, le modèle SARIMA simple décroche en termes de capacité prédictives, bien qu'il s'agisse d'un bon modèle en termes d'identification. Le modèle SARIMAX avec pour régresseur reste le plus précis. 

|     Type    |        Identification        |           Régresseurs           | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:-------------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(1,0,0)(3,1,0)[7]   |              Aucun              |          39%         |   3.62   |   8.88   |
| **SARIMAX** | **SARIMAX(0,0,2)(3,1,0)[7]** |         **Température**         |        **9%**        | **1.56** | **3.58** |
|   SARIMAX   |   SARIMAX(1,0,0)(3,1,0)[7]   | Température, Humidité, Vacances |         0.1%         |   1.90   |   4.34   |

 \

<u>`r colorize("Résultats du **Groupe 12** :", bleu1)`</u>

La dynamique du groupe précédent se poursuit, les températures fraîches étant devenues la norme pour cette période de l'année. Le modèle SARIMA simple a bien du mal à capter la dynamique de la série (il reste beaucoup d'autocorrélation dans les erreurs), là où le modèle SARIMAX avec pour régresseur la température présente une *p*-valeur pour le test de Ljung-Box à faire rougir les autres modèles. La température est définitivement la clé de compréhension principale de la variation de la consommation d'électricité. 

|     Type    |        Identification        |             Régresseurs             | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:-----------------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(1,0,0)(3,1,0)[7]   |                Aucun                |          0%          |   6.88   |   11.20  |
| **SARIMAX** | **SARIMAX(1,0,0)(2,1,0)[7]** |           **Température**           |        **75%**       | **2.08** | **3.10** |
|   SARIMAX   |   SARIMAX(1,0,0)(3,1,0)[7]   | Température, Jours Fériés, Vacances |          0%          |   2.03   |   3.14   |

\

<u>`r colorize("Résultats du **Groupe 13** :", bleu1)`</u>

Le modèle ARIMAX avec pour seul régresseur la température est légèrement plus précis sur l'échantillon de test, mais les erreurs contiennent encore de l'autocorrélation. On choisit donc comme modèle final pour ce groupe le modèle SARIMAX "complet", car bien que moins précis, on peut rejeter l'hypothèse nulle du test de Ljung-Box au seuil 1%. 

|     Type    |        Identification        |               Régresseurs               | Ljung-Box *p*-valeur |   RMSE   |   MAPE   |
|:-----------:|:----------------------------:|:---------------------------------------:|:--------------------:|:--------:|:--------:|
|    SARIMA   |    SARIMA(0,0,4)(0,1,1)[7]   |                  Aucun                  |          6%          |   6.37   |   11.98  |
|   SARIMAX   |   SARIMAX(0,0,3)(1,1,0)[7]   |               Température               |          0%          |   3.78   |   5.75   |
| **SARIMAX** | **SARIMAX(0,0,1)(0,1,1)[7]** | **Température, Jours Fériés, Vacances** |        **4%**        | **3.45** | **6.25** |


```{r Modelisation_Groupe2, include=FALSE}
################################ -
### GROUPE 2 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe2
groupe = groupe2
print = FALSE


##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(3,0,0)
seasonal_sarma_gr <- c(2,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,1)
seasonal_sarma_residuals_1 <- c(2,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$nb_zones)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(3,0,2)
seasonal_sarma_residuals_2 <- c(0,1,1)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "NbZones" = groupe$nb_zones)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}



################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 2 # -
################## -

# Modèle final
modele_final_gr2 = armax_gr_Complet
graph_gr2 = autoplot(armax_gr_Complet_test) + autolayer(serie)
fc_groupe2_test = armax_gr_Complet_test
# Régresseurs retenus
regresseurs_groupe2 = c("Temperature", "NbZones")
```



```{r Modelisation_Groupe3, include=FALSE}
################################ -
### GROUPE 3 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe3
groupe = groupe3
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(1,0,0)
seasonal_sarma_gr <- c(0,1,1)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(3,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$Cover)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(2,0,0)
seasonal_sarma_residuals_2 <- c(0,1,1)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "Couverture" = groupe$Cover)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}



################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 3 # -
################## -

# Modèle final
modele_final_gr3 = armax_gr_Complet
graph_gr3 = autoplot(armax_gr_Complet_test) + autolayer(serie)
fc_groupe3_test = armax_gr_Complet_test
# Régresseurs retenus
regresseurs_groupe3 = c("Temperature", "Couverture")
```



```{r Modelisation_Groupe4, include=FALSE}
################################ -
### GROUPE 4 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe4
groupe = groupe4
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(1,0,0)
seasonal_sarma_gr <- c(3,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(3,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Aucune variable significative excepté la température



################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")


# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 4 # -
################## -

# Modèle final
modele_final_gr4 = armax_gr_TempOnly
graph_gr4 = autoplot(armax_gr_TempOnly_test) + autolayer(serie)
fc_groupe4_test = armax_gr_TempOnly_test
# Régresseurs retenus
regresseurs_groupe4 = c("Temperature")
```



```{r Modelisation_Groupe5, include=FALSE}
################################ -
### GROUPE 5 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe5
groupe = groupe5
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(1,0,0)
seasonal_sarma_gr <- c(0,1,1)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(2,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$dummyJF)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(2,0,0)
seasonal_sarma_residuals_2 <- c(3,1,0)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "JoursFeries" = groupe$dummyJF)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}



################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 5 # -
################## -

# Modèle final
modele_final_gr5 = armax_gr_Complet
graph_gr5 = autoplot(armax_gr_Complet_test) + autolayer(serie)
fc_groupe5_test = armax_gr_Complet_test
# Régresseurs retenus
regresseurs_groupe5 = c("Temperature", "JoursFeries")
```



```{r Modelisation_Groupe6, include=FALSE}
################################ -
### GROUPE 6 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe6
groupe = groupe6
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(1,0,0)
seasonal_sarma_gr <- c(3,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Température pas significative

############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$dummyJF)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(2,0,0)
seasonal_sarma_residuals_2 <- c(0,1,1)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("JoursFeries" = groupe$dummyJF)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}



################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)

armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))

  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 6 # -
################## -

# Modèle final
modele_final_gr6 = armax_gr_Complet
graph_gr6 = autoplot(armax_gr_Complet_test) + autolayer(serie)
fc_groupe6_test = armax_gr_Complet_test
# Régresseurs retenus
regresseurs_groupe6 = c("JoursFeries")
```



```{r Modelisation_Groupe7, include=FALSE}
################################ -
### GROUPE 7 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe7
groupe = groupe7
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(2,0,1)
seasonal_sarma_gr <- c(3,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(2,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$dummyJF)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(0,0,1)
seasonal_sarma_residuals_2 <- c(2,1,0)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "JoursFeries" = groupe$dummyJF)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}



################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 7 # -
################## -

# Modèle final
modele_final_gr7 = armax_gr_TempOnly
graph_gr7 = autoplot(armax_gr_TempOnly_test) + autolayer(serie)
fc_groupe7_test = armax_gr_TempOnly_test
# Régresseurs retenus
regresseurs_groupe7 = c("Temperature")
```



```{r Modelisation_Groupe8, include=FALSE}
################################ -
### GROUPE 8 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe8
groupe = groupe8
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(2,0,1)
seasonal_sarma_gr <- c(2,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(3,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$dummyJF)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(1,0,0)
seasonal_sarma_residuals_2 <- c(0,1,1)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "JoursFeries" = groupe$dummyJF)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}



################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 8 # -
################## -

# Modèle final
modele_final_gr8 = armax_gr_TempOnly
graph_gr8 = autoplot(armax_gr_TempOnly_test) + autolayer(serie)
fc_groupe8_test = armax_gr_TempOnly_test
# Régresseurs retenus
regresseurs_groupe8 = c("Temperature")
```



```{r Modelisation_Groupe9, include=FALSE}
################################ -
### GROUPE 9 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe9
groupe = groupe9
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(2,0,0)
seasonal_sarma_gr <- c(2,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(3,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$Hum + groupe$nb_zones + groupe$dummyJF)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(1,0,0)
seasonal_sarma_residuals_2 <- c(2,1,0)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "Humidite" = groupe$Hum,
                           "JoursFeries" = groupe$dummyJF,
                           "NbZones" = groupe$nb_zones)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}



################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 9 # -
################## -

# Modèle final
modele_final_gr9 = armax_gr_TempOnly
graph_gr9 = autoplot(armax_gr_TempOnly_test) + autolayer(serie)
fc_groupe9_test = armax_gr_TempOnly_test
# Régresseurs retenus
regresseurs_groupe9 = c("Temperature")
```



```{r Modelisation_Groupe10, include=FALSE}
################################ -
### GROUPE 10 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe10
groupe = groupe10
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(1,0,0)
seasonal_sarma_gr <- c(3,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(3,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Rien d'autre que température n'est significatif

################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")


# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))


# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))}



################### -
# BILAN GROUPE 10 # -
################### -

# Modèle final
modele_final_gr10 = armax_gr_TempOnly
graph_gr10 = autoplot(armax_gr_TempOnly_test) + autolayer(serie)
fc_groupe10_test = armax_gr_TempOnly_test
# Régresseurs retenus
regresseurs_groupe10 = c("Temperature")
```



```{r Modelisation_Groupe11, include=FALSE}
################################ -
### GROUPE 11 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe11
groupe = groupe11
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(1,0,0)
seasonal_sarma_gr <- c(3,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(0,0,2)
seasonal_sarma_residuals_1 <- c(3,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$Hum + groupe$nb_zones)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(1,0,0)
seasonal_sarma_residuals_2 <- c(3,1,0)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "Humidite" = groupe$Hum,
                           "NbZones" = groupe$nb_zones)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}


################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################## -
# BILAN GROUPE 11 # -
################## -

# Modèle final
modele_final_gr11 = armax_gr_TempOnly
graph_gr11 = autoplot(armax_gr_TempOnly_test) + autolayer(serie)
fc_groupe11_test = armax_gr_TempOnly_test
# Régresseurs retenus
regresseurs_groupe11 = c("Temperature")
```



```{r Modelisation_Groupe12, include=FALSE}
################################ -
### GROUPE 12 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe12
groupe = groupe12
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(1,0,0)
seasonal_sarma_gr <- c(3,1,0)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(1,0,0)
seasonal_sarma_residuals_1 <- c(2,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$dummyJF + groupe$nb_zones)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(1,0,0)
seasonal_sarma_residuals_2 <- c(3,1,0)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "JoursFeries" = groupe$dummyJF,
                           "NbZones" = groupe$nb_zones)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}

################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:84,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:84,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[85:112,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[85:112,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################### -
# BILAN GROUPE 12 # -
##############"#### -

# Modèle final
modele_final_gr12 = armax_gr_TempOnly
graph_gr12 = autoplot(armax_gr_TempOnly_test) + autolayer(serie)
fc_groupe12_test = armax_gr_TempOnly_test
# Régresseurs retenus
regresseurs_groupe12 = c("Temperature")
```



```{r Modelisation_Groupe13, include=FALSE}
################################ -
### GROUPE 13 - Synthèse jour ### -
################################ -

# Paramètres 
serie = ts_groupe13
groupe = groupe13
print = FALSE



##################### -
# Analyse univariée # -
##################### -

# Stationnarité de la série
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie)))}

serie_d <- diff(serie, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(serie_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(serie_d)))}

# Modélisation SARIMA
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_gr <- c(0,0,4)
seasonal_sarma_gr <- c(0,1,1)
constant_sarma_gr <- FALSE

# Estimation du modèle SARIMA
sarma_gr <- Arima(serie, 
                  order=order_sarma_gr,
                  seasonal = seasonal_sarma_gr,
                  include.constant = constant_sarma_gr, 
                  method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(sarma_gr)
  checkresiduals(sarma_gr)}



####################### -
# Analyse multivariée # -
####################### -

############################################################## -
# MODELE 1 : ARIMAX avec pour seul régresseur la température # -
############################################################## -

# Étape 1 : Modélisation des résidus de la régression

# Régression linéaire et récupération des résidus
regression_1 <- lm(groupe$Consommation ~ groupe$Temp)
if(print==TRUE){summary(regression_1)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_1 <- ts(residuals(regression_1), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1)))}

residuals_1_d <- diff(residuals_1, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_1_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_1_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_1 <- c(0,0,3)
seasonal_sarma_residuals_1 <- c(1,1,0)
constant_sarma_residuals_1 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_1 <- Arima(residuals_1, 
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_1)
  checkresiduals(sarma_residuals_1)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_1 = data.frame("Temperature" = groupe$Temp)

# Modèle ARMAX
armax_gr_TempOnly <- Arima(serie, 
                           xreg = as.matrix(regresseurs_1),
                           order=order_sarma_residuals_1,
                           seasonal = seasonal_sarma_residuals_1,
                           include.constant = constant_sarma_residuals_1, 
                           method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_TempOnly)
  checkresiduals(armax_gr_TempOnly)}



############################# -
# MODELE 2 : ARIMAX Complet # -
############################# -

# Étape 1 : Modélisation des résidus de la régression

# Seconde régression
# Nous avons essayé avec tous les régresseurs possibles
# Nous ne retenons que ceux significatifs
regression_2 <- lm(groupe$Consommation ~ groupe$Temp + groupe$dummyJF + groupe$nb_zones)
if(print==TRUE){summary(regression_2)}

# Mise en forme des résidus comme une TS de fréquence 7
residuals_2 <- ts(residuals(regression_2), frequency = 7)

# Stationnarité de la série des résidus
if(print==TRUE){
  print("Analyse de la série initiale : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2)))}

residuals_2_d <- diff(residuals_2, lag = 7)

if(print==TRUE){
  print("Analyse de la série différenciée : ")
  print(paste("Nombre de différenciations simples requises :", ndiffs(residuals_2_d)))
  print(paste("Nombre de différenciations saisonnières requises :", nsdiffs(residuals_2_d)))}

# Modélisation SARIMA des résidus
# Note : Résultat final après procédure BJ complète - Identification, Estimation, Vérification
order_sarma_residuals_2 <- c(0,0,1)
seasonal_sarma_residuals_2 <- c(0,1,1)
constant_sarma_residuals_2 <- FALSE

# Estimation du modèle SARIMA
sarma_residuals_2 <- Arima(residuals_2, 
                           order=order_sarma_residuals_2,
                           seasonal = seasonal_sarma_residuals_2,
                           include.constant = constant_sarma_residuals_2, 
                           method="CSS-ML")

# Résultat et analyse des résidus ... de la modélisation des résidus !
if(print==TRUE){
  summary(sarma_residuals_2)
  checkresiduals(sarma_residuals_2)}

# Étape 2 : Modélisation ARIMAX

# Construction des régresseurs
regresseurs_2 = data.frame("Temperature" = groupe$Temp,
                           "JoursFeries" = groupe$dummyJF,
                           "NbZones" = groupe$nb_zones)
# Modèle ARMAX
armax_gr_Complet <- Arima(serie, 
                          xreg = as.matrix(regresseurs_2),
                          order=order_sarma_residuals_2,
                          seasonal = seasonal_sarma_residuals_2,
                          include.constant = constant_sarma_residuals_2, 
                          method="CSS-ML")

# Résultats et analyse des résidus
if(print==TRUE){
  summary(armax_gr_Complet)
  checkresiduals(armax_gr_Complet)}

################################################ -
# Analyse de la qualité prédictive des modèles # -
################################################ -

# On crée un échantillon d'entraînement et un échantillon de test
ts_groupe_train <- head(serie, length(serie)*0.75)
ts_groupe_test <- tail(serie, length(serie)*0.25)

# Estimation des modèles sur l'échantillon d'entraînement
sarma_gr_train <- Arima(ts_groupe_train, order=order_sarma_gr,
               seasonal = seasonal_sarma_gr,
               include.constant = constant_sarma_gr, method="CSS-ML")

armax_gr_TempOnly_train <- Arima(ts_groupe_train, 
                                 xreg = as.matrix(regresseurs_1[1:77,]),
                                 order=order_sarma_residuals_1,
                                 seasonal = seasonal_sarma_residuals_1,
                                 include.constant = constant_sarma_residuals_1, 
                                 method="CSS-ML")

armax_gr_Complet_train <- Arima(ts_groupe_train, 
                                xreg = as.matrix(regresseurs_2[1:77,]),
                                order=order_sarma_residuals_2,
                                seasonal = seasonal_sarma_residuals_2,
                                include.constant = constant_sarma_residuals_2, 
                                method="CSS-ML")

# Prévisions sur l'échantillon de test
sarma_gr_test <- forecast(sarma_gr_train, h = 28)
armax_gr_TempOnly_test <- forecast(armax_gr_TempOnly_train, h = 28, 
                                   xreg = as.matrix(regresseurs_1[78:103,]))
armax_gr_Complet_test <- forecast(armax_gr_Complet_train, h = 28, 
                                  xreg = as.matrix(regresseurs_2[78:103,]))

# Calcul des mesures de précision
if(print==TRUE){
  print("Modèle SARMA :", quote = FALSE)
  print(round(accuracy(sarma_gr_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Température :", quote = FALSE)
  print(round(accuracy(armax_gr_TempOnly_test, serie)[,c("RMSE", "MAPE")], 2))
  
  print("Modèle ARMAX Complet :", quote = FALSE)
  print(round(accuracy(armax_gr_Complet_test, serie)[,c("RMSE", "MAPE")], 2))}



################### -
# BILAN GROUPE 13 # -
################### -

# Modèle final
modele_final_gr13 = armax_gr_Complet
graph_gr13 = autoplot(armax_gr_Complet_test) + autolayer(serie)
fc_groupe13_test = armax_gr_Complet_test

# Régresseurs retenus
regresseurs_groupe13 = c("Temperature", "JoursFeries", "NbZones")
```

\
\

### Reconstruction des prévisions annuelles

À partir de ces 12 modèles, il est ainsi possible d'obtenir les prévisions journalières pour une année complète. Pour cela, on calcule les prévisions pour chaque groupe, et l'on regroupe ces dernières en un objet `forecast` unique. Bien entendu, ces prévisions regroupées sont à analyser avec un regard critique, nous y reviendrons dans la conclusion de cette partie.

\

#### Application sur un échantillon de test

Commençons par appliquer cette méthode avec un échantillon d'entraînement et un échantillon de test. Pour cela, on récupère, pour chaque groupe, les résultats obtenus lors de la phase de comparaison des méthodes. On récupère les prévisions sur l'échantillon de test du modèle retenu pour chaque groupe. On regroupe ces 13 prévisions en un objet `forecast` unique. En parallèle, on extrait de notre série `ts_jour` les réalisations correspondantes pour la période, les "vraies valeurs". À partir de ces deux grandeurs, nous pouvons calculer les résidus, c'est-à-dire la différence entre valeurs estimées et vraies réalisations de la série. Une fois les résidus calculés, il est tout à fait possible de calculer des indicateurs permettant d'appréhender la qualité de nos prévisions. 

Ci-dessous, on représente graphiquement la série initiale `ts_jour` ainsi que nos prévisions pour la dernière année de la série (2019). En rouge, on trace la série `ts_jour` (seulement la fin de l'année 2018 et l'année 2019 pour plus de visibilité). En bleu sont représentées nos prévisions et les intervalles de prévision associés. On observe que nos prévisions sont proches des vraies réalisations de la série. 

```{r Regroupement_previsions_jours_2019, include=FALSE}
# Test de la méthode sur échantillon de test
# Regroupement des différentes prévisions
forecast_combined = rbind(data.frame(fc_groupe1_test), 
                           data.frame(fc_groupe2_test), 
                           data.frame(fc_groupe3_test), 
                           data.frame(fc_groupe4_test), 
                           data.frame(fc_groupe5_test),
                           data.frame(fc_groupe6_test),
                           data.frame(fc_groupe7_test),
                           data.frame(fc_groupe8_test),
                           data.frame(fc_groupe9_test),
                           data.frame(fc_groupe10_test),
                           data.frame(fc_groupe11_test),
                           data.frame(fc_groupe12_test),
                           data.frame(fc_groupe13_test))

# Construction d'une liste d'éléments pour créer un objet forecast
liste_forecast = list(mean = ts(forecast_combined$Point.Forecast, start = 1086),
                      level = c(80, 95),
                      upper = cbind(ts(forecast_combined$Hi.80, start = 1086),
                                    ts(forecast_combined$Hi.95, start = 1086)),
                      lower = cbind(ts(forecast_combined$Lo.80, start = 1086),
                                    ts(forecast_combined$Lo.95, start = 1086)),
                      x = head(ts_jour, length(ts_jour) * 0.75))

# Transformation en objet forecast
forecast_combined = structure(liste_forecast, class='forecast')
```

\

<center>

```{r Regroupement_previsions_jours_2019_Graphique, include=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
autoplot(forecast_combined, serie = "Prévisions") + 
  autolayer(ts_jour, serie = "Réalisé") + 
  scale_x_continuous("Temps", limits = c(900,1500)) + 
  labs(title = "Prévisions journalières d'électricité pour l'année 2019",
       subtitle = "Obtenues à partir de la combinaison de 13 modélisations différentes",
       y = "Consommation électrique (GW)") + 
  theme(legend.position="none") +
  
    # Choix manuel des couleurs des courbes
  scale_colour_manual(values=c("black", 
                               rouge1),
    
                        breaks=c("Prévisions",
                               "Réalisé"))

```

</center>

\

Afin de quantifier cette proximité entre nos courbes, nous calculons le RMSE et le MAPE de nos prévisions. Ils sont plutôt bons, à l'image de ce que nous avions obtenu pour chacun de nos groupes individuellement. Le RMSE est égal à 2.18 gigawatts, et le MAPE est de 3.86%, ce qui est au-delà de nos espérances ! 

```{r, include=FALSE}
# Calcul des mesures de prévision
previsions_2019 = forecast_combined$mean[1:360]
realisations_2019 = tail(df.gr.jour$Consommation, 360)
residuals_2019 = realisations_2019 - previsions_2019
percentage_error_2019 = residuals_2019 * 100 / realisations_2019

# Définition des fonctions RMSE et MAPE
RMSE.function = function(x){sqrt(mean(x^2, na.rm = TRUE))}
MAPE.function = function(x){mean(abs(x), na.rm = TRUE)}
```

```{r, include=TRUE, echo=FALSE, collapse=TRUE}
# Calcul des mesures de précision
print(paste("RMSE :", round(RMSE.function(residuals_2019), 2)), quote = FALSE)
print(paste("MAPE :", round(MAPE.function(percentage_error_2019), 2)), quote = FALSE)
```

\

#### Prévisions pour l'année 2020

Nous savons donc désormais que notre méthode semble porter ses fruits, et nous l'appliquons de nouveau pour l'année 2020. Cette fois bien sûr, pas de vraies réalisations avec lesquelles comparer nos prévisions. On commence par recréer les groupes pour les semaines de l'année 2020. En effet, beaucoup de nos modèles étant des modèles SARIMAX, il nous faut récupérer les valeurs futures des régresseurs correspondantes. Une fois le découpage de l'année 2020 effectué, nous pouvons calculer 28 jours de prévisions (4 semaines de 7 jours) pour chaque groupe. On utilise pour chacun le modèle "préféré" retenu dans la partie précédente. On regroupe ces prévisions en un objet `forecast` unique, et on le représente graphiquement ci-dessous. 


```{r, include=FALSE}
# Création des même groupes pour l'année 2020
groupe1_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(1:4),]
groupe2_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(5:8),]
groupe3_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(9:12),]
groupe4_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(13:16),]
groupe5_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(17:20),]
groupe6_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(21:24),]
groupe7_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(25:28),]
groupe8_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(29:32),]
groupe9_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(33:36),]
groupe10_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(37:40),]
groupe11_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(41:44),]
groupe12_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(45:48),]
groupe13_2020 = df.gr.jour.2020[df.gr.jour.2020$NumSem %in% c(49:52),]

# On calcule les prévisions pour tous nos groupes

# Groupe 1
# Forecast 2020
regresseurs = data.frame("Temperature" = groupe1_2020$Temp)
fc_groupe1 = forecast(modele_final_gr1, h=nrow(groupe1_2020), xreg = as.matrix(regresseurs))

# Groupe 2
regresseurs = data.frame("Temperature" = groupe2_2020$Temp,
                         "NbZones" = groupe2_2020$nb_zones)
fc_groupe2 = forecast(modele_final_gr2, h=nrow(groupe2_2020), xreg = as.matrix(regresseurs))

# Groupe 3
regresseurs = data.frame("Temperature" = groupe3_2020$Temp,
                         "Couverture" = groupe3_2020$Cover)
fc_groupe3 = forecast(modele_final_gr3, h=nrow(groupe3_2020), xreg = as.matrix(regresseurs))

# Groupe 4
regresseurs = data.frame("Temperature" = groupe4_2020$Temp)
fc_groupe4 = forecast(modele_final_gr4, h=nrow(groupe4_2020), xreg = as.matrix(regresseurs))


# Groupe 5
regresseurs = data.frame("Temperature" = groupe5_2020$Temp,
                         "JoursFeries" = groupe5_2020$dummyJF)
fc_groupe5 = forecast(modele_final_gr5, h=nrow(groupe5_2020), xreg = as.matrix(regresseurs))

# Groupe 6
groupe = groupe6_2020
regresseurs = data.frame("JoursFeries" = groupe$dummyJF)
fc_groupe6 = forecast(modele_final_gr6, h=nrow(groupe6_2020), xreg = as.matrix(regresseurs))

# Groupe 7
groupe = groupe7_2020
regresseurs = data.frame("Temperature" = groupe$Temp)
fc_groupe7 = forecast(modele_final_gr7, h=nrow(groupe7_2020), xreg = as.matrix(regresseurs))

# Groupe 8
groupe = groupe8_2020
regresseurs = data.frame("Temperature" = groupe$Temp)
fc_groupe8 = forecast(modele_final_gr8, h=nrow(groupe8_2020), xreg = as.matrix(regresseurs))

# Groupe 9
groupe = groupe9_2020
regresseurs = data.frame("Temperature" = groupe$Temp)
fc_groupe9 = forecast(modele_final_gr9, h=nrow(groupe9_2020), xreg = as.matrix(regresseurs))

# Groupe 10
groupe = groupe10_2020
regresseurs = data.frame("Temperature" = groupe$Temp)
fc_groupe10 = forecast(modele_final_gr10, h=nrow(groupe10_2020), xreg = as.matrix(regresseurs))

# Groupe 11
groupe = groupe11_2020
regresseurs = data.frame("Temperature" = groupe$Temp)
fc_groupe11 = forecast(modele_final_gr11, h=nrow(groupe11_2020), xreg = as.matrix(regresseurs))

# Groupe 12
groupe = groupe12_2020
regresseurs = data.frame("Temperature" = groupe$Temp)
fc_groupe12 = forecast(modele_final_gr12, h=nrow(groupe12_2020), xreg = as.matrix(regresseurs))

# Groupe 13
groupe = groupe13_2020
regresseurs = data.frame("Temperature" = groupe$Temp,
                         "JoursFeries" = groupe$dummyJF,
                         "NbZones" = groupe$nb_zones)
fc_groupe13 = forecast(modele_final_gr13, h=nrow(groupe13_2020), xreg = as.matrix(regresseurs))
```


Une fois que les prévisions sont calculées, nous pouvons les regroupées ensemble pour formet un objet `forecast` plus long. Une fois les 13 prévisions regroupées, nous obtenons une prévision totale de 364 périodes, soit (quasiment) la longueur de l'année 2020. Le résultat est présenté graphiquement ci-dessous. 

```{r, include=FALSE}
# Regroupement des différentes prévisions
forecast_combined = rbind(data.frame(fc_groupe1), 
                         data.frame(fc_groupe2), 
                         data.frame(fc_groupe3), 
                         data.frame(fc_groupe4), 
                         data.frame(fc_groupe5),
                         data.frame(fc_groupe6),
                         data.frame(fc_groupe7),
                         data.frame(fc_groupe8),
                         data.frame(fc_groupe9),
                         data.frame(fc_groupe10),
                         data.frame(fc_groupe11),
                         data.frame(fc_groupe12),
                         data.frame(fc_groupe13))

# Construction d'une liste d'éléments pour créer un objet forecast
liste_forecast = list(mean = ts(forecast_combined$Point.Forecast, start = 1448),
                      level = c(80, 95),
                      upper = cbind(ts(forecast_combined$Hi.80, start = 1448),
                                    ts(forecast_combined$Hi.95, start = 1448)),
                      lower = cbind(ts(forecast_combined$Lo.80, start = 1448),
                                    ts(forecast_combined$Lo.95, start = 1448)),
                      x = ts_jour)

# Transformation en objet forecast
forecast_combined = structure(liste_forecast, class='forecast')
```

\

<center>

```{r, include=TRUE, echo=FALSE}
autoplot(forecast_combined) + 
  labs(title = "Prévisions journalière de la consommation d'électricité en 2020",
       subtitle = "Obtenue à partir de la combinaison de 13 modélisations différentes",
       x = "Temps", y = "Consommation électrique (GW)")
```

</center>

\
\

### Conclusions du modèle journalier

Notre analyse journalière est désormais terminée, et les conclusions à en tirer sont nombreuses. Tout d'abord, nous pouvons souligner que nous sommes satisfaits de nos prévisions. En effet, pour chacun des groupes de semaines, nos modélisations sont bonnes, les résidus de ces dernières sont assimilables à des bruits blancs et sont normalement distribués. Regroupées pour former la prévision de l'année 2020, les prévisions par groupe prennent tout leur sens. Nous avons pour l'année 2020 une prévision qui semble cohérente au regard des années passées. De plus, cette partie nous a permis de mettre en application cette idée de découpage d'une série saisonnière multiple en des sous-séries éliminant l'une des saisonnalités, et cette méthode semble donc porter ses fruits. 

Bien entendu, nous réitérons les remarques déjà formulées pour les modèles précédents. La plupart des modélisations sont des modèles de type SARIMAX, dont les prévisions sont calculées à partir de valeurs futures des régresseurs. L'incertitude autour de ces valeurs pour les régresseurs non-calendaires (au premier rang desquels la température) n'apparaît pas sur les intervalles de prévision, mais ne doit jamais quitter l'esprit de celui qui les lit. De plus, avec cette méthode, le cours du temps semble un petit peu "remis en question". `r colorize("**Les prévisions pour la fin de l'année 2020 présentent des niveaux d'incertitude similaires à ceux du début 2020. Or nous savons qu'habituellement en séries temporelles, l'incertitude va croissante avec l'horizon temporel des prévisions. Avec notre méthode de découpage, cela ne se voit évidemment pas, car pour chaque modèle la prévision n'est que de 28 périodes.**", rouge1)`

Ainsi, on peut raisonnablement penser que les intervalles de prévision pour les premiers groupes de 2020 sont cohérents. Cependant, la logique voudrait qu'ils aillent croissant à mesure que l'on avance dans l'année : l'environnement national a une probabilité de changer d'autant plus grande qu'il est éloigné dans le futur. Pourquoi l'année 2020 ne serait-elle pas par exemple celle d'une pandémie historique, mettant la production à l'arrêt pendant de nombreuses semaines et impactant fortement la consommation électrique ? 

\
\

## Idées pour la modélisation de la consommation horaire

Nous disposons désormais de prévisions semble-t-il solides pour la consommation journalière d'électricité. L'ambition initiale de ce projet était de parvenir à une modélisation horaire. Cependant, la quantité de travail demandée pour les modélisations précédentes ne nous a pas permis de traiter cette question. Qu'à cela ne tienne, nous avons tout de même réfléchi aux différentes façon de traiter la modélisation de la série horaire. Les voici en quelques lignes.

\

Travailler avec les données horaires va faire apparaître une nouvelle saisonnalité dans les données, nous l'avons dit. Deux grandes méthodes permettraient de la traiter. 

- Tout d'abord, il serait possible bien sûr de ré-appliquer le principe que nous avons mis en place pour la modélisation journalière, à savoir de subdiviser encore notre série afin de ne faire face qu'à une saisonnalité. Il est intéressant de noter que c'est ce qui est fait dans plusieurs articles de recherche sur le sujet. Les auteurs de ces derniers, pour une modélisation à très court terme de la consommation d'électricité, font le choix de construire un modèle par jour de la semaine, ou bien un modèle par créneau horaire.

- Une autre option serait d'utiliser notre fonction permettant de modéliser une double saisonnalité ! Et cette fois, cela devrait fonctionner. En effet, en gardant les groupes tels que définis pour la modélisation journalière, la saisonnalité horaire est d'ordre 8, et la saisonnalité hebdomadaire d'ordre 7 x 8 = 56. Ainsi, un modèle SARIMA double d'ordre $\textrm{SARMA}(0,0)(1,0)[8](1,0)[56]$ sera estimé par notre fonction comme un modèle ARMA d'ordre p=64, ce qui est cette fois dans les limites autorisées par la fonction `Arima` comprise dans R. 

`r colorize("**Ainsi, les idées de poursuite d'études pour notre série ne manquent pas, le temps quant à lui oui !**", bleu1)`

\
\
\
\

# Conclusion

---

En découvrant la littérature économétrique relative à la question de la prévision de la consommation d'électricité, nous avions été surpris par sa richesse et sa diversité. Désormais, après ce projet, nous comprenons davantage pourquoi tant a été et continue d'être écrit sur ce sujet. La prévision de la demande d'électricité est un sujet aussi vaste qu'intéressant, tant il comporte de problématiques, d'approches possibles, d'outils à expérimenter pour tenter de capturer au mieux la dynamique complexe de cette série. 

Notre projet était centré autour de la gestion des saisonnalités multiples présentes dans les données. L'approche que nous avons choisie pour y faire face a été la suivante : synthétiser nos données et ajouter progressivement de la complexité à nos séries, et *a fortiori* à nos modèles. Nous avons donc commencé par modéliser et prévoir la série mensuelle de la consommation française d'électricité. Les premiers résultats obtenus étaient bons, et nous on conduit à poursuivre l'analyse en travaillant cette fois sur des données synthétisées à la semaine. Là-encore, notre modélisation est de notre point de vue satisfaisante. Nous avons ensuite voulu nous attaquer à la consommation journalière d'électricité, tout en gardant un horizon de prévision annuel. Comment conjuguer alors saisonnalité annuelle et journalière dans nos données ? Nous avons adopté la solution d'une subdivision de notre série en sous-séries de plus petites tailles, permettant d'ignorer à cette échelle la saisonnalité annuelle. Une fois regroupées, nos différentes prévisions nous ont permis d'aboutir à des chiffres pour l'ensemble de l'année 2020, des résultats qui nous paraissent de qualité. 

Ce projet semestriel de séries temporelles a été sans aucun doute très riche d'enseignement. Il nous a permis de mettre en application les modèles univariés type SARIMA, ainsi que de comprendre les modèles type SARIMAX. Des variables comme la température sont réellement clées pour comprendre et modéliser la série de la consommation d'électricité, et nous avons pu nous en rendre bien compte avec nos données. Nous l'avons également dit en introduction, ce projet nous a permis de travailler longuement sur l'intégration de nouveaux polynômes à un modèle SARMA simple, une intégration dont que nous avons voulu automatiser avec le développement de la fonction `S3ARMA` qui, le lecteur l'aura compris, nous tient à cœur ! 

**Ce projet, bien qu'abouti selon nous, donne réellement envie d'aller plus loin, d'essayer encore de nouvelles choses**, d'expérimenter des modèles supplémentaires. Bien entendu, nous aurions aimé avoir le temps de travailler sur la question des données horaires. Comment aborder cette troisième saisonnalité qui vient s'ajouter à la série ? Nous aurions également aimé mettre en place des modèles supplémentaires, sur lesquels nous avions commencé à travaillé mais qui n'étaient pas assez aboutis pour trouver leur place dans ce compte-rendu. Nous avons par exemple essayé de mettre en place des **modèles de lissage exponentiel**, aux premiers résultats prometteurs, notamment pour ceux permettant de modéliser plusieurs saisonnalités par l'ajout d'équations supplémentaires. Une idée intéressante était également de travailler sur des **méthode de décomposition de notre série**, permettant de prédire chaque composante séparément, et de recomposer finalement nos prévisions. Rob J. Hyndman et George Athanasopoulos présentent ainsi dans leur ouvrage, dans le chapitre consacré aux saisonnalités complexes (*Complex seasonnality*), une décomposition STL multiple permettant de décomposer une série multi-saisonnière. Un simple lissage exponentiel permet ensuite de prédire chaque composante de la série initiale avant de les additionner de nouveau. Une autre piste que nous avions commencé à explorer était **l'utilisation de séries de Fourier**, permettant de capturer plusieurs saisonnalités, une piste prometteuse là-encore. 

Ce sujet semble bien être beaucoup plus vaste que ce à quoi nous nous attendions, tout à la fois bac à sable pour la modélisation tant les choix sont nombreux, que domaine de recherche avancé sur lequel les modèles les plus modernes sont expérimentés. Malgré notre niveau plus proche du bac à sable que du laboratoire de recherche, travailler sur cette question fût passionnant, et les chances sont grandes que nous revenions vers ce sujet à l'avenir, afin de poursuivre et d'enrichir encore notre travail.


\
\
\
\


# Appendix A : Fonction S3ARMA

---

## Fonction `func_S3ARMA_part1`

L'objectif de cette fonction est l'estimation du modèle SARMA triple. Pour y parvenir, plusieurs étapes sont nécessaires. Nous l'avons dit, notre modèle SARMA triple est en fait un modèle ARMA d'ordres élevés. Cependant, tous les ordres de l'ARMA n'ont pas besoin d'être estimés. Prenons un exemple qui va nous permettre de bien comprendre. Considérons le modèle SARMA triple suivant : 

\

$$
\textrm{SARMA}(1,0)(2, 0)[4](1, 0)[7](0, 0)[0] \ \textrm{sans moyenne}
$$

\

Il s'agit en réalité d'un modèle SARMA double. Factorisé en polynômes, il s'écrit de la façon suivante :

\

$$
\underbrace{(1-L)}_{\Phi(L)} \times \underbrace{(1-\phi_{4}L^4 - \phi_8L^8)}_{\Phi_4(L^4)} \times \underbrace{(1-\phi_7L^7)}_{\Phi_7(L^7)} \times X_t = \varepsilon_t
$$

Développons-le :


$$
(1 - \phi_4L^4 - \phi_8L^8 - L + \phi_4L^5 + \phi_8L^9)(1-\phi_7L^7) = \varepsilon_t
$$
$$
(1 - \phi_4L^4 - \phi_8L^8 - L + \phi_4L^5 + \phi_8L^9 -\phi_7L^7 + \phi_7\phi_4L^{11}  + \phi_7\phi_8L^{15} + \phi_7L^8 -\phi_7\phi_4L^{13} -\phi_7\phi_8L^{16})\times X_t = \varepsilon_t
$$

\

Une fois le polynôme complètement développé, on observe qu'il s'agit d'un processus AR(16). Cependant, seuls les retards 1,4,5,7,8,9,11,13,15 et 16 présentent un coefficient non nul, les autres retards pouvant être fixés à 0. Or nous savons qu'il est possible de fixer un certain nombre de retards à 0 lors de l'utilisation de la fonction `Arima`. Pour cela, il suffit de fournir à la fonction le vecteur adéquat pour l'argument `fixed`. 

La fonction `func_S3ARMA_part1` se divise donc en deux grands temps : 

- Le premier consiste à développer automatiquement les polynômes pour identifier les ordres qui doivent être estimés, et former ainsi le vecteur à entrer dans l'argument `fixed`

- Le second consiste quant à lui à estimer le modèle ARMA


\
\

### Définition du vecteur `fixed`

Le lecteur l'aura compris, la partie la plus fastidieuse si elle devait être effectuée à la main serait le développement des polynômes. Nous avons réussi à l'automatiser. Décrivons de la manière la plus simple possible comment. 

- La fonction va créer un total de 8 polynômes : 4 polynômes AR (un non-saisonnier et un pour chaque saisonnalité) et 4 polynômes MA. Pour créer chaque polynôme, on utilise le *package* `multipol` et on exécute une petite boucle comme celle-ci : 

```{r, include=TRUE, eval=FALSE}
vec_AR = c(1) # Le vecteur initial est 1

if(p>0){ # Les opérations ne démarrent que si l'ordre du polynôme est supérieur à 0
  vec_AR = rep(0, p) # On initialise un vecteur de longueur de l'ordre p
  for (i in 1:p){vec_AR[i] = 1} # On remplace chaque coefficient par 1
  vec_AR = c(1, vec_AR) # On ajoute 1 en début de vecteur pour la constante
}

poly_AR = multipol(matrix(vec_AR, ncol=1)) # On crée un objet polynôme
```

\

Prenons un exemple, avec un AR(2) pour la partie non-saisonnière. L'objet `poly_AR` définit par le code ci-dessus est le suivant : 

\

```{r, include=TRUE, echo=FALSE, warnings=FALSE, message=FALSE}
p=2
vec_AR = c(1)

if(p>0){
  vec_AR = rep(0, p)
  for (i in 1:p){vec_AR[i] = 1} 
  vec_AR = c(1, vec_AR)
}

poly_AR = multipol(matrix(vec_AR, ncol=1)) 
poly_AR
```

\

Le polynôme ainsi défini est $(1 + X + X^2)$. Les signes ne sont certes pas cohérents avec l'expression classique d'un polynôme AR. Cependant, il ne faut pas oublier que ce polynôme ne sert qu'au produit avec les autres, afin de trouver les ordres du polynôme final. Ainsi, affecter un coefficient 1 devant chaque $X=L$ permet de simplifier le produit et d'éviter de voir des coefficients disparaître. 

Pour les polynômes AR saisonniers, le principe est le même, à la seule différence que l'on ne considère que les multiples de la saisonnalité. Ci dessous on trouve le code utilisé dans la fonction et un exemple avec un polynôme AR(2) pour un saisonnalité de fréquence 4.

```{r, include=TRUE, warning=FALSE, message=FALSE}
p_s1 = 2 # Ordre du AR saisonnier
saison1 = 4 # Fréquence de la saisonnalité s1

vec_AR_s1 = c(1) # Polynôme initialisé à 1

if(p_s1>0){ # Les opérations ne démarrent que si l'ordre AR saisonnier est supérieur à 0
  vec_AR_s1 = rep(0, p_s1*saison1) 
  for (i in 1:p_s1){vec_AR_s1[i*saison1] = 1} # On remplace chaque coefficient 
                                              # multiple de s1 par 1
  vec_AR_s1 = c(1, vec_AR_s1) # Ajout de 1 en début de vecteur pour la constante
}

poly_AR_s1 = multipol(matrix(vec_AR_s1, ncol=1)) # Création de l'objet polynôme
poly_AR_s1
```

\

Nous obtenons donc bien un polynôme $(1+ X^4 + X^8)$. 

La fonction `func_S3ARMA_part1` effectue ce travail pour les 8 polynômes cités précédemment, puis calcule les produits de tous les polynômes AR entre eux et de tous les polynômes MA entre eux. Une fois ces opérations effectuées, elle récupère la forme finale des parties AR et MA à partir des coefficients non-nuls des polynômes multipliés. 

Illustrons-cela par un exemple, pour un modèle $\textrm{SARMA}(2,0)(2,0)[4]$. Nous avons donc calculé nos deux polynômes AR, et il n'y a pas de partie MA dans ce modèle. La fonction fait donc le produit de nos deux polynômes : 

```{r}
poly_prod_AR = poly_AR * poly_AR_s1 # Produit des polynômes AR
poly_prod_AR # Forme du polynôme AR final
```

\

On obtient donc un polynôme de degré 10, avec seulement les termes $X^3$ et $X^7$ dont les coefficients doivent être fixés à 0. 

Ainsi, la dernière étape pour notre fonction avant l'estimation consiste à créer le vecteur `fixed ` à partir des polynômes `poly_prod_AR` et `poly_prod_MA`. Pour chacun des polynômes, elle retire la partie constante, puis elle remplace les coefficients 1 par `NA`, et concatène les deux polynômes en un vecteur. Enfin, elle ajoute un dernier terme au nouveau vecteur concaténé, correspondant à l'estimation d'une moyenne ou non (une valeur `NA` ou 0). 

Pour notre exemple, le vecteur `fixed` est le suivant : 

```{r}
fixed_AR = poly_prod_AR[,0][-1] # On retire le premier coefficient (partie constante)
fixed_AR = replace(fixed_AR, fixed_AR==1, NA) # Remplacement des 1 par des NA

fixed_MA = c() # Pas de partie MA
vec_mean = c(0) # On ne veut pas estimer de moyenne

fixed_ARMA = c(fixed_AR, fixed_MA, vec_mean) # Construction du vecteur fixed
fixed_ARMA
```

\

Le vecteur `fixed_ARMA` est donc, pour notre exemple, le suivant : 

$$
\texttt{fixedARMA} = \texttt{c(} \underbrace{\texttt{NA,NA,0,NA,NA,NA,0,NA,NA,NA}}_{\textrm{Partie AR}}\texttt{,} \underbrace{\texttt{0}}_{\textrm{Moyenne}} \texttt{)}
$$

Il ne reste donc plus qu'à estimer notre modèle !

\
\

### Estimation du modèle ARMA

L'estimation du modèle ARMA correspondant à notre modélisation SARMA multiple est bien plus simple que la partie précédente. On utilise bien sûr pour cela la fonction `Arima`, que l'on configure correctement avec les paramètres suivants : 

- `serie` : La série à modéliser. `r colorize("À noter que la série doit être différenciée saisonnièrement avant d'utiliser la fonction", rouge1)` `func_S3ARMA_part1` (potentiellement une différenciation par saisonnalité). La fonction n'est pas prévue en l'état pour différencier elle-même la série saisonnièrement. Cependant, elle peut effectuer une dernière différenciation simple, si tant est que la série différenciée saisonnièrement ne soit pas stationnaire. Dans ce cas, l'utilisateur peut fixer le paramètre `d` = 1 dans la fonction. C'est le même principe que pour n'importe quel modèle ARIMA. 

- `length(fixed_AR)` et `length(fixed_MA)` : Ces paramètres correspondent à l'ordre du modèle ARMA. Ils sont fixés automatiquement à partir de la longueur des vecteurs `fixed_AR` et `fixed_MA` (nous les avons construits pour cela !)

- `fixed` : Notre vecteur `fixed_ARMA` est utilisé pour cet argument. 

- `include.mean` : L'utilisateur précise dans les paramètres de la fonction s'il souhaite estimer ou non un modèle avec moyenne (`TRUE` ou `FALSE`). Son choix est pris en compte, nous l'avons vu, dans la construction du vecteur `fixed`.

- `method` : Enfin, l'utilisateur peut choisir la méthode d'estimation. Par défaut, l'estimation se fait par maximum de vraisemblance (`method = "ML"`). Ce choix s'explique par un nombre d'échecs d'estimation moins important pour cette méthode. 

```{r, include=TRUE, eval=FALSE}
Arima(serie, # Série à étudier
      order = c(length(fixed_AR), d, length(fixed_MA)), # Ordres du ARIMA
      fixed = fixed_ARMA, # Vecteur fixed calculé précédemment
      include.mean = mean, # Inclure une moyenne ou non
      method = method) # Méthode d'estimation 
```

\

Une fois l'estimation effectuée, la fonction fournit en sortie une liste composée de :

1. Le nom du modèle que l'on vient d'estimer, construit selon la terminologie présentée plus haut pour les modèles SARMA triples. 

2. Le modèle ARIMA estimé.

\
\

## Fonction `func_S3ARMA_part2`

L'objectif de cette seconde fonction est de faciliter la vie de l'utilisateur, en rendant plus lisibles les résultats de la fonction précédente. Ainsi, la fonction `func_S3ARMA_part2` prend comme *inputs* les *outputs* de la fonction `func_S3ARMA_part1`, et les transforme. Nous ne détaillons pas ici les étapes de transformation, car assez simples et faciles à comprendre en lisant le code. De manière synthétique : 


- La fonction propose tout d'abord une table regroupant l'ensemble des coefficients estimés du modèle ARIMA. Les coefficients fixés à 0 n'apparaissent pas, facilitant ainsi la lecture. Pour chacun de ces coefficients, la fonction récupère l'erreur-standard, qu'elle ajoute à la table. Elle propose également une analyse rapide de la significativité de chaque coefficient. La règle mise en place est la suivante. Pour chaque coefficient $i$ du modèle, noté $C_i$ et d'erreur standard ($S.E.(C_i)$), on considère le coefficient comme significatif si :

\

$$
|C_i| - 2\times |S.E.(C_i)| > 0 
$$

\

Dans la table de résultat fournie, une étoile est affichée pour chaque coefficient considéré comme significatif à partir de cette règle de décision. 

- La fonction `func_S3ARMA_part2` fournit enfin un second petit tableau qui comporte le nom du modèle, l'AICc de ce dernier, la taille du modèle (nombre de coefficients estimés) et enfin le pourcentage de coefficients significatifs par rapport au nombre total de coefficients estimés.

\
\

## La fonction `func_S3ARMA_part3`

Cette troisième partie de la fonction se caractérise par une idée simple, mais un code assez lourd. À ce stade, nous avons donc estimé notre modèle SARMA multiple sur notre série différenciée saisonnièrement (potentiellement trois fois), et nous avons une idée de sa qualité grâce à la fonction `func_S3ARMA_part2`. La dernière étape consiste à produire des prévisions, et pas seulement sur la série différenciée, mais bien sur la série initiale. Comment procéder ? 

*Note : On ne parle ici que des différenciations saisonnières. La différenciation simple évoquée pour la partie `func_S3ARMA_part1` est traitée automatiquement par la fonction `forecast`*

Notre modèle est estimé sur la série différenciée. Prenons l'exemple d'un modèle SARMA simple, avec une saisonnalité $s_1$ de fréquence 4, et un modèle $\textrm{SARMA}(1,0)(1,0)[4]$. Notre modèle s'écrit : 

\

$$
X_t' = \phi_4 X'_{t-4} + \phi X'_{t-1} - \phi \phi_4 X'_{t-5} + \varepsilon_t
$$

\

Le lecteur se demande sûrement pourquoi un symbole prime est apparu au côté des $X_t$. Il s'agit tout simplement de signifier que $X_t'$ correspond à la série différenciée saisonnièrement. En effet, la série utilisée pour estimer ce modèle est la série différenciée saisonnièrement (fréquence 4). On a donc : 

\

$$
X_t' = X_t - X_{t-4}
$$

\

Une fois que l'on connaît la valeur estimée de $X_t'$, on peut facilement retrouver la valeur estimée de $X_t$ de la façon suivante : 

\

$$
X_t = X_t' + X_{t-4}
$$

\

À noter que pour des prévisions où l'horizon temporel serait suffisamment éloigné pour que l'on ne connaisse pas la vraie valeur de $X_{t-4}$, on remplacerait cette dernière par sa valeur prédite, $\hat X_{t-4}$.  Ainsi, on peut facilement retrouver la valeur prédite de la série à partir de la valeur prédite de la série différenciée. Le principe reste le même lorsque l'on différencie deux ou trois fois saisonnièrement la série. Par exemple, pour une double différenciation saisonnières (fréquences 4 et 7), on obtient : 

\

$$
\begin{aligned}
X_t' &= X_t - X_{t-4} \\
X_t'' &= X_t' - X_{t-7}' \\
      &= X_t - X_{t-4} - \left(X_{t-7} - X_{t-4-7}\right) \\
X_t'' &= X_t - X_{t-4} - X_{t-7} + X_{t-11} 
\end{aligned}
$$

\

Le principe est le même pour retrouver la valeur estimée de $X_t$ à partir des autres paramètres. La démarche est également similaire avec une triple différenciation. 

Notre fonction `func_S3ARMA_part3` applique ainsi ce principe. Elle commence par calculer les prévisions du modèle sur la série différenciée saisonnièrement, en utilisant le *package* `forecast`, puis elle transforme ces prévisions pour retrouver les valeurs non-différenciées. Elle fait la même chose pour les intervalles de prévision : tant que les vraies valeurs de $X_t$ sont disponibles, les transformations sont effectuées en utilisant ces dernières, puis une fois un horizon temporel trop lointain atteint, on utilise les valeurs estimées des intervalles de prévision précédents. Nous ne détaillons pas plus le code, car il n'y a rien de technique, simplement de la manipulation de séries et de séries retardées, auxquelles on ajoute progressivement nos prévisions. 

\
\

## Note sur l'efficacité de ces trois fonctions

Avant de présenter la quatrième et dernière fonction, il est utile de préciser que nous avons bien entendu testé nos trois fonctions précédentes. Pour l'estimation du modèle ARIMA, elles fonctionnent parfaitement (`func_S3ARMA_part1`). Pour le savoir, nous avons comparé les résultats obtenus par notre fonction et par la fonction SARIMA de R (fonction `Arima` pour laquelle on précise un ordre dans le paramètre `seasonal`). L'estimation d'un modèle SARMA simple par notre fonction ou par la méthode habituelle R conduit exactement aux mêmes résultats, nous retrouvons les mêmes coefficients (voir plus loin les tests sur données simulées). 

Pour la partie prévisions, les points moyens de prévision sont également bien dé-transformés à partir de la série différenciée saisonnièrement. Ce que la fonction `forecast` fait automatiquement à partir d'un modèle SARIMA R avec différenciation saisonnière, notre modèle `func_S3ARMA_part3` le fait de la même manière, puisque nous retrouvons les mêmes prévisions. Le seul bémol concerne les intervalles de prévision. À partir d'un certain horizon temporel, nos intervalles sont bien plus larges que ceux calculés automatiquement. Nous n'en n'avons pas à ce jour trouvé l'explication, excepté l'idée que ce que fait automatiquement la fonction `forecast` n'est pas de dé-transformer les intervalles de prévision de la même manière que pour les points de prévision, mais de les recalculer. Cependant, nous pensons que cela ne remet pas en cause nos fonctions : l'estimation du modèle est correcte, la prévision sur la série différenciée l'est également, et les points de prévisions sur la série initiale sont aussi corrects. Il s'agit simplement de considérer avec un certain recul critique les intervalles de prévision obtenus pour la série non-différenciée. 

\
\

## La fonction `func_S3ARMA_part4`

La dernière partie de notre fonction `S3ARMA` a pour but de répondre à la question suivante : comment trouver le meilleur modèle SARMA multiple pour notre série temporelle ? La lecture d'un graphique ACF/PACF n'est pas toujours aisée, et nous avons souhaité construire une fonction similaire à la fonction `auto.arima` dans R. L'idée est simple : l'utilisateur fournit à la fonction un ensemble de modèles à tester, la fonction les estime tous et renvoie la liste des résultats, triée du meilleur modèle au moins bon. Pour cela, l'utilisateur peut utiliser le code suivant, qui permet de générer toutes les combinaisons possibles en fonction de ce qu'il fixe. Dans cet exemple, on souhaite estimer toutes les combinaisons possibles pour un SARMA triple avec les ordres AR pouvant aller jusqu'à 1, aucune partie MA. 

```{r, include=TRUE, collapse=TRUE}
# Code pour créer une liste de combinaisons à estimer
list_combinaisons = expand.grid(p = c(0:1),
                                q = c(0:1),
                                # Première saisonnalité
                                p_s1 = c(0:1),
                                q_s1 = c(0:0),
                                # Seconde saisonnalité
                                p_s2 = c(0:1),
                                q_s2 = c(0:0),
                                # Troisième saisonnalité
                                p_s3 = c(0:1),
                                q_s3 = c(0:0),
                                # Moyenne
                                mean = c(TRUE, FALSE))

# Résultats (head)
head(list_combinaisons)

# Résultats (tail)
tail(list_combinaisons)
```

\

L'utilisateur n'a ainsi qu'à fournir une liste de cette forme ainsi que la fréquence de chaque saisonnalité (possible de fixer 0 pour des modèles SARMA simples ou doubles). La fonction `func_S3ARMA_part4` se lance alors dans une boucle d'estimation de chaque modèle, et affiche le résultat une fois terminé. 

Bien entendu, cette méthode n'est pas optimale : tester toutes les possibilités est rarement la meilleure méthode en informatique, et le calcul peut s'avérer particulièrement long. En effet, analyse combinatoire oblige, le nombre de possibilités avec des ordre élevés croit de manière exponentielle. À titre d'exemple, si l'on reprend notre exemple précédent en autorisant en plus cette fois pour chaque saisonnalité et pour la partie non-saisonnière un terme MA d'ordre 1 maximum, la fonction doit estimer 512 possibilités !

\
\

## Code des fonctions

Dans cette partie du projet l'utilisateur trouvera les codes R des quatre fonctions que nous venons de présenter. Nous ne les intégrons pas au rendu HTML afin de ne pas alourdir le fichier. 

```{r func_S3ARMA_part1, include=FALSE}
func_S3ARMA_part1 = function(serie, # Série à étudier
                          p = 0, q = 0, d=0, # Paramètres (p,d,q) non-saisonniers
                          saison1 = 0, p_s1 = 0, q_s1 = 0, # (p,q) saisonnalité n1
                          saison2 = 0, p_s2 = 0, q_s2 = 0, # (p,q) saisonnalité n2
                          saison3 = 0, p_s3 = 0, q_s3 = 0, # (p,q) saisonnalité n3
                          mean = FALSE, # Inclure une moyenne
                          method = "ML", # Méthode d'estimation
                          messages = TRUE # Afficher des messages de suivi
                          ){
  
  ############################# -
  ### PARTIE I - ESTIMATION ### -
  ############################# -
  
  ################# -
  # Nom du modèle # -
  ################# -
  
  nom_modele = paste0("SARMA(", p, ",", q, ")",
                      "(", p_s1, ",", q_s1, ")[", saison1, "]",
                      "(", p_s2, ",", q_s2, ")[", saison2, "]",
                      "(", p_s3, ",", q_s3, ")[", saison3, "]")
  
  if(mean == TRUE){nom_modele = paste(nom_modele, "avec moyenne")}
  
  ########### -
  # Moyenne # -
  ########### -
  
  vec_mean = c()
  if(mean==TRUE){vec_mean = c(NA)}
  
  ############# -
  # Partie AR # -
  ############# -
  
  # AR non-saisonnier
  # ----------------- #
  vec_AR = c(1)
  
  if(p>0){
    vec_AR = rep(0, p)
    for (i in 1:p){vec_AR[i] = 1} 
    vec_AR = c(1, vec_AR)
  }
  
  poly_AR = multipol(matrix(vec_AR, ncol=1)) 
  poly_AR
  
  # AR Saisonnalité 1
  # ----------------- #
  vec_AR_s1 = c(1)
  
  if(p_s1>0){
    vec_AR_s1 = rep(0, p_s1*saison1)
    for (i in 1:p_s1){vec_AR_s1[i*saison1] = 1} 
    vec_AR_s1 = c(1, vec_AR_s1) 
  }
  
  poly_AR_s1 = multipol(matrix(vec_AR_s1, ncol=1))
  poly_AR_s1
  
  # AR Saisonnalité 2
  # ----------------- #
  vec_AR_s2 = c(1)
  
  if(p_s2>0){
    vec_AR_s2 = rep(0, p_s2*saison2) 
    for (i in 1:p_s2){vec_AR_s2[i*saison2] = 1} 
    vec_AR_s2 = c(1, vec_AR_s2) 
  }
  
  poly_AR_s2 = multipol(matrix(vec_AR_s2, ncol=1))
  poly_AR_s2

  # AR Saisonnalité 3 
  # ----------------- #
  vec_AR_s3 = c(1)
  
  if(p_s3>0){
    vec_AR_s3 = rep(0, p_s3*saison3) 
    for (i in 1:p_s3){vec_AR_s3[i*saison3] = 1} 
    vec_AR_s3 = c(1, vec_AR_s3) 
  }
  
  poly_AR_s3 = multipol(matrix(vec_AR_s3, ncol=1))
  poly_AR_s3
  
  ############# -
  # Partie MA # -
  ############# -

  # MA non-saisonnier
  # ----------------- #
  vec_MA = c(1)
  
  if(q>0){
    vec_MA = rep(0, q) 
    for (i in 1:q){vec_MA[i] = 1} 
    vec_MA = c(1, vec_MA)
  }
  
  poly_MA = multipol(matrix(vec_MA, ncol=1))
  poly_MA
  
  # MA Saisonnalité 1
  # ----------------- #
  vec_MA_s1 = c(1)
  
  if(q_s1>0){
    vec_MA_s1 = rep(0, q_s1*saison1) 
    for (i in 1:q_s1){vec_MA_s1[i*saison1] = 1}
    vec_MA_s1 = c(1, vec_MA_s1)
  }
  
  poly_MA_s1 = multipol(matrix(vec_MA_s1, ncol=1)) 
  poly_MA_s1
  
  # MA Saisonnalité 2
  # ----------------- #
  vec_MA_s2 = c(1)
  
  if(q_s2>0){
    vec_MA_s2 = rep(0, q_s2*saison2) 
    for (i in 1:q_s2){vec_MA_s2[i*saison2] = 1} 
    vec_MA_s2 = c(1, vec_MA_s2) 
  }
  
  poly_MA_s2 = multipol(matrix(vec_MA_s2, ncol=1)) 
  poly_MA_s2

  # MA Saisonnalité 3
  # ----------------- #
  vec_MA_s3 = c(1)
  
  if(q_s3>0){
    vec_MA_s3 = rep(0, q_s3*saison3) 
    for (i in 1:q_s3){vec_MA_s3[i*saison3] = 1} 
    vec_MA_s3 = c(1, vec_MA_s3) 
  }
  
  poly_MA_s3 = multipol(matrix(vec_MA_s3, ncol=1)) 
  poly_MA_s3
  
  ######################### -
  # Produit des polynômes # -
  ######################### -
  
  # Partie AR
  poly_prod_AR = poly_AR * poly_AR_s1 * poly_AR_s2 * poly_AR_s3
  poly_prod_AR
  
  # Partie MA
  poly_prod_MA = poly_MA * poly_MA_s1 * poly_MA_s2 * poly_MA_s3
  poly_prod_MA
  
  ################################### -
  # Construction des vecteurs fixed # -
  ################################### -
  
  # Objectif : Récupérer l'identifiant de tous les retards du polynôme
  fixed_AR = poly_prod_AR[,0][-1] # On retire le premier coefficient (partie constante)
  fixed_AR = replace(fixed_AR, fixed_AR==1, NA) # Remplacement des 1 par des NA pour estimation

  fixed_MA = poly_prod_MA[,0][-1]
  fixed_MA = replace(fixed_MA, fixed_MA==1, NA)

  # Construction du vecteur fixed complet pour l'estimation
  fixed_ARMA = c(fixed_AR, fixed_MA, vec_mean)
  fixed_ARMA
  
  #################### -
  # Message de suivi # -
  #################### -
  
  if(messages == TRUE){
    # Présentation de la fonction
    cat("\n")
    cat("####################### \n")
    cat("### Fonction S3ARMA ### \n")
    cat("####################### \n")
    cat("\n")
    cat("Modèle SARMA à saisonnalités multiples \n")
    cat("Version 2.0 \n")
    cat("Paul BOUST \n")
    cat("\n")
    cat("Partie I - Estimation \n")
    cat("--------------------- \n\n")
    cat(paste("Heure de début :", Sys.time(), "\n\n"))
    
    # Message avant (longue) estimation du modèle
    cat("Je réfléchis ... Vous avez le temps pour un petit café ! ") 
    cat("\U0002615 \n")
  }
  
  ################### -
  # Estimation ARMA # -
  ################### - 
  
  # Estimation ARIMA
  modele <- tryCatch(Arima(serie,
                    order = c(length(fixed_AR), d, length(fixed_MA)),
                    fixed = fixed_ARMA,
                    include.mean = mean,
                    method = method),
                  error = function(c){return(NA)})
  
  ############# -
  # Résultats # -
  ############# -
  
  # Message de fin d'estimation
  if(messages==TRUE){
    cat("Je crois avoir trouvé ! \n\n")
    cat("### Fin d'éxécution \n")}
  
  return(list("Nom_modele" = nom_modele,
              "Resultats" = modele))
  
}
```

```{r func_S3ARMA_part2, include=FALSE}
func_S3ARMA_part2 = function(modele, # Élement [[2]] de l'output de S3ARMA_part1
                             nom_modele = NA, # Élement [[1]] de l'output de S3ARMA_part1
                             messages = TRUE # Messages de suivi
                             ){
  
  ########################################## -
  ### PARTIE II  - Analyse des résultats ### -
  ########################################## -

  #################### -
  # Message de suivi # -
  #################### -
  
  if(messages == TRUE){
  
    # Présentation de la fonction
    cat("\n")
    cat("####################### \n")
    cat("### Fonction S3ARMA ### \n")
    cat("####################### \n")
    cat("\n")
    cat("Modèle SARMA à saisonnalités multiples \n")
    cat("Version 2.0 \n")
    cat("Paul BOUST \n")
    cat("\n")
    cat("Partie II - Synthèse \n")
    cat("-------------------- \n\n")
  } 
  
  ################## -
  # Initialisation # -
  ################## -
  
  modele_aicc = NA
  taille_modele = NA
  significativite_score = NA
  
  df_coefficients = data.frame("Estimate" = NA,
                               "S.E." = NA,
                               "Sig." = ".")
  
  ############################ - 
  # Récupération des données # -
  ############################ - 
  
  coefficients_modele = tryCatch(round(modele$coef[modele$coef!=0], 4), 
                                 error = function(c){return(NA)})
  
  variance_coef = tryCatch(modele$var.coef, 
                           error = function(c){return(NA)})
  
  ########### -
  # Analyse # -
  ########### -
  
  # On se débarrasse de tous les cas où cela ne marche pas :
    # - Aucun coefficient non-nul 
    # - Le modèle fourni est NA
  
  if((length(coefficients_modele) > 0 & 
      length(variance_coef) > 0 &
      all(is.na(coefficients_modele) == FALSE) &
      all(is.na(variance_coef) == FALSE)) == TRUE){
    
    # Calcul des erreur standard
    standard_error = tryCatch(round(sqrt(diag(variance_coef)), 4), 
                              error = function(c){return(NA)})
    
    # Construction d'une data.frame
    df_coefficients = data.frame("Estimate" = coefficients_modele,
                                 "S.E." = standard_error,
                                 "Sig." = ".")
    
    # On calcule quels coefficients sont significatifs
    # On considère significatif car le coefficient est superieur a deux fois la s.e. (abs)
    for (i in 1:length(df_coefficients$Estimate)){
      
      # Test de significativité
      test_significativite = abs(df_coefficients$Estimate[i]) - 2*abs(df_coefficients$S.E.[i]) > 0
      
      if(test_significativite == TRUE & is.na(test_significativite) == FALSE){df_coefficients$Sig.[i] = "*"}
    }
    
    # Calcul de petits indicateurs supplémentaires
    # AICc
    modele_aicc = modele$aicc 
    
    # Nombre de coefficients du modèle (pour parcimonie)
    taille_modele = length(modele$coef[modele$coef!=0])
    
    # Pourcentage de coefficients significatifs
    significativite_score = length(df_coefficients$Sig.[df_coefficients$Sig.=="*"]) / taille_modele * 100
  }
  
  ######################################## -
  # Construction de la table de résultat # -
  ######################################## -
  
  results_df = data.frame("Modele" = nom_modele,
                          "AICc" = modele_aicc,
                          "Nb.coefs" = taille_modele,
                          "Sig.score" = significativite_score)
  
  ############# -
  # Résultats # -
  ############# -
  
  if(messages==TRUE){cat("### Fin d'éxécution \n")}
  
  return(list("Coefficients" = df_coefficients,
              "Synthese" = results_df))

}
```

```{r func_S3ARMA_part3, include=FALSE}
func_S3ARMA_part3 = function(modele, # Élément [[2]] de l'output de S3ARMA_part1
                             nom_modele=NA, # Élément [[1]] de l'output de S3ARMA_part1
                             horizon = 200, # Horizon de prévision
                             level=c(80,95), # Niveau des intervalles de prévision
                             serie_init, # Série non-différenciée
                             d1=0, d2=0, d3=0, # Niveaux de différenciation saisonnière
                             messages=TRUE # Messages de suivi
                             ){
  
  ################################ -
  ### PARTIE III  - Prévisions ### -
  ################################ -
  
  #################### -
  # Message de suivi # -
  #################### -
  
  if(messages == TRUE){
  
    # Présentation de la fonction
    cat("\n")
    cat("####################### \n")
    cat("### Fonction S3ARMA ### \n")
    cat("####################### \n")
    cat("\n")
    cat("Modèle SARMA à saisonnalités multiples \n")
    cat("Version 2.0 \n")
    cat("Paul BOUST \n")
    cat("\n")
    cat("Partie III - Dé-différenciations et Prévisions \n")
    cat("---------------------------------------------- \n\n")
  }   
  
  ######################### -
  # Calcul des prévisions # -
  ######################### -
  
  # Modèle ARIMA sur la série différenciée
  # On peut donc calculer les prévisions facilement
  
  fc = forecast(modele, h = horizon, level = level)
  
  # L'objectif est désormais de dé-différencier la série, les prévisions et les intervalles
  
  ################## -
  # Initialisation # -
  ################## -
  
  # Transformation de la série en vecteur
  serie = as.vector(serie_init)
  
  # Trois cas de figure possibles
  
    ########################################## -
    ### Différenciation saisonnière simple ### -
    ########################################## -
    
    if(d1>0 & d2==0 & d3==0){
      
      # On utilise une data.frame pour les prévisions
      df1 = data.frame(# On récupère les valeurs estimées différenciées 
                       "Xt_prime_hat" = c(rep(NA, length(serie) - length(fc$fitted)),
                                          as.vector(fc$fitted), 
                                          as.vector(fc$mean)),
                       
                       # On récupère les intervalles de prévision différenciés
                       "Upper1_prime" = c(serie, as.vector(fc$upper[,1])),
                       "Upper2_prime" = c(serie, as.vector(fc$upper[,2])),
                       "Lower1_prime" = c(serie, as.vector(fc$lower[,1])),
                       "Lower2_prime" = c(serie, as.vector(fc$lower[,2])),
                       
                       # On récupère la série initiale
                       "Xt" = c(serie, rep(NA, horizon)),
                       
                       # Que l'on différencie
                       "Xt_d1" = c(lag(serie, d1), rep(NA, horizon)))
      
      # Calcul des valeurs estimées dé-différenciées (fitted values)
      # Formule dans la documentation mathématique de la fonction
      df1$Xt_hat = df1$Xt_prime_hat + df1$Xt_d1
  
      # Valeurs futures dé-différenciées (prévisions et intervalles)
    
      last_observation = length(serie)
      
      for (i in (last_observation + 1):(last_observation + horizon)){
        
        # Remplir la série différenciée
        if(is.na(df1$Xt[i-d1]) == FALSE){df1$Xt_d1[i] = df1$Xt[i-d1]}
        if(is.na(df1$Xt[i-d1]) == TRUE){df1$Xt_d1[i] = df1$Xt_hat[i-d1]}
    
        # Calcul des prévisions
        df1$Xt_hat[i] = df1$Xt_prime_hat[i] + df1$Xt_d1[i]
        
        # Calcul des intervalles de prédiction
        # Note : Intervalles de prédiction améliorables
        df1$Upper1[i] = df1$Upper1_prime[i] + df1$Upper1[i-d1]
        df1$Upper2[i] = df1$Upper2_prime[i] + df1$Upper2[i-d1]
        df1$Lower1[i] = df1$Lower1_prime[i] + df1$Lower1[i-d1]
        df1$Lower2[i] = df1$Lower2_prime[i] + df1$Lower2[i-d1]
      }
    }

    ########################################## -
    ### Différenciation saisonnière double ### -
    ########################################## -

    # Les étapes sont similaires
  
    if(d1>0 & d2>0 & d3==0){
      
      # Data.frame
      df1 = data.frame("Xt_2prime_hat" = c(rep(NA,  length(serie) - length(fc$fitted)),
                                          as.vector(fc$fitted), 
                                          as.vector(fc$mean)),
                       "Upper1_2prime" = c(serie, as.vector(fc$upper[,1])),
                       "Upper2_2prime" = c(serie, as.vector(fc$upper[,2])),
                       "Lower1_2prime" = c(serie, as.vector(fc$lower[,1])),
                       "Lower2_2prime" = c(serie, as.vector(fc$lower[,2])),
                      
                       "Xt" = c(serie, rep(NA, horizon)),
                       
                       "Xt_d1" = c(lag(serie, d1), rep(NA, horizon)),
                       "Xt_d2" = c(lag(serie, d2), rep(NA, horizon)),
                       "Xt_d1_d2" = c(lag(serie, d1+d2), rep(NA, horizon)))
      
      # Valeurs estimées dé-différenciées
      df1$Xt_hat = df1$Xt_2prime_hat + df1$Xt_d1 + df1$Xt_d2 - df1$Xt_d1_d2

      # Valeurs futures dé-différenciées (prévisions et intervalles)
      last_observation = length(serie)
      
      for (i in (last_observation + 1):(last_observation + horizon)){
        
        # Remplir les séries différenciées
        # Série Xt-d1
        if(is.na(df1$Xt[i-d1]) == FALSE){df1$Xt_d1[i] = df1$Xt[i-d1]}
        if(is.na(df1$Xt[i-d1]) == TRUE){df1$Xt_d1[i] = df1$Xt_hat[i-d1]}
        # Série Xt-d2
        if(is.na(df1$Xt[i-d2]) == FALSE){df1$Xt_d2[i] = df1$Xt[i-d2]}
        if(is.na(df1$Xt[i-d2]) == TRUE){df1$Xt_d2[i] = df1$Xt_hat[i-d2]}    
        # Série Xt-d1-d2
        if(is.na(df1$Xt[i-d1-d2]) == FALSE){df1$Xt_d1_d2[i] = df1$Xt[i-d1-d2]}
        if(is.na(df1$Xt[i-d1-d2]) == TRUE){df1$Xt_d1_d2[i] = df1$Xt_hat[i-d1-d2]}            
        
        # Calcul des prévisions
        df1$Xt_hat[i] = df1$Xt_2prime_hat[i] + df1$Xt_d1[i] + df1$Xt_d2[i] - df1$Xt_d1_d2[i]
        
        # Calcul des intervalles de prédiction
        # Note : Intervalles de prédiction améliorables
        df1$Upper1[i] = df1$Upper1_2prime[i] + df1$Upper1[i-d1] + df1$Upper1[i-d2] - df1$Upper1[i-d1-d2]
        df1$Upper2[i] = df1$Upper2_2prime[i] + df1$Upper2[i-d1] + df1$Upper2[i-d2] - df1$Upper2[i-d1-d2]
        df1$Lower1[i] = df1$Lower1_2prime[i] + df1$Lower1[i-d1] + df1$Lower1[i-d2] - df1$Lower1[i-d1-d2]
        df1$Lower2[i] = df1$Lower2_2prime[i] + df1$Lower2[i-d1] + df1$Lower2[i-d2] - df1$Lower2[i-d1-d2]
      }
    }

    ########################################## -
    ### Différenciation saisonnière triple ### -
    ########################################## -

    # Les étapes sont similaires
  
    if(d1>0 & d2>0 & d3>0){
      
      # Data.frame
      df1 = data.frame("Xt_3prime_hat" = c(rep(NA,  length(serie) - length(fc$fitted)),
                                          as.vector(fc$fitted), 
                                          as.vector(fc$mean)),
                       "Upper1_3prime" = c(serie, as.vector(fc$upper[,1])),
                       "Upper2_3prime" = c(serie, as.vector(fc$upper[,2])),
                       "Lower1_3prime" = c(serie, as.vector(fc$lower[,1])),
                       "Lower2_3prime" = c(serie, as.vector(fc$lower[,2])),
                      
                       "Xt" = c(serie, rep(NA, horizon)),
                       
                       "Xt_d1" = c(lag(serie, d1), rep(NA, horizon)),
                       "Xt_d2" = c(lag(serie, d2), rep(NA, horizon)),
                       "Xt_d3" = c(lag(serie, d3), rep(NA, horizon)),
                       "Xt_d1_d2" = c(lag(serie, d1+d2), rep(NA, horizon)),
                       "Xt_d1_d3" = c(lag(serie, d1+d3), rep(NA, horizon)),
                       "Xt_d2_d3" = c(lag(serie, d2+d3), rep(NA, horizon)),
                       "Xt_d1_d2_d3" = c(lag(serie, d1+d2+d3), rep(NA, horizon)))
      
      # Valeurs estimées dé-différenciées
      df1$Xt_hat = df1$Xt_3prime_hat + df1$Xt_d1 + df1$Xt_d2 + df1$Xt_d3 - df1$Xt_d1_d2 - df1$Xt_d1_d3 - df1$Xt_d2_d3 + df1$Xt_d1_d2_d3

      # Valeurs futures dé-différenciées (prévisions et intervalles)
      last_observation = length(serie)
      
      for (i in (last_observation + 1):(last_observation + horizon)){
        # Remplir la série différenciée
        # Série Xt-d1
        if(is.na(df1$Xt[i-d1]) == FALSE){df1$Xt_d1[i] = df1$Xt[i-d1]}
        if(is.na(df1$Xt[i-d1]) == TRUE){df1$Xt_d1[i] = df1$Xt_hat[i-d1]}
          # Série Xt-d2
        if(is.na(df1$Xt[i-d2]) == FALSE){df1$Xt_d2[i] = df1$Xt[i-d2]}
        if(is.na(df1$Xt[i-d2]) == TRUE){df1$Xt_d2[i] = df1$Xt_hat[i-d2]}
        # Série Xt-d3
        if(is.na(df1$Xt[i-d3]) == FALSE){df1$Xt_d3[i] = df1$Xt[i-d3]}
        if(is.na(df1$Xt[i-d3]) == TRUE){df1$Xt_d3[i] = df1$Xt_hat[i-d3]} 
        
        # Série Xt-d1-d2
        if(is.na(df1$Xt[i-d1-d2]) == FALSE){df1$Xt_d1_d2[i] = df1$Xt[i-d1-d2]}
        if(is.na(df1$Xt[i-d1-d2]) == TRUE){df1$Xt_d1_d2[i] = df1$Xt_hat[i-d1-d2]}            
        # Série Xt-d1-d3
        if(is.na(df1$Xt[i-d1-d3]) == FALSE){df1$Xt_d1_d3[i] = df1$Xt[i-d1-d3]}
        if(is.na(df1$Xt[i-d1-d3]) == TRUE){df1$Xt_d1_d3[i] = df1$Xt_hat[i-d1-d3]}
        # Série Xt-d2-d3
        if(is.na(df1$Xt[i-d2-d3]) == FALSE){df1$Xt_d2_d3[i] = df1$Xt[i-d2-d3]}
        if(is.na(df1$Xt[i-d2-d3]) == TRUE){df1$Xt_d2_d3[i] = df1$Xt_hat[i-d2-d3]}   
        
        # Série Xt-d1-d2-d3
        if(is.na(df1$Xt[i-d1-d2-d3]) == FALSE){df1$Xt_d1_d2_d3[i] = df1$Xt[i-d1-d2-d3]}
        if(is.na(df1$Xt[i-d1-d2-d3]) == TRUE){df1$Xt_d1_d2_d3[i] = df1$Xt_hat[i-d1-d2-d3]}  
        
        # Calcul des prévisions
        df1$Xt_hat[i] = df1$Xt_3prime_hat[i] + df1$Xt_d1[i] + df1$Xt_d2[i] + df1$Xt_d3[i] - df1$Xt_d1_d2[i] - df1$Xt_d1_d3[i] - df1$Xt_d2_d3[i] + df1$Xt_d1_d2_d3[i]
        
        # Calcul des intervalles de prévision
        df1$Upper1[i] = df1$Upper1_3prime[i] + df1$Upper1[i-d1] + df1$Upper1[i-d2] + df1$Upper1[i-d3] - df1$Upper1[i-d1-d2] - df1$Upper1[i-d1-d3] - df1$Upper1[i-d2-d3] + df1$Upper1[i-d1-d2-d3]
        df1$Upper2[i] = df1$Upper2_3prime[i] + df1$Upper2[i-d1] + df1$Upper2[i-d2] + df1$Upper2[i-d3] - df1$Upper2[i-d1-d2] - df1$Upper2[i-d1-d3] - df1$Upper2[i-d2-d3] + df1$Upper2[i-d1-d2-d3]
        df1$Lower1[i] = df1$Lower1_3prime[i] + df1$Lower1[i-d1] + df1$Lower1[i-d2] + df1$Lower1[i-d3] - df1$Lower1[i-d1-d2] - df1$Lower1[i-d1-d3] - df1$Lower1[i-d2-d3] + df1$Lower1[i-d1-d2-d3]
        df1$Lower2[i] = df1$Lower2_3prime[i] + df1$Lower2[i-d1] + df1$Lower2[i-d2] + df1$Lower2[i-d3] - df1$Lower2[i-d1-d2] - df1$Lower2[i-d1-d3] - df1$Lower2[i-d2-d3] + df1$Lower2[i-d1-d2-d3]
      }
    }
  
  ###################################### -
  # Reconstruction d'un objet forecast # -
  ###################################### -
    
  # Préparation des éléments
  # Série initiale
  x = df1$Xt[1:last_observation]
  x = ts(x, start = 1)
  
  # Prévisions
  mean = df1$Xt_hat[(last_observation+1):(last_observation+horizon)]
  mean = ts(mean, start = last_observation+1)
  
  # Valeurs estimées
  fitted = df1$Xt_hat[1:last_observation]
  fitted = ts(fitted, start = 1)
  
  # Résidus
  residuals = fitted[(d1 + d2 +1):length(fitted)] - x[(d1+d2 +d3 +1):length(fitted)]
  residuals = ts(residuals, start = (d1 + d2 +d3 +1))
  
  level = level # Niveau de confiance
  method = nom_modele # Nom du modèle
  model = modele # Modèle utilisé

  # Intervalles de prévisions (upper)
  upper = cbind(df1$Upper1[(last_observation + 1):(last_observation + horizon)], 
                df1$Upper2[(last_observation + 1):(last_observation + horizon)])
  colnames(upper) = c(paste0(level[1],"pct"), paste0(level[2], "pct"))
  upper = ts(upper, start = last_observation+1)
  
  # Intervalles de prévisions (lower)
  lower = cbind(df1$Lower1[(last_observation + 1):(last_observation + horizon)], 
                df1$Lower2[(last_observation + 1):(last_observation + horizon)])
  colnames(lower) = c(paste0(level[1],"pct"), paste0(level[2], "pct"))
  lower = ts(lower, start = last_observation+1)

  # Création d'une liste
  S3ARMA_fc = list(x = x, 
                mean = mean,
                fitted = fitted,
                residuals = residuals,
                level = level,
                method = method,
                model = model,
                upper = upper,
                lower = lower)
  
  # Création de l'objet forecast
  S3ARMA_fc = structure(S3ARMA_fc, class='forecast')
  
  ############# -
  # Résultats # -
  ############# -
  
  if(messages==TRUE){cat("### Fin d'éxécution \n")}
  
  return("S3ARMA_forecast" = S3ARMA_fc)
  
}
```

```{r func_S3ARMA_part4, include=FALSE}
#*Note* : Il faut fournir à la fonction une série stationnaire. Pas de différenciation simple possible, le paramètre `d` de la fonction `func_S3ARMA_part1` est fixé à 0. Une fois le meilleur modèle trouvé, il sera possible de donner à la fonction `func_S3ARMA_part1` une série à laquelle il faudra appliquer une différenciation simple.

func_S3ARMA_part4 = function(serie_used, # Série différenciée à modéliser
                             saison1 = 0, # Saisonnalités
                             saison2 = 0,
                             saison3 = 0,
                             list_combinaisons, # Liste des combinaisons à modéliser et comparer
                             messages = TRUE # Messages de suivi
                             ){
  
  ################################ -
  ### PARTIE IV  - Auto.S3ARMA ### -
  ################################ -
  
  # POUR INFORMATION : Format attendu pour le paramètre list_combinaisons
  
  # list_combinaisons = expand.grid(p = c(0:1),
  #                                 q = c(0,0),
  #                                 # Première saisonnalité
  #                                 p_s1 = c(0:1),
  #                                 q_s1 = c(0:0),
  #                                 # Seconde saisonnalité
  #                                 p_s2 = c(0:1),
  #                                 q_s2 = c(0:0),
  #                                 # Troisième saisonnalité
  #                                 p_s3 = c(0:1),
  #                                 q_s3 = c(0:0),
  #                                 # Moyenne
  #                                 mean = c(TRUE, FALSE))
  
  #################### -
  # Message de suivi # -
  #################### -
  
  if(messages == TRUE){
  
    cat("\n")
    cat("####################### \n")
    cat("### Fonction S3ARMA ### \n")
    cat("####################### \n")
    cat("\n")
    cat("Modèle SARMA à saisonnalités multiples \n")
    cat("Version 2.0 \n")
    cat("Paul BOUST \n")
    cat("\n")
    cat("Partie IV - Sélection automatique du meilleur modèle \n")
    cat("---------------------------------------------------- \n\n")
    cat(paste("Nombre de modèles :", count(list_combinaisons), "\n"))
    cat(paste("Heure de début :", Sys.time(), "\n\n"))
    
    # Message avant (longue) estimation du modèle
    cat("Je réfléchis ... Vous avez le temps pour un petit café ! ") 
    cat("\U0002615 \n\n")
    
  }   
  
  # Temps début d'exécution
  temps_debut = Sys.time()

  ################## -
  # Initialisation # -
  ################## -
  
  # Création de la table de résultat complète
  resultats.total = data.frame("Modele" = character(),
                                "AICc" = numeric(),
                                "Nb.coefs" = integer(),
                                "Sig.score" = numeric())
  
  ####################### -
  # Boucle d'estimation # -
  ####################### -
  
  # Début de la boucle sur tous les modèles à tester
  for (j in index(list_combinaisons)){
  
    # On récupère les paramètres du modèle
    # Partie non-saisonnière
    p = list_combinaisons[j,1]
    q = list_combinaisons[j,2]
    
    # Partie saisonnière 1
    saison1 = saison1
    p_s1 = list_combinaisons[j,3]
    q_s1 = list_combinaisons[j,4]
    
    # Partie saisonnière 2
    saison2 = saison2
    p_s2 = list_combinaisons[j,5]
    q_s2 = list_combinaisons[j,6]
    
    # Partie saisonnière 1
    saison3 = saison3
    p_s3 = list_combinaisons[j,7]
    q_s3 = list_combinaisons[j,8]
    
    # Moyenne
    mean = list_combinaisons[j,9]
  
    # Nom du modèle 
    nom_modele = paste0("S3ARMA(",p,",",q,")",
                      "(",p_s1,",",q_s1,")","[", saison1, "]",
                      "(",p_s2,",",q_s2,")","[", saison2, "]",
                      "(",p_s3,",",q_s3,")","[", saison3, "]")
    
    if(mean == TRUE){nom_modele = paste(nom_modele, "avec dérive")}

    # Message de suivi : 
    if(messages == TRUE){cat(paste("Modele", j, ":", nom_modele, "\n"))}
    
    # On estime le modèle par func_S3ARMA_part1
    estimation.modele = func_S3ARMA_part1(serie = serie_used, 
                                          p=p, q=q, d=0,
                                          saison1=saison1, p_s1=p_s1, q_s1=q_s1, 
                                          saison2=saison2, p_s2=p_s2, q_s2=q_s2, 
                                          saison3=saison3, p_s3=p_s3, q_s3=q_s3,
                                          mean, messages = FALSE)
    
    # Analyse du résultat par func_S3ARMA_part2
    analyse.modele = func_S3ARMA_part2(estimation.modele[[2]], 
                                       nom_modele = estimation.modele[[1]],
                                       messages = FALSE)
    
    # Résultat
    resultat.modele = analyse.modele[[2]]
    
    # On joint le résultat a la base complète
    resultats.total = rbind(resultats.total, resultat.modele)
  }
  
  ##################### -
  # Tri des résultats # -
  ##################### -
  
  # Meilleurs modèles

  meilleurs_resultats = na.omit(resultats.total)
  meilleurs_resultats = meilleurs_resultats[order(meilleurs_resultats$AICc),]
  
  ############ -
  # Résultat # -
  ############ -
  
  temps_fin = Sys.time()
  temps_total = temps_fin - temps_debut
  
  if(messages==TRUE){
    cat("\n")
    cat(temps_total)
    cat("\n")
    cat("\n")
    cat("### Fin d'éxécution \n")
  }
  
  return(list("Meilleurs_resultats" = meilleurs_resultats, 
              "Tous_resultats" = resultats.total))
}

```

\
\
\
\

# Appendix B : Application de la fonction S3ARMA sur données simulées

--- 

## Simulation des données

Dans ce dernier appendix, nous proposons d'essayer nos fonctions sur des séries simulées. Pour construire nos séries, nous partons de trois séries initiales, toutes saisonnières et de fréquences différentes :

- Une première série `S1` saisonnière de fréquence 10
- Une seconde série `S2` saisonnière de fréquence 105
- Une dernière série `S3` saisonnière de fréquence 33

```{r Simulations, include=FALSE}
################################## -
# Simulation de plusieurs séries # -
################################## -

longeur_serie = 700
amplitude_bruit = 200

################### -
# Niveau et bruit # -
################### -
t = seq(1:longeur_serie)
Level = rep(0, longeur_serie)
Bruit = rnorm(longeur_serie) * amplitude_bruit

################## -
# Saisonnalité 1 # -
################## -
#Fréquence = 10
saisonnalite1 = c(-200, -100, -150, 50, -500, 250, 400, 100, 0, -150)
S1 = rep(saisonnalite1, ceiling(longeur_serie/length(saisonnalite1)))
S1 = S1[1:longeur_serie]

################## -
# Saisonnalité 2 # -
################## -
#Fréquence = 105
x = seq(from = 1, to = 105, by = 1)
saisonnalite2 = (sin(0.06 * x) + cos(0.12*x))*1000
S2 = rep(saisonnalite2, ceiling(longeur_serie/length(saisonnalite2)))
S2 = S2[1:longeur_serie]

################## -
# Saisonnalité 3 # -
################## -
#Fréquence = 33
x = seq(from = -1, to = 1, by = 0.061)
saisonnalite3 = (sin(pi*x) + abs(x))*350
S3 = rep(saisonnalite3, ceiling(longeur_serie/length(saisonnalite3)))
S3 = S3[1:longeur_serie]

############# -
# Dataframe # -
############# -
df.simulations = data.frame(t, Level, S1, S2, S3, Bruit) 

df.simulations$X1S = (df.simulations$Level + 
                      df.simulations$S1 +
                      df.simulations$Bruit/7)

df.simulations$X2S = (df.simulations$Level + 
                      df.simulations$S1 +
                      df.simulations$S2 + 
                      df.simulations$Bruit/2)

df.simulations$X3S = (df.simulations$Level + 
                      df.simulations$S1 + 
                      df.simulations$S2 + 
                      df.simulations$S3 + 
                      df.simulations$Bruit/1)

# Représentation graphique
autoplot(ts(df.simulations$X3S)) + 
  autolayer(ts(df.simulations$S1)) + 
  autolayer(ts(df.simulations$S2)) + 
  autolayer(ts(df.simulations$S3))

###################################### -
# Récupération des séries temporelle # -
###################################### -

Sim1S = ts(df.simulations$X1S)
Sim1S_D = diff(Sim1S, 10)

Sim2S = ts(df.simulations$X2S)
Sim2S_D = diff(Sim2S, 10)
Sim2S_DD = diff(diff(Sim2S, 10), 105)

Sim3S = ts(df.simulations$X3S)
Sim3S_D = diff(Sim3S, 10)
Sim3S_DD = diff(diff(Sim3S, 10), 105)
Sim3S_DDD = diff(diff(diff(Sim3S, 10), 105), 33)
```

On représente ci-dessous nos différentes séries simulées

\

<center>

```{r, include=TRUE, echo=FALSE}
autoplot(head(ts(df.simulations$S1), 150), series = "Frequence = 10") + 
  autolayer(head(ts(df.simulations$S2), 150), series = "Fréquence = 105") + 
  autolayer(head(ts(df.simulations$S3), 150), series = "Fréquence = 33") +
  theme(legend.position = "bottom") + 
  labs(title = "Représentation de nos trois séries saisonnières",
       x = "Temps", y = "Valeurs des séries")
```

</center>

\

À partir de ces trois séries, on peut construire des séries simplement, doublement et triplement saisonnières en les additionnant, et en ajoutant du bruit. On construit ainsi trois séries : 

- Une première série `Sim1S` saisonnière de fréquence 10.
- Une seconde série `Sim2S` doublement saisonnière de fréquence 10 et 105
- Une dernière série `Sim3S` triplement saisonnière de fréquence 10, 105 et 33

On peut donc utiliser nos fonctions `S3ARMA` pour traiter ces séries. 

\
\

## Vérification du bon fonctionnement sur saisonnalité simple

On s'intéresse tout d'abord à notre série `Sim1S`, simple série saisonnière de fréquence 10. Elle est représentée en rouge sur le graphique précédent. Elle est construite comme la répétition d'un motif de longueur 10, sur 500 périodes, auquel on ajoute du bruit. Pour l'étudier, on la différencie saisonnièrement et on appelle la série différenciée `Sim1S_D`. Pour la modéliser, un modèle SARMA saisonnier est évidemment requis. Comparons les résultats obtenus *via* une modélisation classique et avec notre fonction `S3ARMA`.

```{r Modelisation_classique_Sim1S, include=TRUE}
# Modélisation classique de la série Sim1S
modele_classique_Sim1S = Arima(ts(Sim1S, frequency = 10),
                               order = c(1,0,0),
                               seasonal = c(1,1,0),
                               method = "CSS-ML",
                               include.mean = FALSE)

# Affichage des résultats de la modélisation classique 
modele_classique_Sim1S
```

\

Ci-dessous le résultat avec la fonction `func_S3ARMA_part1` :



```{r Modelisation_maison_Sim1S, include=TRUE}
# Modélisation de la série à grâce à notre fonction func_S3ARMA_part1

# Série à étudier
serie = Sim1S_D

# Paramètres du modèle
p = 1
q = 0
saison1 = 10
p_s1 = 1
q_s1 = 0
saison2 = 0
p_s2 = 0
q_s2 = 0
saison3 = 0
p_s3 = 0
q_s3 = 0
mean = FALSE

# Estimation du modèle
modele_maison_Sim1S = func_S3ARMA_part1(serie=serie, p = p, q = q, 
                            saison1 = saison1, p_s1 = p_s1, q_s1 = q_s1, 
                            saison2 = saison2, p_s2 = p_s2, q_s2 = q_s2,
                            saison3 = saison3, p_s3 = p_s3, q_s3 = q_s3,
                            method = "CSS-ML",
                            mean = mean)
```

\

On affiche les résultats grâce à la fonction `func_S3ARMA_part2`

```{r, include=TRUE, collapse=TRUE, warning=FALSE, message=FALSE}
# Affichage des résultats de notre estimation S3ARMA
func_S3ARMA_part2(modele = modele_maison_Sim1S[[2]],
                  nom_modele = modele_maison_Sim1S[[1]])
```

\

On observe que nous obtenons bien les mêmes résultats avec nos deux modélisations. Afin de confirmer également le bon fonctionnement de notre fonction `func_S3ARMA_part3`, nous souhaitons obtenir les prévisions pour notre série initiale `Sim1S`, non-différenciée donc. Avec la fonction `Arima` classique, c'est facile : la fonction `forecast` s'occupe de tout. C'est ce que l'on fait ci-dessous, avec le premier graphique. Le second graphique correspond aux prévisions calculées par notre fonction `func_S3ARMA_part3`. On observe bien qu'il s'agit des mêmes chiffres. 

\

<center>

```{r, include=TRUE, echo=FALSE}
# Utilisation classique de la fonction forecast
forecast_classique_Sim1S = forecast(modele_classique_Sim1S, h=50)
autoplot(forecast_classique_Sim1S, PI=FALSE) +
  labs(title = "Prévisions pour la série Sim1S, simplement saisonnière",
       subtitle = "Obtenues par modélisation ARIMA(1,0,0)(1,1,0)[10] classique (fonction R)",
       x = "Temps", y="Valeur de la série")
```
</center>

\

On calcule les prévisions pour notre modèle S3ARMA. 

```{r, include=TRUE}
# Utilisation de la fonction func_S3ARMA_part3
forecast_simulation_Sim1S = func_S3ARMA_part3(modele = modele_maison_Sim1S[[2]],
                              nom_modele = modele_maison_Sim1S[[1]], 
                              horizon = 50, 
                              level = c(80,95),
                              serie_init = Sim1S,
                              d1 = 10, d2 = 0, d3 = 0)
```

\

On affiche le résultat graphique : 

\


<center>

```{r, include=TRUE, echo=FALSE, collapse=TRUE}
# Affichage graphique des résultats
autoplot(forecast_simulation_Sim1S, PI=FALSE) +
    labs(title = "Prévisions pour la série Sim1S, simplement saisonnière",
       subtitle = "Obtenues par modélisation SARMA(1,0)(1,0)[10] par la fonction S3ARMA",
       x = "Temps", y="Valeur de la série")
```

</center>

\

Pour s'en convaincre, on affiche ci-dessous les premières valeur de chacun des objets `forecast`. En premier on trouve les valeurs obtenues de manière classique, tandis qu'en dessous le lecteur trouvera celles obtenues par notre fonction. 

```{r, include=TRUE, echo=FALSE}
# Prévisions obtenues de manière classique
cat("Fonction Arima classique :\n\n")
head(forecast_classique_Sim1S$mean)
```

```{r, include=TRUE, echo=FALSE}
# Prévisions calculées avec la fonction func_S3ARMA_part3
cat("Fonction func_S3ARMA_part3 :\n\n")
head(forecast_simulation_Sim1S$mean)
```

\
\

## Application des fonctions à une série doublement saisonnière

Tentons pour ce dernier point du projet de modéliser une série doublement saisonnière. Nous souhaitons modéliser la série `Sim2S`. La série est représentée graphiquement ci-dessous.

\

<center>

```{r, include=TRUE, echo=FALSE}
autoplot(Sim2S) + 
  labs(title = "Représentation graphique de la série Sim2S",
       subtitle = "Série doublement saisonnière de fréquences 10 et 105",
       x = "Temps", y = "Valeur de la série")
```

</center>

\

Supposons que nous n'ayons aucune idée quant à la façon de modéliser cette série. Nous la savons doublement saisonnière, nous la différencions saisonnièrement donc deux fois, et nous souhaitons appliquer la fonction `func_S3ARMA_part4`. C'est ce que nous faisons ci-dessous. Nous essayons 8 combinaisons, à savoir tous les modèles où seule la partie AR, qu'elle soit saisonnière ou non, peut être égale à 0 ou 1. Deux tableaux s'affichent ci-dessous : le premier correspond aux meilleurs modèles trouvés par la fonction selon l'AICc, et le second correspond à l'ensemble des résultats. Sans surprise, le meilleur modèle trouvé par la fonction est le modèle :

$$
\textrm{SARMA(0,0)(1,0)[10](1,0)[105]}
$$

\

```{r Application func_S3ARMA_part4, include=TRUE, echo=FALSE}
# Liste des combinaisons à estimer 
list_combinaisons = expand.grid(p = c(0:1),
                                q = c(0:0),
                                # Première saisonnalité
                                p_s1 = c(0:1),
                                q_s1 = c(0:0),
                                # Seconde saisonnalité
                                p_s2 = c(0:1),
                                q_s2 = c(0:0),
                                # Troisième saisonnalité
                                p_s3 = c(0:0),
                                q_s3 = c(0:0),
                                # Moyenne
                                mean = c(FALSE))

# Fonction func_S3ARMA_part4
func_S3ARMA_part4(serie_used = Sim2S_DD, 
                  saison1 = 10,
                  saison2 = 105,
                  saison3 = 0,
                  list_combinaisons = list_combinaisons,
                  messages = TRUE)
```

\

Nous fixons donc cette modélisation que nous ré-estimons en utilisant la fonction `func_S3ARMA_part1`. Une fois l'estimation effectuée, nous calculons les prévisions grâce à la fonction `func_S3ARMA_part3` et nous les représentons graphiquement. Le résultat est présenté ci-dessous. **Il confirme à lui seul l'efficacité de notre méthode, capturant parfaitement la double saisonnalité présente dans les données**. 

\

```{r, include=TRUE, echo=FALSE}
# Modélisation de la série doublement saisonnière
# Série à étudier
serie = Sim2S_DD

# Paramètres du modèle
p = 0
q = 0
saison1 = 10
p_s1 = 1
q_s1 = 0
saison2 = 105
p_s2 = 1
q_s2 = 0
saison3 = 0
p_s3 = 0
q_s3 = 0
mean = FALSE

# Estimation du modèle
modele_maison_Sim2S = func_S3ARMA_part1(serie=serie, p = p, q = q, 
                            saison1 = saison1, p_s1 = p_s1, q_s1 = q_s1, 
                            saison2 = saison2, p_s2 = p_s2, q_s2 = q_s2,
                            saison3 = saison3, p_s3 = p_s3, q_s3 = q_s3,
                            method = "ML",
                            mean = mean)

# Calcul des prévisions
forecast_simulation_Sim2S = func_S3ARMA_part3(modele = modele_maison_Sim2S[[2]],
                              nom_modele = modele_maison_Sim2S[[1]], 
                              horizon = 150, 
                              level = c(80,95),
                              serie_init = Sim2S,
                              d1 = 10, d2 = 105, d3 = 0)
```

<center>

```{r, include=TRUE, echo=FALSE}
# Construction graphique
autoplot(forecast_simulation_Sim2S, PI=FALSE) + 
  labs(title="Prévisions de la série Sim2S, doublement saisonnière",
       subtitle = "Prévisions obtenues à partir d'un modèle SARMA(0,0)(1,0)[10](1,0)[105]",
       x = "Temps", y = "Valeurs de la série")

```

</center>

\


*Note : Nous n'explorons pas ici la triple saisonnalité, car nous n'avons pas au moment de la rédaction de ce devoir eu suffisamment de temps pour tester les différentes modélisations pour la série `Sim3S`. Le calcul des différents modèles possibles est extrêmement coûteux en temps. Cependant, nous sommes pleinement convaincus de l'efficacité de notre fonction pour une série triplement saisonnière.*

\
\

# Bibliographie









